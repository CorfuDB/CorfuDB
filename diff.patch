diff --git a/infrastructure/proto/log_replication_metadata.proto b/infrastructure/proto/log_replication_metadata.proto
index 6b03bca96c9..00ec2fb450e 100644
--- a/infrastructure/proto/log_replication_metadata.proto
+++ b/infrastructure/proto/log_replication_metadata.proto
@@ -3,22 +3,16 @@ syntax = "proto3";
 package org.corfudb.infrastructure.logreplication.proto;
 
 import "corfu_options.proto";
+import "rpc_common.proto";
 import "google/protobuf/timestamp.proto";
 
-/**
- * This is used by replication metadata table in corfu store.
- * The metadata table has the following key-value pairs defined both as strings:
- * One example to show the standby is at log entry sync state:
- * "topologyConfigId": "0"
- * "version": "release-1.0"
- * "lastSnapshotStarted": "100"
- * "lastSnapshotTransferredSeqNumber": "88"
- * "lastSnapshotTransferred": "100"
- * "lastSnapshotApplied": "100"
- * "lastLogEntryProcessed": "168"
- */
-message LogReplicationMetadataKey {
-  string key = 1;
+message LogReplicationSession {
+  string clusterId = 1;
+}
+
+enum SyncType {
+  SNAPSHOT = 0;
+  LOG_ENTRY = 1;
 }
 
 /**
@@ -26,26 +20,46 @@ message LogReplicationMetadataKey {
  * metadata table in corfu store. For example:
  * key: "topologyConfigId", val: "1".
  */
-message LogReplicationMetadataVal {
-  string val = 1;
+message ReplicationMetadata {
+  uint64 topologyConfigId = 1;
+  string version = 2;
+  int64 lastSnapshotStarted = 3;
+  int64 lastSnapshotTransferredSeqNumber = 4;
+  int64 lastSnapshotTransferred = 5;
+  int64 lastSnapshotApplied = 6;
+  int64 lastLogEntryProcessed = 7;
+  org.corfudb.runtime.UuidMsg currentSnapshotCycleId = 8;
+  int64 currentCycleMinShadowStreamTs = 9;
+  int64 remainingReplicationPercent = 10;
+  bool dataConsistentOnStandby = 11;
+  SyncType snapshotSyncType = 12;
+  int64 snapshotSyncCompleteTime = 13;
 }
 
-/*
- * Replication Status Key
- */
- message ReplicationStatusKey {
-   string clusterId = 1;
- }
+message SourceReplicationStatus {
+   option (org.corfudb.runtime.table_schema).stream_tag = "lr_status";
 
-/*
- * Replication Status Value
- * Active Site sets the completionPercent, Standby sets the dataConsistent boolean
- */
-message ReplicationStatusVal {
+   uint64 remainingEntriesToSend = 1; // Set only by Source
+   enum SyncType {
+     SNAPSHOT = 0;
+     LOG_ENTRY = 1;
+   }
+   SyncType syncType = 2;
+   SyncStatus status = 3;
+   SnapshotSyncInfo snapshotSyncInfo = 4;
+}
+
+message SinkReplicationStatus {
   option (org.corfudb.runtime.table_schema).stream_tag = "lr_status";
 
-  uint64 remainingEntriesToSend = 1;
-  bool dataConsistent = 2;
+  bool dataConsistent = 1; // Set only by Sink
+}
+
+message ReplicationStatus {
+  option (org.corfudb.runtime.table_schema).stream_tag = "lr_status";
+
+  uint64 remainingEntriesToSend = 1; // Set only by Source
+  bool dataConsistent = 2; // Set only by Sink
   enum SyncType {
     SNAPSHOT = 0;
     LOG_ENTRY = 1;
@@ -55,6 +69,20 @@ message ReplicationStatusVal {
   SnapshotSyncInfo snapshotSyncInfo = 5;
 }
 
+message SourceReplicationStatus {
+  option (org.corfudb.runtime.table_schema).stream_tag = "lr_status";
+
+  uint64 remainingEntriesToSend = 1; // Set only by Source
+  SyncType syncType = 2;
+  SyncStatus status = 3;
+  SnapshotSyncInfo snapshotSyncInfo = 4;
+}
+
+message SinkReplicationStatus {
+  option (org.corfudb.runtime.table_schema).stream_tag = "lr_status";
+  bool dataConsistent = 1;
+}
+
 /*
  * Snapshot Sync Info
  *
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationRuntimeParameters.java b/infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationRuntimeParameters.java
index f366347505e..2190e083ddf 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationRuntimeParameters.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationRuntimeParameters.java
@@ -5,6 +5,7 @@ import io.netty.channel.EventLoopGroup;
 import lombok.Data;
 import org.corfudb.comm.ChannelImplementation;
 import org.corfudb.infrastructure.logreplication.LogReplicationConfig;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationSession;
 import org.corfudb.infrastructure.logreplication.transport.IChannelContext;
 
 import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;
@@ -22,6 +23,9 @@ import java.util.UUID;
 @Data
 public class LogReplicationRuntimeParameters extends RuntimeParameters {
 
+    // Runtime unique log replication session identifier
+    private LogReplicationSession session;
+
     // Remote Cluster Descriptor
     private ClusterDescriptor remoteClusterDescriptor;
 
@@ -60,6 +64,7 @@ public class LogReplicationRuntimeParameters extends RuntimeParameters {
         private LogReplicationConfig replicationConfig;
         private IChannelContext channelContext;
         private int maxWriteSize;
+        private LogReplicationSession session;
 
         private LogReplicationRuntimeParametersBuilder() {
         }
@@ -69,6 +74,11 @@ public class LogReplicationRuntimeParameters extends RuntimeParameters {
             return this;
         }
 
+        public LogReplicationRuntimeParameters.LogReplicationRuntimeParametersBuilder session(LogReplicationSession session) {
+            this.session = session;
+            return this;
+        }
+
         public LogReplicationRuntimeParameters.LogReplicationRuntimeParametersBuilder localClusterId(String localClusterId) {
             this.localClusterId = localClusterId;
             return this;
@@ -251,6 +261,7 @@ public class LogReplicationRuntimeParameters extends RuntimeParameters {
             runtimeParameters.setUncaughtExceptionHandler(uncaughtExceptionHandler);
             runtimeParameters.setSystemDownHandler(systemDownHandler);
             runtimeParameters.setBeforeRpcHandler(beforeRpcHandler);
+            runtimeParameters.setSession(session);
             runtimeParameters.setLocalCorfuEndpoint(localCorfuEndpoint);
             runtimeParameters.setLocalClusterId(localClusterId);
             runtimeParameters.setRemoteClusterDescriptor(remoteClusterDescriptor);
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java b/infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java
index 226b5083df0..1dec73c9208 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java
@@ -7,10 +7,14 @@ import io.netty.channel.ChannelPipeline;
 import lombok.Getter;
 import lombok.extern.slf4j.Slf4j;
 import org.corfudb.infrastructure.logreplication.LogReplicationConfig;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationSession;
 import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;
 import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationSinkManager;
+import org.corfudb.runtime.LogReplication;
 import org.corfudb.runtime.LogReplication.LogReplicationEntryMsg;
 import org.corfudb.runtime.LogReplication.LogReplicationEntryType;
+import org.corfudb.runtime.proto.service.CorfuMessage;
 import org.corfudb.runtime.proto.service.CorfuMessage.HeaderMsg;
 import org.corfudb.runtime.proto.service.CorfuMessage.RequestMsg;
 import org.corfudb.runtime.proto.service.CorfuMessage.RequestPayloadMsg.PayloadCase;
@@ -69,9 +73,9 @@ public class LogReplicationServer extends AbstractServer {
 
     public LogReplicationServer(@Nonnull ServerContext context, @Nonnull  LogReplicationConfig logReplicationConfig,
                                 @Nonnull LogReplicationMetadataManager metadataManager, String corfuEndpoint,
-                                long topologyConfigId, String localNodeId) {
+                                long topologyConfigId, String localNodeId, String localClusterId) {
         this(context, metadataManager, new LogReplicationSinkManager(corfuEndpoint, logReplicationConfig,
-                metadataManager, context, topologyConfigId), localNodeId);
+                metadataManager, context, topologyConfigId, LogReplicationSession.newBuilder().setClusterId(localClusterId).build()), localNodeId);
     }
 
     public LogReplicationServer(@Nonnull ServerContext context,
@@ -153,15 +157,26 @@ public class LogReplicationServer extends AbstractServer {
         log.info("Log Replication Metadata Request received by Server.");
 
         if (isLeader(request, ctx, router, false)) {
-            LogReplicationMetadataManager metadataMgr = sinkManager.getLogReplicationMetadataManager();
-            ResponseMsg response = metadataMgr.getMetadataResponse(getHeaderMsg(request.getHeader()));
+            LogReplicationMetadata.ReplicationMetadata metadata = sinkManager.getMetadata();
+
+            LogReplication.LogReplicationMetadataResponseMsg metadataMsg = LogReplication.LogReplicationMetadataResponseMsg
+                    .newBuilder()
+                    .setTopologyConfigID(metadata.getTopologyConfigId())
+                    .setVersion(metadata.getVersion())
+                    .setSnapshotStart(metadata.getLastSnapshotStarted())
+                    .setSnapshotTransferred(metadata.getLastSnapshotTransferred())
+                    .setSnapshotApplied(metadata.getLastSnapshotApplied())
+                    .setLastLogEntryTimestamp(metadata.getLastLogEntryProcessed())
+                    .build();
+            CorfuMessage.ResponsePayloadMsg payload = CorfuMessage.ResponsePayloadMsg.newBuilder()
+                    .setLrMetadataResponse(metadataMsg).build();
+            ResponseMsg response = getResponseMsg(getHeaderMsg(request.getHeader()), payload);
+
             log.info("Send Metadata response :: {}", TextFormat.shortDebugString(response.getPayload()));
             router.sendResponse(response, ctx);
 
             // If a snapshot apply is pending, start (if not started already)
-            if (isSnapshotApplyPending(metadataMgr) && !sinkManager.getOngoingApply().get()) {
-                sinkManager.resumeSnapshotApply();
-            }
+            sinkManager.startPendingSnapshotApply();
         } else {
             log.warn("Dropping metadata request as this node is not the leader.");
         }
@@ -191,11 +206,6 @@ public class LogReplicationServer extends AbstractServer {
 
     /* ************ Private / Utility Methods ************ */
 
-    private boolean isSnapshotApplyPending(LogReplicationMetadataManager metadataMgr) {
-        return (metadataMgr.getLastStartedSnapshotTimestamp() == metadataMgr.getLastTransferredSnapshotTimestamp()) &&
-                metadataMgr.getLastTransferredSnapshotTimestamp() > metadataMgr.getLastAppliedSnapshotTimestamp();
-    }
-
     /**
      * Verify if current node is still the lead receiving node.
      *
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java
index 2a0f4b0c582..ff5dd1135fa 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryService.java
@@ -17,7 +17,7 @@ import org.corfudb.infrastructure.logreplication.infrastructure.plugins.LogRepli
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationEvent;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationEventKey;
 import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;
@@ -335,11 +335,13 @@ public class CorfuReplicationDiscoveryService implements Runnable, CorfuReplicat
         // such as streams to replicate and version
         LogReplicationConfig logReplicationConfig = getLogReplicationConfiguration(getCorfuRuntime());
 
+        // TODO(AGMM): the metadataManager & LogReplicatioServer should probably be created on leadership acquire (second one role-based)
         logReplicationMetadataManager = new LogReplicationMetadataManager(getCorfuRuntime(),
-            topologyDescriptor.getTopologyConfigId(), localClusterDescriptor.getClusterId());
+            topologyDescriptor, LogReplicationConfigManager.getCurrentVersion());
 
         logReplicationServerHandler = new LogReplicationServer(serverContext, logReplicationConfig,
-            logReplicationMetadataManager, localCorfuEndpoint, topologyDescriptor.getTopologyConfigId(), localNodeId);
+            logReplicationMetadataManager, localCorfuEndpoint, topologyDescriptor.getTopologyConfigId(), localNodeId,
+                localClusterDescriptor.getClusterId());
         logReplicationServerHandler.setActive(localClusterDescriptor.getRole().equals(ClusterRole.ACTIVE));
         logReplicationServerHandler.setStandby(localClusterDescriptor.getRole().equals(ClusterRole.STANDBY));
 
@@ -794,13 +796,13 @@ public class CorfuReplicationDiscoveryService implements Runnable, CorfuReplicat
      * snapshot sync is in the apply phase)
      */
     @Override
-    public Map<String, LogReplicationMetadata.ReplicationStatusVal> queryReplicationStatus() {
+    public Map<String, ReplicationStatus> queryReplicationStatus() {
         if (localClusterDescriptor == null || logReplicationMetadataManager == null) {
             log.warn("Cluster configuration has not been pushed to current LR node.");
             return null;
         } else if (localClusterDescriptor.getRole() == ClusterRole.ACTIVE) {
-            Map<String, LogReplicationMetadata.ReplicationStatusVal> mapReplicationStatus = logReplicationMetadataManager.getReplicationRemainingEntries();
-            Map<String, LogReplicationMetadata.ReplicationStatusVal> mapToSend = new HashMap<>(mapReplicationStatus);
+            Map<String, ReplicationStatus> mapReplicationStatus = logReplicationMetadataManager.getReplicationRemainingEntries();
+            Map<String, ReplicationStatus> mapToSend = new HashMap<>(mapReplicationStatus);
             // If map contains local cluster, remove (as it might have been added by the SinkManager) but this node
             // has an active role.
             if (mapToSend.containsKey(localClusterDescriptor.getClusterId())) {
@@ -809,32 +811,32 @@ public class CorfuReplicationDiscoveryService implements Runnable, CorfuReplicat
             }
             return mapToSend;
         } else if (localClusterDescriptor.getRole() == ClusterRole.STANDBY) {
-            return logReplicationMetadataManager.getDataConsistentOnStandby();
+            return logReplicationMetadataManager.getDataConsistentOnStandby(localClusterDescriptor.clusterId);
         }
         log.error("Received Replication Status Query in Incorrect Role {}.", localClusterDescriptor.getRole());
         return null;
     }
 
     @Override
-    public UUID forceSnapshotSync(String clusterId) throws LogReplicationDiscoveryServiceException {
+    public UUID forceSnapshotSync(String remoteClusterId) throws LogReplicationDiscoveryServiceException {
         if (localClusterDescriptor.getRole() == ClusterRole.STANDBY) {
-            String errorStr = "The forceSnapshotSync command is not supported on standby cluster.";
+            String errorStr = "Force snapshot sync is not supported on sink. Please request from source node.";
             log.error(errorStr);
             throw new LogReplicationDiscoveryServiceException(errorStr);
         }
 
         UUID forceSyncId = UUID.randomUUID();
-        log.info("Received forceSnapshotSync command for standby cluster {}, forced sync id {}",
-                clusterId, forceSyncId);
+        log.info("Received forceSnapshotSync request to (sink) cluster {}, force_sync_id={}",
+                remoteClusterId, forceSyncId);
 
         // Write a force sync event to the logReplicationEventTable
-        ReplicationEventKey key = ReplicationEventKey.newBuilder().setKey(System.currentTimeMillis() + " " + clusterId).build();
+        ReplicationEventKey key = ReplicationEventKey.newBuilder().setKey(System.currentTimeMillis() + " " + remoteClusterId).build();
         ReplicationEvent event = ReplicationEvent.newBuilder()
-                .setClusterId(clusterId)
+                .setClusterId(remoteClusterId)
                 .setEventId(forceSyncId.toString())
                 .setType(ReplicationEvent.ReplicationEventType.FORCE_SNAPSHOT_SYNC)
                 .build();
-        getLogReplicationMetadataManager().updateLogReplicationEventTable(key, event);
+        logReplicationMetadataManager.addEvent(key, event);
         return forceSyncId;
     }
 
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryServiceAdapter.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryServiceAdapter.java
index 34dfddafa97..a59dbd9d43d 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryServiceAdapter.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationDiscoveryServiceAdapter.java
@@ -1,7 +1,7 @@
 package org.corfudb.infrastructure.logreplication.infrastructure;
 
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus;
 
 import java.util.Map;
 import java.util.UUID;
@@ -18,7 +18,7 @@ public interface CorfuReplicationDiscoveryServiceAdapter {
      *
      * @return
      */
-    Map<String, LogReplicationMetadata.ReplicationStatusVal> queryReplicationStatus();
+    Map<String, ReplicationStatus> queryReplicationStatus();
 
     /**
      * Enforce snapshotFullSync
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java
index 9edb60a9bc0..7188847d754 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/CorfuReplicationManager.java
@@ -5,6 +5,7 @@ import lombok.Getter;
 import lombok.Setter;
 import lombok.extern.slf4j.Slf4j;
 import org.corfudb.infrastructure.LogReplicationRuntimeParameters;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationSession;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.SyncStatus;
 import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;
 import org.corfudb.infrastructure.logreplication.runtime.CorfuLogReplicationRuntime;
@@ -27,7 +28,7 @@ public class CorfuReplicationManager {
 
     // Keep map of remote cluster ID and the associated log replication runtime (an abstract
     // client to that cluster)
-    private final Map<String, CorfuLogReplicationRuntime> runtimeToRemoteCluster = new HashMap<>();
+    private final Map<LogReplicationSession, CorfuLogReplicationRuntime> runtimeToSessionMap = new HashMap<>();
 
     @Setter
     @Getter
@@ -77,15 +78,15 @@ public class CorfuReplicationManager {
      * Stop log replication for all the standby sites
      */
     public void stop() {
-        runtimeToRemoteCluster.values().forEach(runtime -> {
+        runtimeToSessionMap.values().forEach(runtime -> {
             try {
-                log.info("Stop log replication runtime to remote cluster id={}", runtime.getRemoteClusterId());
+                log.info("Stop log replication runtime to remote cluster id={}", runtime.getSession().getClusterId());
                 runtime.stop();
             } catch (Exception e) {
-                log.warn("Failed to stop log replication runtime to remote cluster id={}", runtime.getRemoteClusterId());
+                log.warn("Failed to stop log replication runtime to remote cluster id={}", runtime.getSession().getClusterId());
             }
         });
-        runtimeToRemoteCluster.clear();
+        runtimeToSessionMap.clear();
     }
 
     /**
@@ -102,7 +103,7 @@ public class CorfuReplicationManager {
     private void startLogReplicationRuntime(ClusterDescriptor remoteClusterDescriptor) {
         String remoteClusterId = remoteClusterDescriptor.getClusterId();
         try {
-            if (!runtimeToRemoteCluster.containsKey(remoteClusterId)) {
+            if (!runtimeToSessionMap.containsKey(remoteClusterId)) {
                 log.info("Starting Log Replication Runtime to Standby Cluster id={}", remoteClusterId);
                 connect(remoteClusterDescriptor);
             } else {
@@ -123,7 +124,11 @@ public class CorfuReplicationManager {
         try {
             IRetry.build(IntervalRetry.class, () -> {
                 try {
+                    LogReplicationSession session = LogReplicationSession.newBuilder()
+                            .setClusterId(remoteCluster.clusterId).build();
+
                     LogReplicationRuntimeParameters parameters = LogReplicationRuntimeParameters.builder()
+                            .session(session)
                             .localCorfuEndpoint(context.getLocalCorfuEndpoint())
                             .remoteClusterDescriptor(remoteCluster)
                             .localClusterId(localNodeDescriptor.getClusterId())
@@ -141,7 +146,7 @@ public class CorfuReplicationManager {
                     CorfuLogReplicationRuntime replicationRuntime = new CorfuLogReplicationRuntime(parameters,
                             metadataManager, replicationConfigManager);
                     replicationRuntime.start();
-                    runtimeToRemoteCluster.put(remoteCluster.getClusterId(), replicationRuntime);
+                    runtimeToSessionMap.put(session, replicationRuntime);
                 } catch (Exception e) {
                     log.error("Exception {}. Failed to connect to remote cluster {}. Retry after 1 second.",
                             e, remoteCluster.getClusterId());
@@ -159,11 +164,11 @@ public class CorfuReplicationManager {
      * Stop Log Replication to a specific standby Cluster
      */
     private void stopLogReplicationRuntime(String remoteClusterId) {
-        CorfuLogReplicationRuntime logReplicationRuntime = runtimeToRemoteCluster.get(remoteClusterId);
+        CorfuLogReplicationRuntime logReplicationRuntime = runtimeToSessionMap.get(remoteClusterId);
         if (logReplicationRuntime != null) {
             log.info("Stop log replication runtime to remote cluster id={}", remoteClusterId);
             logReplicationRuntime.stop();
-            runtimeToRemoteCluster.remove(remoteClusterId);
+            runtimeToSessionMap.remove(remoteClusterId);
         } else {
             log.warn("Runtime not found to remote cluster {}", remoteClusterId);
         }
@@ -173,7 +178,7 @@ public class CorfuReplicationManager {
      * Update Log Replication Runtime config id.
      */
     public void updateRuntimeConfigId(TopologyDescriptor newConfig) {
-        runtimeToRemoteCluster.values().forEach(runtime -> runtime.updateFSMConfigId(newConfig));
+        runtimeToSessionMap.values().forEach(runtime -> runtime.updateFSMConfigId(newConfig));
     }
 
     /**
@@ -203,7 +208,7 @@ public class CorfuReplicationManager {
 
         // Start the standbys that are in the new config but not in the current config
         for (String clusterId : newStandbys) {
-            if (!runtimeToRemoteCluster.containsKey(clusterId)) {
+            if (!runtimeToSessionMap.containsKey(clusterId)) {
                 ClusterDescriptor clusterInfo = newConfig.getStandbyClusters().get(clusterId);
                 topology.addStandbyCluster(clusterInfo);
                 startLogReplicationRuntime(clusterInfo);
@@ -215,7 +220,7 @@ public class CorfuReplicationManager {
         // to the correct endpoints/nodes
         for (String clusterId : intersection) {
             ClusterDescriptor clusterInfo = newConfig.getStandbyClusters().get(clusterId);
-            runtimeToRemoteCluster.get(clusterId).updateRouterClusterDescriptor(clusterInfo);
+            runtimeToSessionMap.get(clusterId).updateRouterClusterDescriptor(clusterInfo);
         }
     }
 
@@ -223,12 +228,12 @@ public class CorfuReplicationManager {
      * Stop the current log replication event and start a full snapshot sync for the given remote cluster.
      */
     public void enforceSnapshotSync(DiscoveryServiceEvent event) {
-        CorfuLogReplicationRuntime standbyRuntime = runtimeToRemoteCluster.get(event.getRemoteClusterInfo().getClusterId());
+        CorfuLogReplicationRuntime standbyRuntime = runtimeToSessionMap.get(event.getRemoteClusterInfo().getClusterId());
         if (standbyRuntime == null) {
             log.warn("Failed to start enforceSnapshotSync for cluster {} as it is not on the standby list.",
                     event.getRemoteClusterInfo());
         } else {
-            log.info("EnforceSnapshotSync for cluster {}", standbyRuntime.getRemoteClusterId());
+            log.info("EnforceSnapshotSync for cluster {}", standbyRuntime.session.getClusterId());
             standbyRuntime.getSourceManager().stopLogReplication();
             standbyRuntime.getSourceManager().startForcedSnapshotSync(event.getEventId());
         }
@@ -239,7 +244,7 @@ public class CorfuReplicationManager {
      * Should be called only once in an active lifecycle.
      */
     public void updateStatusAsNotStarted() {
-        runtimeToRemoteCluster.values().forEach(corfuLogReplicationRuntime ->
+        runtimeToSessionMap.values().forEach(corfuLogReplicationRuntime ->
                 corfuLogReplicationRuntime
                         .getSourceManager()
                         .getAckReader()
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/DiscoveryServiceEvent.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/DiscoveryServiceEvent.java
index 104977aaa23..4e2fb60a716 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/DiscoveryServiceEvent.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/DiscoveryServiceEvent.java
@@ -2,6 +2,7 @@ package org.corfudb.infrastructure.logreplication.infrastructure;
 
 import lombok.Getter;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationSession;
 
 import java.util.UUID;
 
@@ -12,7 +13,7 @@ public class DiscoveryServiceEvent {
 
     private TopologyConfigurationMsg topologyConfig = null;
 
-    private ClusterDescriptor remoteClusterInfo;
+    private LogReplicationSession session;
 
     private UUID eventId = null;
 
@@ -22,7 +23,7 @@ public class DiscoveryServiceEvent {
 
     public DiscoveryServiceEvent(DiscoveryServiceEventType type, String clusterId) {
         this.type = type;
-        this.remoteClusterInfo = new ClusterDescriptor(clusterId);
+        this.session = LogReplicationSession.newBuilder().setClusterId(clusterId).build();
     }
 
     public DiscoveryServiceEvent(DiscoveryServiceEventType type, TopologyConfigurationMsg topologyConfigMsg) {
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/CorfuReplicationClusterManagerAdapter.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/CorfuReplicationClusterManagerAdapter.java
index 969334a180a..eeee0602a97 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/CorfuReplicationClusterManagerAdapter.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/CorfuReplicationClusterManagerAdapter.java
@@ -3,7 +3,7 @@ package org.corfudb.infrastructure.logreplication.infrastructure.plugins;
 import org.corfudb.infrastructure.logreplication.infrastructure.CorfuReplicationDiscoveryServiceAdapter;
 import org.corfudb.infrastructure.logreplication.infrastructure.LogReplicationDiscoveryServiceException;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus;
 
 import java.util.Map;
 import java.util.UUID;
@@ -50,7 +50,7 @@ public interface CorfuReplicationClusterManagerAdapter {
      *
      * @return
      */
-    Map<String, LogReplicationMetadata.ReplicationStatusVal> queryReplicationStatus();
+    Map<String, ReplicationStatus> queryReplicationStatus();
 
     /**
      * This API enforce a full snapshot sync on the standby cluster with the clusterId at best effort.
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/CorfuReplicationClusterManagerBaseAdapter.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/CorfuReplicationClusterManagerBaseAdapter.java
index 67309e8cb83..ae62334806c 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/CorfuReplicationClusterManagerBaseAdapter.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/CorfuReplicationClusterManagerBaseAdapter.java
@@ -5,7 +5,7 @@ import lombok.extern.slf4j.Slf4j;
 import org.corfudb.infrastructure.logreplication.infrastructure.CorfuReplicationDiscoveryServiceAdapter;
 import org.corfudb.infrastructure.logreplication.infrastructure.LogReplicationDiscoveryServiceException;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus;
 
 import java.util.Map;
 import java.util.UUID;
@@ -45,7 +45,7 @@ public abstract class CorfuReplicationClusterManagerBaseAdapter implements Corfu
         }
     }
 
-    public Map<String, LogReplicationMetadata.ReplicationStatusVal> queryReplicationStatus() {
+    public Map<String, ReplicationStatus> queryReplicationStatus() {
         return corfuReplicationDiscoveryService.queryReplicationStatus();
     }
 
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java
index ae6b7faf951..8dbedb1b873 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java
@@ -5,7 +5,7 @@ import lombok.ToString;
 import lombok.extern.slf4j.Slf4j;
 import org.corfudb.infrastructure.logreplication.LogReplicationConfig;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.SyncStatus;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatusVal.SyncType;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus.SyncType;
 import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;
 import org.corfudb.infrastructure.logreplication.replication.send.LogEntrySender;
 import org.corfudb.infrastructure.logreplication.replication.send.logreader.LogEntryReader;
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/fsm/InLogEntrySyncState.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/fsm/InLogEntrySyncState.java
index 9546b15dfc7..b2d9e3c80e1 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/fsm/InLogEntrySyncState.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/fsm/InLogEntrySyncState.java
@@ -2,7 +2,7 @@ package org.corfudb.infrastructure.logreplication.replication.fsm;
 
 import lombok.extern.slf4j.Slf4j;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.SyncStatus;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatusVal.SyncType;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus.SyncType;
 import org.corfudb.infrastructure.logreplication.replication.send.LogEntrySender;
 
 import java.util.UUID;
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogEntryWriter.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogEntryWriter.java
index b58ffd51b4f..804f51488d4 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogEntryWriter.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogEntryWriter.java
@@ -3,6 +3,9 @@ package org.corfudb.infrastructure.logreplication.replication.receive;
 import com.google.protobuf.TextFormat;
 import lombok.extern.slf4j.Slf4j;
 import org.corfudb.infrastructure.logreplication.LogReplicationConfig;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationMetadata;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationSession;
 import org.corfudb.protocols.logprotocol.OpaqueEntry;
 import org.corfudb.protocols.logprotocol.SMREntry;
 import org.corfudb.runtime.CorfuRuntime;
@@ -11,7 +14,6 @@ import org.corfudb.runtime.LogReplication.LogReplicationEntryMsg;
 import org.corfudb.runtime.LogReplication.LogReplicationEntryType;
 import org.corfudb.runtime.collections.TxnContext;
 import org.corfudb.runtime.view.Address;
-import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager.LogReplicationMetadataType;
 
 import javax.annotation.concurrent.NotThreadSafe;
 import java.util.HashMap;
@@ -33,15 +35,21 @@ public class LogEntryWriter {
     private long srcGlobalSnapshot; //the source snapshot that the transaction logs are based
     private long lastMsgTs; //the timestamp of the last message processed.
     private Map<UUID, List<UUID>> dataStreamToTagsMap;
+    private final LogReplicationSession session;
 
-    public LogEntryWriter(LogReplicationConfig config, LogReplicationMetadataManager logReplicationMetadataManager) {
+    public LogEntryWriter(LogReplicationConfig config, LogReplicationMetadataManager logReplicationMetadataManager,
+                          LogReplicationSession session) {
         this.logReplicationMetadataManager = logReplicationMetadataManager;
+        this.session = session;
         this.srcGlobalSnapshot = Address.NON_ADDRESS;
         this.lastMsgTs = Address.NON_ADDRESS;
         this.streamMap = new HashMap<>();
         this.dataStreamToTagsMap = config.getDataStreamToTagsMap();
 
         config.getStreamsToReplicate().stream().forEach(stream -> streamMap.put(CorfuRuntime.getStreamID(stream), stream));
+
+        ReplicationMetadata metadata = logReplicationMetadataManager.queryReplicationMetadata(session);
+        reset(metadata.getLastSnapshotApplied(), metadata.getLastLogEntryProcessed());
     }
 
     /**
@@ -60,6 +68,7 @@ public class LogEntryWriter {
 
     /**
      * Convert message data to an MultiObjectSMREntry and write to log.
+     *
      * @param txMessage
      * @return true when the msg is appended to the log
      */
@@ -68,7 +77,7 @@ public class LogEntryWriter {
 
         try (TxnContext txnContext = logReplicationMetadataManager.getTxnContext()) {
 
-            Map<LogReplicationMetadataType, Long> metadataMap = logReplicationMetadataManager.queryMetadata(txnContext, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID, LogReplicationMetadataType.LAST_SNAPSHOT_STARTED,
+            Map<LogReplicationMetadataType, Long> metadataMap = logReplicationMetadataManager.queryReplicationMetadata(txnContext, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID, LogReplicationMetadataType.LAST_SNAPSHOT_STARTED,
                     LogReplicationMetadataType.LAST_SNAPSHOT_APPLIED, LogReplicationMetadataType.LAST_LOG_ENTRY_PROCESSED);
             long persistedTopologyConfigId = metadataMap.get(LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);
             long persistedSnapshotStart = metadataMap.get(LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java
index 4dc23baba02..7acecd9f72e 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationMetadataManager.java
@@ -1,35 +1,35 @@
 package org.corfudb.infrastructure.logreplication.replication.receive;
 
+import com.google.protobuf.Descriptors;
 import com.google.protobuf.Message;
 import com.google.protobuf.Timestamp;
 import io.micrometer.core.instrument.Timer;
 import lombok.Getter;
 import lombok.extern.slf4j.Slf4j;
 import org.corfudb.common.metrics.micrometer.MeterRegistryProvider;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationMetadataKey;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationMetadataVal;
+import org.corfudb.infrastructure.logreplication.infrastructure.TopologyDescriptor;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationMetadata;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationEvent;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationEventKey;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatusKey;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatusVal;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatusVal.SyncType;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationSession;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus.SyncType;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.SnapshotSyncInfo;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.SyncStatus;
 import org.corfudb.infrastructure.logreplication.utils.LogReplicationConfigManager;
 import org.corfudb.runtime.CorfuRuntime;
 import org.corfudb.runtime.CorfuStoreMetadata;
-import org.corfudb.runtime.LogReplication;
+import org.corfudb.runtime.LogReplication.LogReplicationEntryMsg;
 import org.corfudb.runtime.collections.CorfuStore;
 import org.corfudb.runtime.collections.CorfuStoreEntry;
+import org.corfudb.runtime.collections.CorfuTable;
 import org.corfudb.runtime.collections.StreamListener;
 import org.corfudb.runtime.collections.Table;
 import org.corfudb.runtime.collections.TableOptions;
 import org.corfudb.runtime.collections.TxnContext;
 import org.corfudb.runtime.exceptions.TransactionAbortedException;
 import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;
-import org.corfudb.runtime.proto.service.CorfuMessage;
-import org.corfudb.runtime.proto.service.CorfuMessage.HeaderMsg;
-import org.corfudb.runtime.proto.service.CorfuMessage.ResponseMsg;
+import org.corfudb.runtime.proto.RpcCommon;
 import org.corfudb.runtime.view.Address;
 import org.corfudb.util.retry.IRetry;
 import org.corfudb.util.retry.IntervalRetry;
@@ -41,235 +41,240 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Optional;
+import java.util.Set;
 import java.util.UUID;
 
-import static org.corfudb.protocols.service.CorfuProtocolMessage.getResponseMsg;
 import static org.corfudb.runtime.view.TableRegistry.CORFU_SYSTEM_NAMESPACE;
 
 /**
- * The table persisted at the replication writer side.
- * It records the log reader cluster's snapshot timestamp and last log entry's timestamp, it has received and processed.
+ * The LogReplicationMetadataManager holds relevant metadata associated to
+ * all ongoing replication sessions for Source and Sink.
+ *
+ * It maintains metadata on 3 tables:
+ *
+ * (1) Metadata Table:
+ * (2) Replication Status Table: status of a replication session, this info is mostly intended for client consumption,
+ * e.g., User Interface / Alarms system. Note that this data is a subset of metadata information aimed for consumption.
+ * (3) Replication Event Table:
  */
 @Slf4j
 public class LogReplicationMetadataManager {
 
     public static final String NAMESPACE = CORFU_SYSTEM_NAMESPACE;
-    public static final String METADATA_TABLE_PREFIX_NAME = "CORFU-REPLICATION-WRITER-";
-    public static final String REPLICATION_STATUS_TABLE = "LogReplicationStatus";
-    public static final String LR_STATUS_STREAM_TAG = "lr_status";
     private static final String REPLICATION_EVENT_TABLE_NAME = "LogReplicationEventTable";
+    public static final String METADATA_TABLE_NAME = "LogReplicationMetadataTable";
+    public static final String REPLICATION_STATUS_TABLE_NAME = "LogReplicationStatus";
+    public static final String LR_STATUS_STREAM_TAG = "lr_status";
     private static final String LR_STREAM_TAG = "log_replication";
 
     private final CorfuStore corfuStore;
 
-    private final String metadataTableName;
-
     @Getter
     private final CorfuRuntime runtime;
 
-    private final String localClusterId;
-
-    private final Table<ReplicationStatusKey, ReplicationStatusVal, Message> replicationStatusTable;
-    private final Table<LogReplicationMetadataKey, LogReplicationMetadataVal, Message> metadataTable;
+    private final Table<LogReplicationSession, ReplicationStatus, Message> replicationStatusTable;
+    private final Table<LogReplicationSession, ReplicationMetadata, Message> metadataTable;
     private final Table<ReplicationEventKey, ReplicationEvent, Message> replicationEventTable;
 
     private Optional<Timer.Sample> snapshotSyncTimerSample = Optional.empty();
 
-    public LogReplicationMetadataManager(CorfuRuntime rt, long topologyConfigId, String localClusterId) {
+    /**
+     * Constructor
+     *
+     * @param rt Corfu runtime
+     * @param topologyDescriptor topology configuration descriptor
+     */
+    public LogReplicationMetadataManager(CorfuRuntime rt, TopologyDescriptor topologyDescriptor, String logReplicatorVersion) {
         this.runtime = rt;
         this.corfuStore = new CorfuStore(runtime);
 
-        metadataTableName = getPersistedWriterMetadataTableName(localClusterId);
         try {
-            this.metadataTable = this.corfuStore.openTable(NAMESPACE,
-                            metadataTableName,
-                            LogReplicationMetadataKey.class,
-                            LogReplicationMetadataVal.class,
+            this.metadataTable = this.corfuStore.openTable(NAMESPACE, METADATA_TABLE_NAME,
+                    LogReplicationSession.class,
+                            ReplicationMetadata.class,
                             null,
-                            TableOptions.fromProtoSchema(LogReplicationMetadataVal.class));
+                            TableOptions.fromProtoSchema(ReplicationMetadata.class));
 
-            this.replicationStatusTable = this.corfuStore.openTable(NAMESPACE,
-                            REPLICATION_STATUS_TABLE,
-                            ReplicationStatusKey.class,
-                            ReplicationStatusVal.class,
-                            null,
-                            TableOptions.fromProtoSchema(ReplicationStatusVal.class));
+            this.replicationStatusTable = this.corfuStore.openTable(NAMESPACE, REPLICATION_STATUS_TABLE_NAME,
+                    LogReplicationSession.class, ReplicationStatus.class, null,
+                    TableOptions.fromProtoSchema(ReplicationStatus.class));
 
-            this.replicationEventTable = this.corfuStore.openTable(NAMESPACE,
-                    REPLICATION_EVENT_TABLE_NAME,
+            this.replicationEventTable = this.corfuStore.openTable(NAMESPACE, REPLICATION_EVENT_TABLE_NAME,
                     ReplicationEventKey.class,
                     ReplicationEvent.class,
                     null,
                     TableOptions.fromProtoSchema(ReplicationEvent.class));
-
-            this.localClusterId = localClusterId;
         } catch (Exception e) {
-            log.error("Caught an exception while opening MetadataManagerTables ", e);
+            log.error("Caught an exception while opening metadata tables", e);
             throw new ReplicationWriterException(e);
         }
-        setupTopologyConfigId(topologyConfigId);
-    }
 
-    public TxnContext getTxnContext() {
-        return corfuStore.txn(NAMESPACE);
-    }
+        initializeMetadataTable(topologyDescriptor.getSessions(), topologyDescriptor.getTopologyConfigId(), logReplicatorVersion);
+        initializeStatusTable(topologyDescriptor.getSessions(), topologyDescriptor.getTopologyConfigId());
+        initializeEventTable(topologyDescriptor.getSessions(), topologyDescriptor.getTopologyConfigId());
 
-    private String queryString(LogReplicationMetadataType key) {
-        CorfuStoreEntry record;
-        LogReplicationMetadataKey txKey = LogReplicationMetadataKey.newBuilder().setKey(key.getVal()).build();
+        setupTopologyConfigId(topologyConfigId);
+    }
 
+    private void initializeMetadataTable(Set<LogReplicationSession> sessions, long topologyConfigId, String logReplicatorVersion) {
         try (TxnContext txn = corfuStore.txn(NAMESPACE)) {
-            record = txn.getRecord(metadataTableName, txKey);
-            txn.commit();
-        }
-
-        if (record.getPayload() != null) {
-            LogReplicationMetadataVal metadataVal = (LogReplicationMetadataVal)record.getPayload();
 
-            if (metadataVal != null) {
-                return metadataVal.getVal();
-            }
-        }
-
-        return null;
-    }
+            ReplicationMetadata initialMetadata = ReplicationMetadata.newBuilder()
+                    .setTopologyConfigId(topologyConfigId)
+                    .setVersion(logReplicatorVersion)
+                    .setLastLogEntryProcessed(Address.NON_ADDRESS)
+                    .setLastSnapshotTransferredSeqNumber(Address.NON_ADDRESS)
+                    .setLastSnapshotApplied(Address.NON_ADDRESS)
+                    .setLastSnapshotTransferred(Address.NON_ADDRESS)
+                    .setLastSnapshotStarted(Address.NON_ADDRESS)
+                    .setCurrentCycleMinShadowStreamTs(Address.NON_ADDRESS)
+                    .setRemainingReplicationPercent(0L)
+                    .build();
 
-    /**
-     * Query multiple Log Replication Metadata keys across the same timestamp
-     * TODO: this table should be reformatted such that metadata is accessed with a single RPC call (group keys)
-     *    this should be done later as it will require a data migration task
-     *
-     * @param keyTypes all metadata key types to query across the same timestamp
-     * @return
-     */
-    public Map<LogReplicationMetadataType, Long> queryMetadata(TxnContext txn, LogReplicationMetadataType... keyTypes) {
-        Map<LogReplicationMetadataType, Long> metadataMap = new HashMap<>();
+            ReplicationStatus initialStatus = ReplicationStatus.newBuilder()
+                    .setDataConsistent()
+                    .build();
 
-        CorfuStoreEntry record;
-        String stringValue;
-        for (LogReplicationMetadataType keyType : keyTypes) {
-            stringValue = null;
-                record = txn.getRecord(metadataTableName, LogReplicationMetadataKey.newBuilder().setKey(keyType.getVal()).build());
+            for (LogReplicationSession session : sessions) {
+                // Add an entry for this session if it does not exist, otherwise, this is a resuming/ongoing session
+                if (!txn.keySet(metadataTable).contains(session)) {
+                    log.debug("Adding entry for session={} in Replication Metadata Table", session);
+                    txn.putRecord(metadataTable, session, initialMetadata, null);
+                }
 
-            if (record.getPayload() != null) {
-                LogReplicationMetadataVal metadataValue = (LogReplicationMetadataVal) record.getPayload();
+                if(!txn.keySet(replicationStatusTable).contains(session)) {
+                    log.debug("Adding entry for session={} in Replication Status Table", session);
+                    txn.putRecord(replicationStatusTable, session, newMetadata, null);
+                }
 
-                if (metadataValue != null) {
-                    stringValue = metadataValue.getVal();
+                if(!txn.keySet(replicationEventTable).contains(session)) {
+                    log.debug("Adding entry for session={} in Replication Status Table", session);
+                    txn.putRecord(replicationEventTable, session, newMetadata, null);
                 }
             }
 
-            metadataMap.put(keyType, stringValue != null ? Long.parseLong(stringValue) : -1L);
-        }
-
-        return metadataMap;
-    }
-
-    public long queryMetadata(LogReplicationMetadataType key) {
-        long val = -1;
-        String str = queryString(key);
-        if (str != null) {
-            val = Long.parseLong(str);
+            txn.commit();
         }
-        return val;
     }
 
-    public long getTopologyConfigId() {
-        return queryMetadata(LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);
-    }
-
-    public String getVersion() {
-        return queryString(LogReplicationMetadataType.VERSION);
-    }
-
-    public long getLastStartedSnapshotTimestamp() {
-        return queryMetadata(LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);
+    public TxnContext getTxnContext() {
+        return corfuStore.txn(NAMESPACE);
     }
 
-    public long getLastTransferredSnapshotTimestamp() {
-        return queryMetadata(LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED);
-    }
+    // =========================== Replication Metadata Table Methods ===============================
 
-    public long getLastAppliedSnapshotTimestamp() {
-        return queryMetadata(LogReplicationMetadataType.LAST_SNAPSHOT_APPLIED);
-    }
+    /**
+     * Query the replication metadata / status for a given LR session
+     *
+     * @param session unique identifier for LR session
+     * @return replication metadata info
+     */
+    public ReplicationMetadata queryReplicationMetadata(LogReplicationSession session) {
+        ReplicationMetadata metadata;
 
-    public long getLastSnapshotTransferredSequenceNumber() {
-        return queryMetadata(LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED_SEQUENCE_NUMBER);
-    }
+        try (TxnContext txn = corfuStore.txn(NAMESPACE)) {
+            metadata = queryReplicationMetadata(txn, session);
+            txn.commit();
+        }
 
-    public long getLastProcessedLogEntryTimestamp() {
-        return queryMetadata(LogReplicationMetadataType.LAST_LOG_ENTRY_PROCESSED);
+        return metadata;
     }
 
-    public ResponseMsg getMetadataResponse(HeaderMsg header) {
-        LogReplication.LogReplicationMetadataResponseMsg metadataMsg = LogReplication.LogReplicationMetadataResponseMsg
-                .newBuilder()
-                .setTopologyConfigID(getTopologyConfigId())
-                .setVersion(getVersion())
-                .setSnapshotStart(getLastStartedSnapshotTimestamp())
-                .setSnapshotTransferred(getLastTransferredSnapshotTimestamp())
-                .setSnapshotApplied(getLastAppliedSnapshotTimestamp())
-                .setLastLogEntryTimestamp(getLastProcessedLogEntryTimestamp()).build();
-        CorfuMessage.ResponsePayloadMsg payload = CorfuMessage.ResponsePayloadMsg.newBuilder()
-                .setLrMetadataResponse(metadataMsg).build();
-        return getResponseMsg(header, payload);
+    /**
+     * Query the replication metadata / status as part of an ongoing transaction, for a given LR session
+     *
+     * @param txn open/ongoing transaction context
+     * @param session unique identifier of LR session
+     * @return replication metadata info for given session
+     */
+    public ReplicationMetadata queryReplicationMetadata(TxnContext txn, LogReplicationSession session) {
+        CorfuStoreEntry<LogReplicationSession, ReplicationMetadata, Message> record = txn.getRecord(METADATA_TABLE_NAME, session);
+        return record.getPayload();
     }
 
-    public void appendUpdate(TxnContext txn, LogReplicationMetadataType keyType, long val) {
-        appendUpdate(txn, keyType, LogReplicationMetadataVal.newBuilder().setVal(Long.toString(val)).build());
-    }
+    /**
+     * Update a single field of replication metadata for a given LR session as part of an ongoing transaction
+     *
+     * @param txn transaction context, for atomic commit
+     * @param session unique identifier for LR Session
+     * @param fieldNumber field number corresponding to attribute in replication metadata to be updated
+     * @param value value to update
+     */
+    public void updateReplicationMetadataField(TxnContext txn, LogReplicationSession session, int fieldNumber, Object value) {
+        Descriptors.FieldDescriptor fd = ReplicationMetadata.getDescriptor().findFieldByNumber(fieldNumber);
+        if (fd == null) {
+            log.error("Failed to find metadata field number {} in ReplicationMetadata object. Metadata is not UPDATED!", fieldNumber);
+            return;
+        }
+        CorfuStoreEntry<LogReplicationSession, ReplicationMetadata, Message> record = txn.getRecord(metadataTable, session);
+        ReplicationMetadata updatedMetadata = record.getPayload().toBuilder().setField(fd, value).build();
+        txn.putRecord(metadataTable, session, updatedMetadata, null);
 
-    private void appendUpdate(TxnContext txn, LogReplicationMetadataType keyType, String val) {
-        appendUpdate(txn, keyType, LogReplicationMetadataVal.newBuilder().setVal(val).build());
+        log.trace("Update metadata field {}, value={}", fd.getFullName(), value);
     }
 
-    private void appendUpdate(TxnContext txn, LogReplicationMetadataType keyType, LogReplicationMetadataVal value) {
-        LogReplicationMetadataKey key = LogReplicationMetadataKey.newBuilder().setKey(keyType.getVal()).build();
-        txn.putRecord(metadataTable, key, value, null);
+    /**
+     * Update replication metadata for a given LR session.
+     *
+     * @param txn transaction context, for atomic commit
+     * @param session unique identifier for LR Session
+     * @param metadata new replication metadata object
+     */
+    public void updateReplicationMetadata(TxnContext txn, LogReplicationSession session, ReplicationMetadata metadata) {
+        txn.putRecord(metadataTable, session, metadata, null);
     }
 
-    public void setupTopologyConfigId(long topologyConfigId) {
-        long persistedTopologyConfigId = queryMetadata(LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);
-
-        if (topologyConfigId <= persistedTopologyConfigId) {
-            log.warn("Skip setupTopologyConfigId. the current topologyConfigId {} is not larger than the persistedTopologyConfigID {}",
-                topologyConfigId, persistedTopologyConfigId);
-            return;
-        }
-
+    /**
+     * Set new topology config identifier which is common for all LR Sessions
+     *
+     * @param newTopologyConfigId
+     */
+    public void setupTopologyConfigId(long newTopologyConfigId) {
         try {
             IRetry.build(IntervalRetry.class, () -> {
+
                 try (TxnContext txn = corfuStore.txn(NAMESPACE)) {
-                    for (LogReplicationMetadataType type : LogReplicationMetadataType.values()) {
-                        if (type == LogReplicationMetadataType.TOPOLOGY_CONFIG_ID) {
-                            appendUpdate(txn, type, topologyConfigId);
-                        } else if (type == LogReplicationMetadataType.VERSION) {
-                            // TODO: We should update the version in metadata manager
-                            //  when the version is read from static file
-                            String version = LogReplicationConfigManager.getCurrentVersion();
-                            if (version == null) {
-                                log.error("Failed to fetch version from plugin.");
-                                appendUpdate(txn, type, Address.NON_ADDRESS);
-                            } else {
-                                appendUpdate(txn, type, version);
-                            }
+
+                    // TODO: should be set at the time of reading the config/version and thus copied from persisted data
+                    String version = LogReplicationConfigManager.getCurrentVersion() == null ? "" :
+                            LogReplicationConfigManager.getCurrentVersion();
+
+                    ReplicationMetadata newMetadata = ReplicationMetadata.newBuilder()
+                            .setTopologyConfigId(newTopologyConfigId)
+                            .setVersion(version)
+                            .setLastLogEntryProcessed(Address.NON_ADDRESS)
+                            .setLastSnapshotTransferredSeqNumber(Address.NON_ADDRESS)
+                            .setLastSnapshotApplied(Address.NON_ADDRESS)
+                            .setLastSnapshotTransferred(Address.NON_ADDRESS)
+                            .setLastSnapshotStarted(Address.NON_ADDRESS)
+                            .setCurrentCycleMinShadowStreamTs(Address.NON_ADDRESS)
+                            .setRemainingReplicationPercent(0L)
+                            .build();
+
+                    metadataTable.entryStream().forEach(entry -> {
+                        ReplicationMetadata currentMetadata = entry.getPayload();
+                        long currentTopologyConfigId = currentMetadata.getTopologyConfigId();
+
+                        if (newTopologyConfigId <= currentTopologyConfigId) {
+                            // TODO(AGMM): should we skip the rest as topology config id should be common or could it ever change for some sessions and others not
+                            log.warn("Skip stale topology config id for session={}. newTopologyConfigId={} <= currentTopologyConfigID={}",
+                                    entry.getKey(), newTopologyConfigId, currentTopologyConfigId);
                         } else {
-                            appendUpdate(txn, type, Address.NON_ADDRESS);
+                            txn.putRecord(metadataTable, entry.getKey(), newMetadata, entry.getMetadata());
                         }
-                    }
+                    });
+
                     txn.commit();
+                    log.info("Update topologyConfigId, new metadata for all sessions {}", newMetadata);
                 } catch (TransactionAbortedException e) {
-                    log.error("Exception when updating the topology config id",
-                        e);
+                    log.error("Exception when updating the topology config id", e);
                     throw new RetryNeededException();
                 }
-                log.info("Update topologyConfigId, new metadata {}", this);
                 return null;
             }).run();
         } catch (InterruptedException e) {
             log.error("Unrecoverable exception when updating the topology " +
-                "config id", e);
+                    "config id", e);
             throw new UnrecoverableCorfuInterruptedError(e);
         }
     }
@@ -284,49 +289,50 @@ public class LogReplicationMetadataManager {
      * Otherwise, update the base snapshot start timestamp. The update of topologyConfigId just fences off
      * any other metadata updates in other transactions.
      *
+     * @param session unique identifier for LR session
      * @param topologyConfigId current topologyConfigId
-     * @param ts snapshot start timestamp
+     * @param snapshotStartTs snapshot start timestamp
      * @return true, if succeeds
      *         false, otherwise
      */
-    public boolean setBaseSnapshotStart(long topologyConfigId, long ts) {
+    public boolean setBaseSnapshotStart(LogReplicationSession session, long topologyConfigId, long snapshotStartTs) {
+
+        ReplicationMetadata metadata;
+
         try (TxnContext txn = corfuStore.txn(NAMESPACE)) {
-            Map<LogReplicationMetadataType, Long> metadataMap = queryMetadata(txn, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID,
-                    LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);
-            long persistedTopologyConfigID = metadataMap.get(LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);
-            long persistedSnapshotStart = metadataMap.get(LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);
+
+            metadata = queryReplicationMetadata(txn, session);
 
             log.debug("Set snapshotStart topologyConfigId={}, ts={}, persistedTopologyConfigID={}, persistedSnapshotStart={}",
-                    topologyConfigId, ts, persistedTopologyConfigID, persistedSnapshotStart);
+                    topologyConfigId, snapshotStartTs, metadata.getTopologyConfigId(), metadata.getLastSnapshotStarted());
 
             // It means the cluster config has changed, ignore the update operation.
-            if (topologyConfigId != persistedTopologyConfigID) {
-                log.warn("Config differs between sender and receiver, sender[topologyConfigId={}, ts={}]" +
-                                " receiver[persistedTopologyConfigId={}, persistedSnapshotStart={}]", topologyConfigId, ts,
-                        persistedTopologyConfigID, persistedSnapshotStart);
+            if (topologyConfigId != metadata.getTopologyConfigId()) {
+                log.warn("Config differs between source and sink, Source[topologyConfigId={}, ts={}]" +
+                                " Sink[topologyConfigId={}, snapshotStart={}]", topologyConfigId,
+                        snapshotStartTs, metadata.getTopologyConfigId(), metadata.getLastSnapshotStarted());
                 return false;
             }
 
-            // Update the topologyConfigId to fence all other transactions that update the metadata at the same time
-            appendUpdate(txn, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID, topologyConfigId);
-
-            // Setup the LAST_LAST_SNAPSHOT_STARTED
-            appendUpdate(txn, LogReplicationMetadataType.LAST_SNAPSHOT_STARTED, ts);
-
-            // Reset other metadata
-            appendUpdate(txn, LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED, Address.NON_ADDRESS);
-            appendUpdate(txn, LogReplicationMetadataType.LAST_SNAPSHOT_APPLIED, Address.NON_ADDRESS);
-            appendUpdate(txn, LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED_SEQUENCE_NUMBER, Address.NON_ADDRESS);
-            appendUpdate(txn, LogReplicationMetadataType.LAST_LOG_ENTRY_PROCESSED, Address.NON_ADDRESS);
+            ReplicationMetadata updatedMetadata = metadata.toBuilder()
+                    .setTopologyConfigId(topologyConfigId)  // Update the topologyConfigId to fence all other txs
+                    // that update the metadata at the same time
+                    .setLastSnapshotStarted(snapshotStartTs)
+                    .setLastSnapshotTransferred(Address.NON_ADDRESS) // Reset other metadata fields
+                    .setLastSnapshotApplied(Address.NON_ADDRESS)
+                    .setLastSnapshotTransferredSeqNumber(Address.NON_ADDRESS)
+                    .setLastLogEntryProcessed(Address.NON_ADDRESS)
+                    .build();
 
+            updateReplicationMetadata(txn, session, updatedMetadata);
             txn.commit();
 
             log.debug("Commit. Set snapshotStart topologyConfigId={}, ts={}, persistedTopologyConfigID={}, " +
                             "persistedSnapshotStart={}",
-                    topologyConfigId, ts, persistedTopologyConfigID, persistedSnapshotStart);
+                    topologyConfigId, snapshotStartTs, metadata.getTopologyConfigId(), metadata.getLastSnapshotStarted());
         }
 
-        return (ts == getLastStartedSnapshotTimestamp() && topologyConfigId == getTopologyConfigId());
+        return (snapshotStartTs == metadata.getLastSnapshotStarted() && topologyConfigId == metadata.getTopologyConfigId());
     }
 
 
@@ -339,7 +345,7 @@ public class LogReplicationMetadataManager {
     public void setLastSnapshotTransferCompleteTimestamp(long topologyConfigId, long ts) {
         try (TxnContext txn = corfuStore.txn(NAMESPACE)) {
             // Read metadata & validate
-            Map<LogReplicationMetadataType, Long> metadataMap = queryMetadata(txn, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID,
+            Map<LogReplicationMetadataType, Long> metadataMap = queryReplicationMetadata(txn, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID,
                     LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);
             long persistedTopologyConfigId = metadataMap.get(LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);
             long persistedSnapshotStart = metadataMap.get(LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);
@@ -365,9 +371,9 @@ public class LogReplicationMetadataManager {
         log.debug("Commit snapshot transfer complete timestamp={}, for topologyConfigId={}", ts, topologyConfigId);
     }
 
-    public void setSnapshotAppliedComplete(LogReplication.LogReplicationEntryMsg entry) {
+    public void setSnapshotAppliedComplete(LogReplicationEntryMsg entry, String clusterId) {
         try (TxnContext txn = corfuStore.txn(NAMESPACE)) {
-            Map<LogReplicationMetadataType, Long> metadataMap = queryMetadata(txn, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID,
+            Map<LogReplicationMetadataType, Long> metadataMap = queryReplicationMetadata(txn, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID,
                     LogReplicationMetadataType.LAST_SNAPSHOT_STARTED, LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED);
             long persistedTopologyConfigId = metadataMap.get(LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);
             long persistedSnapshotStart = metadataMap.get(LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);
@@ -390,11 +396,11 @@ public class LogReplicationMetadataManager {
             // Set 'isDataConsistent' flag on replication status table atomically with snapshot sync completed
             // information, to prevent any inconsistency between flag and state of snapshot sync completion in
             // the event of crashes
-            ReplicationStatusVal statusValue = ReplicationStatusVal.newBuilder()
+            ReplicationStatus statusValue = ReplicationStatus.newBuilder()
                     .setDataConsistent(true)
                     .setStatus(SyncStatus.UNAVAILABLE)
                     .build();
-            txn.putRecord(replicationStatusTable, ReplicationStatusKey.newBuilder().setClusterId(localClusterId).build(),
+            txn.putRecord(replicationStatusTable, LogReplicationSession.newBuilder().setClusterId(clusterId).build(),
                     statusValue, null);
 
             txn.commit();
@@ -402,6 +408,79 @@ public class LogReplicationMetadataManager {
         }
     }
 
+    /**
+     * Set the snapshot sync start marker, i.e., a unique identification of the current snapshot sync cycle.
+     * Identified by the snapshot sync Id and the min shadow stream update timestamp for this cycle.
+     *
+     * @param session
+     * @param newSnapshotCycleId
+     * @param shadowStreamTs
+     */
+    public void setSnapshotSyncStartMarker(LogReplicationSession session, UUID newSnapshotCycleId,
+                                           CorfuStoreMetadata.Timestamp shadowStreamTs) {
+
+        try (TxnContext txn = corfuStore.txn(NAMESPACE)) {
+            ReplicationMetadata metadata = queryReplicationMetadata(txn, session);
+            UUID currentSnapshotCycleId = new UUID(metadata.getCurrentSnapshotCycleId().getMsb(), metadata.getCurrentSnapshotCycleId().getLsb());
+
+            // Update if current Snapshot Sync differs from the persisted one, otherwise ignore.
+            // It could have already been updated in the case that leader changed in between a snapshot sync cycle
+            if (currentSnapshotCycleId != newSnapshotCycleId) {
+                RpcCommon.UuidMsg uuidMsg = RpcCommon.UuidMsg.newBuilder()
+                        .setMsb(newSnapshotCycleId.getMostSignificantBits())
+                        .setLsb(newSnapshotCycleId.getLeastSignificantBits())
+                        .build();
+
+                ReplicationMetadata updatedMetadata = metadata.toBuilder()
+                        .setCurrentCycleMinShadowStreamTs(shadowStreamTs.getSequence())
+                        .setCurrentSnapshotCycleId(uuidMsg)
+                        .build();
+
+                updateReplicationMetadata(txn, session, updatedMetadata);
+            }
+            txn.commit();
+        }
+    }
+
+    // =============================== Replication Event Table Methods ===================================
+
+    /**
+     * Add log replication event
+     *
+     * Because a ReplicationEvent can be triggered from a lead or non-lead node, we persist it in CorfuDB
+     * for lead node to process accordingly.
+     *
+     * @param key
+     * @param event
+     */
+    public void addEvent(ReplicationEventKey key, ReplicationEvent event) {
+        log.info("Add event :: {}", event);
+        try (TxnContext txn = corfuStore.txn(NAMESPACE)) {
+            txn.putRecord(replicationEventTable, key, event, null);
+            txn.commit();
+        }
+    }
+
+    /**
+     * Subscribe to the logReplicationEventTable
+     *
+     * @param listener
+     */
+    public void subscribeReplicationEventTable(StreamListener listener) {
+        log.info("LogReplication start listener for table {}", REPLICATION_EVENT_TABLE_NAME);
+        corfuStore.subscribeListener(listener, NAMESPACE, LR_STREAM_TAG, Collections.singletonList(REPLICATION_EVENT_TABLE_NAME));
+    }
+
+    /**
+     * Unsubscribe the logReplicationEventTable
+     * @param listener
+     */
+    public void unsubscribeReplicationEventTable(StreamListener listener) {
+        corfuStore.unsubscribeListener(listener);
+    }
+
+    // ================================= Replication Status Table Methods ===================================
+
     /**
      * Update replication status table's snapshot sync info as ongoing.
      *
@@ -411,7 +490,7 @@ public class LogReplicationMetadataManager {
      */
     public void updateSnapshotSyncStatusOngoing(String clusterId, boolean forced, UUID eventId,
                                                 long baseVersion, long remainingEntries) {
-        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setClusterId(clusterId).build();
+        LogReplicationSession key = LogReplicationSession.newBuilder().setClusterId(clusterId).build();
 
         SnapshotSyncInfo.SnapshotSyncType syncType = forced ?
                 SnapshotSyncInfo.SnapshotSyncType.FORCED :
@@ -424,7 +503,7 @@ public class LogReplicationMetadataManager {
                 .setBaseSnapshot(baseVersion)
                 .build();
 
-        ReplicationStatusVal status = ReplicationStatusVal.newBuilder()
+        ReplicationStatus status = ReplicationStatus.newBuilder()
                 .setRemainingEntriesToSend(remainingEntries)
                 .setSyncType(SyncType.SNAPSHOT)
                 .setStatus(SyncStatus.ONGOING)
@@ -455,14 +534,14 @@ public class LogReplicationMetadataManager {
         Instant time = Instant.now();
         Timestamp timestamp = Timestamp.newBuilder().setSeconds(time.getEpochSecond())
                 .setNanos(time.getNano()).build();
-        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setClusterId(clusterId).build();
+        LogReplicationSession key = LogReplicationSession.newBuilder().setClusterId(clusterId).build();
 
         try (TxnContext txn = corfuStore.txn(NAMESPACE)) {
 
-            CorfuStoreEntry<ReplicationStatusKey, ReplicationStatusVal, Message> record = txn.getRecord(replicationStatusTable, key);
+            CorfuStoreEntry<LogReplicationSession, ReplicationStatus, Message> record = txn.getRecord(replicationStatusTable, key);
 
             if (record.getPayload() != null) {
-                ReplicationStatusVal previous = record.getPayload();
+                ReplicationStatus previous = record.getPayload();
                 SnapshotSyncInfo previousSyncInfo = previous.getSnapshotSyncInfo();
 
                 SnapshotSyncInfo currentSyncInfo = previousSyncInfo.toBuilder()
@@ -471,7 +550,7 @@ public class LogReplicationMetadataManager {
                         .setCompletedTime(timestamp)
                         .build();
 
-                ReplicationStatusVal current = ReplicationStatusVal.newBuilder()
+                ReplicationStatus current = ReplicationStatus.newBuilder()
                         .setRemainingEntriesToSend(remainingEntriesToSend)
                         .setSyncType(SyncType.LOG_ENTRY)
                         .setStatus(SyncStatus.ONGOING)
@@ -502,14 +581,14 @@ public class LogReplicationMetadataManager {
      * @param clusterId standby cluster id
      */
     public void updateSyncStatus(String clusterId, SyncType lastSyncType, SyncStatus status) {
-        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setClusterId(clusterId).build();
+        LogReplicationSession key = LogReplicationSession.newBuilder().setClusterId(clusterId).build();
 
         try (TxnContext txn = corfuStore.txn(NAMESPACE)) {
 
-            CorfuStoreEntry<ReplicationStatusKey, ReplicationStatusVal, Message> record = txn.getRecord(replicationStatusTable, key);
+            CorfuStoreEntry<LogReplicationSession, ReplicationStatus, Message> record = txn.getRecord(replicationStatusTable, key);
 
-            ReplicationStatusVal previous = record.getPayload() != null ? record.getPayload() : ReplicationStatusVal.newBuilder().build();
-            ReplicationStatusVal current;
+            ReplicationStatus previous = record.getPayload() != null ? record.getPayload() : ReplicationStatus.newBuilder().build();
+            ReplicationStatus current;
 
             if (lastSyncType.equals(SyncType.LOG_ENTRY)) {
                 current = previous.toBuilder().setSyncType(SyncType.LOG_ENTRY).setStatus(status).build();
@@ -537,13 +616,13 @@ public class LogReplicationMetadataManager {
      * @param type sync type
      */
     public void setReplicationStatusTable(String clusterId, long remainingEntries, SyncType type) {
-        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setClusterId(clusterId).build();
+        LogReplicationSession key = LogReplicationSession.newBuilder().setClusterId(clusterId).build();
         SnapshotSyncInfo snapshotStatus = null;
-        ReplicationStatusVal current;
-        ReplicationStatusVal previous = null;
+        ReplicationStatus current;
+        ReplicationStatus previous = null;
 
         try (TxnContext txn = corfuStore.txn(NAMESPACE)) {
-            CorfuStoreEntry<ReplicationStatusKey, ReplicationStatusVal, Message> record = txn.getRecord(replicationStatusTable, key);
+            CorfuStoreEntry<LogReplicationSession, ReplicationStatus, Message> record = txn.getRecord(replicationStatusTable, key);
             if (record.getPayload() != null) {
                 previous = record.getPayload();
                 snapshotStatus = previous.getSnapshotSyncInfo();
@@ -565,7 +644,7 @@ public class LogReplicationMetadataManager {
                 snapshotStatus = SnapshotSyncInfo.newBuilder().build();
             }
 
-            current = ReplicationStatusVal.newBuilder()
+            current = ReplicationStatus.newBuilder()
                     .setRemainingEntriesToSend(remainingEntries)
                     .setSyncType(type)
                     .setStatus(SyncStatus.ONGOING)
@@ -599,7 +678,7 @@ public class LogReplicationMetadataManager {
                         .build();
             }
 
-            current = ReplicationStatusVal.newBuilder()
+            current = ReplicationStatus.newBuilder()
                     .setRemainingEntriesToSend(remainingEntries)
                     .setSyncType(type)
                     .setStatus(SyncStatus.ONGOING)
@@ -616,17 +695,21 @@ public class LogReplicationMetadataManager {
         }
     }
 
-    public Map<String, ReplicationStatusVal> getReplicationRemainingEntries() {
-        Map<String, ReplicationStatusVal> replicationStatusMap = new HashMap<>();
-        List<CorfuStoreEntry<ReplicationStatusKey, ReplicationStatusVal, Message>> entries;
+    /**
+     *
+     * @return
+     */
+    public Map<String, ReplicationStatus> getReplicationRemainingEntries() {
+        Map<String, ReplicationStatus> replicationStatusMap = new HashMap<>();
+        List<CorfuStoreEntry<LogReplicationSession, ReplicationStatus, Message>> entries;
         try (TxnContext txn = corfuStore.txn(NAMESPACE)) {
             entries = txn.executeQuery(replicationStatusTable, record -> true);
             txn.commit();
         }
 
-        for (CorfuStoreEntry<ReplicationStatusKey, ReplicationStatusVal, Message> entry : entries) {
+        for (CorfuStoreEntry<LogReplicationSession, ReplicationStatus, Message> entry : entries) {
             String clusterId = entry.getKey().getClusterId();
-            ReplicationStatusVal value = entry.getPayload();
+            ReplicationStatus value = entry.getPayload();
             replicationStatusMap.put(clusterId, value);
             log.debug("getReplicationRemainingEntries: clusterId={}, remainingEntriesToSend={}, " +
                     "syncType={}, is_consistent={}", clusterId, value.getRemainingEntriesToSend(),
@@ -645,9 +728,9 @@ public class LogReplicationMetadataManager {
      *
      * @param isConsistent data is consistent or not
      */
-    public void setDataConsistentOnStandby(boolean isConsistent) {
-        ReplicationStatusKey key = ReplicationStatusKey.newBuilder().setClusterId(localClusterId).build();
-        ReplicationStatusVal val = ReplicationStatusVal.newBuilder()
+    public void setDataConsistentOnStandby(boolean isConsistent, String clusterId) {
+        LogReplicationSession key = LogReplicationSession.newBuilder().setClusterId(clusterId).build();
+        ReplicationStatus val = ReplicationStatus.newBuilder()
                 .setDataConsistent(isConsistent)
                 .setStatus(SyncStatus.UNAVAILABLE)
                 .build();
@@ -656,174 +739,98 @@ public class LogReplicationMetadataManager {
             txn.commit();
         }
 
-        log.debug("setDataConsistentOnStandby: localClusterId: {}, isConsistent: {}", localClusterId, isConsistent);
+        log.debug("setDataConsistentOnStandby: localClusterId: {}, isConsistent: {}", clusterId, isConsistent);
     }
 
-    public Map<String, ReplicationStatusVal> getDataConsistentOnStandby() {
-        CorfuStoreEntry<ReplicationStatusKey, ReplicationStatusVal, Message> record;
-        ReplicationStatusVal statusVal;
+    /**
+     *
+     * @param clusterId
+     * @return
+     */
+    public Map<String, ReplicationStatus> getDataConsistentOnStandby(String clusterId) {
+        CorfuStoreEntry<LogReplicationSession, ReplicationStatus, Message> record;
+        ReplicationStatus statusVal;
 
         try (TxnContext txn = corfuStore.txn(NAMESPACE)) {
-            record = txn.getRecord(replicationStatusTable, ReplicationStatusKey.newBuilder().setClusterId(localClusterId).build());
+            record = txn.getRecord(replicationStatusTable, LogReplicationSession.newBuilder().setClusterId(clusterId).build());
             txn.commit();
         }
 
         // Initially, snapshot sync is pending so the data is not consistent.
         if (record.getPayload() == null) {
-            log.warn("DataConsistent status is not set for local cluster {}", localClusterId);
-            statusVal = ReplicationStatusVal.newBuilder().setDataConsistent(false).build();
+            log.warn("DataConsistent status is not set for local cluster {}", clusterId);
+            statusVal = ReplicationStatus.newBuilder().setDataConsistent(false).build();
         } else {
             statusVal = record.getPayload();
         }
-        Map<String, ReplicationStatusVal> dataConsistentMap = new HashMap<>();
-        dataConsistentMap.put(localClusterId, statusVal);
+        Map<String, ReplicationStatus> dataConsistentMap = new HashMap<>();
+        dataConsistentMap.put(clusterId, statusVal);
 
-        log.debug("getDataConsistentOnStandby: localClusterId: {}, statusVal: {}", localClusterId, statusVal);
+        log.debug("getDataConsistentOnStandby: localClusterId: {}, statusVal: {}", clusterId, statusVal);
 
         return dataConsistentMap;
     }
 
+    /**
+     * Reset replication status for all sessions
+     */
     public void resetReplicationStatus() {
-        log.info("syncStatus :: reset replication status");
-        try (TxnContext tx = corfuStore.txn(replicationStatusTable.getNamespace())) {
+        log.info("Reset replication status for all LR sessions");
+        try (TxnContext tx = corfuStore.txn(NAMESPACE)) {
             replicationStatusTable.clearAll();
             tx.commit();
         }
     }
 
-    @Override
-    public String toString() {
-        StringBuilder builder = new StringBuilder();
-        for (LogReplicationMetadataType type : LogReplicationMetadataType.values()) {
-            builder.append(type).append(": ");
-            switch (type) {
-                case TOPOLOGY_CONFIG_ID:
-                    builder.append(getTopologyConfigId());
-                    break;
-                case LAST_SNAPSHOT_STARTED:
-                   builder.append(getLastStartedSnapshotTimestamp());
-                   break;
-                case LAST_SNAPSHOT_TRANSFERRED:
-                   builder.append(getLastTransferredSnapshotTimestamp());
-                   break;
-                case LAST_SNAPSHOT_APPLIED:
-                   builder.append(getLastAppliedSnapshotTimestamp());
-                   break;
-                case LAST_SNAPSHOT_TRANSFERRED_SEQUENCE_NUMBER:
-                   builder.append(getLastSnapshotTransferredSequenceNumber());
-                   break;
-                case LAST_LOG_ENTRY_PROCESSED:
-                   builder.append(getLastProcessedLogEntryTimestamp());
-                   break;
-                default:
-                    // error
-            }
-            builder.append(" ");
-        }
-        builder.append("Replication Completion: ");
-        Map<String, ReplicationStatusVal> replicationStatusMap = getReplicationRemainingEntries();
-        replicationStatusMap.entrySet().forEach( entry -> builder.append(entry.getKey())
-                .append(entry.getValue().getRemainingEntriesToSend()));
-
-        builder.append("Data Consistent: ").append(getDataConsistentOnStandby());
-        return builder.toString();
-    }
-
-    public static String getPersistedWriterMetadataTableName(String localClusterId) {
-        return METADATA_TABLE_PREFIX_NAME + localClusterId;
-    }
+//    @Override
+//    public String toString() {
+//        StringBuilder builder = new StringBuilder();
+//        for (LogReplicationMetadataType type : LogReplicationMetadataType.values()) {
+//            builder.append(type).append(": ");
+//            switch (type) {
+//                case TOPOLOGY_CONFIG_ID:
+//                    builder.append(getTopologyConfigId());
+//                    break;
+//                case LAST_SNAPSHOT_STARTED:
+//                   builder.append(getLastStartedSnapshotTimestamp());
+//                   break;
+//                case LAST_SNAPSHOT_TRANSFERRED:
+//                   builder.append(getLastTransferredSnapshotTimestamp());
+//                   break;
+//                case LAST_SNAPSHOT_APPLIED:
+//                   builder.append(getLastAppliedSnapshotTimestamp());
+//                   break;
+//                case LAST_SNAPSHOT_TRANSFERRED_SEQUENCE_NUMBER:
+//                   builder.append(getLastSnapshotTransferredSequenceNumber());
+//                   break;
+//                case LAST_LOG_ENTRY_PROCESSED:
+//                   builder.append(getLastProcessedLogEntryTimestamp());
+//                   break;
+//                default:
+//                    // error
+//            }
+//            builder.append(" ");
+//        }
+//        builder.append("Replication Completion: ");
+//        Map<String, ReplicationStatus> replicationStatusMap = getReplicationRemainingEntries();
+//        replicationStatusMap.entrySet().forEach( entry -> builder.append(entry.getKey())
+//                .append(entry.getValue().getRemainingEntriesToSend()));
+//
+//        // builder.append("Data Consistent: ").append(getDataConsistentOnStandby());
+//        return builder.toString();
+//    }
+
+
+    // ================================ Runtime Helper Functions ======================================
 
     public long getLogHead() {
         return runtime.getAddressSpaceView().getTrimMark().getSequence();
     }
 
-    /**
-     * Set the snapshot sync start marker, i.e., a unique identification of the current snapshot sync cycle.
-     * Identified by the snapshot sync Id and the min shadow stream update timestamp for this cycle.
-     *
-     * @param currentSnapshotSyncId
-     * @param shadowStreamTs
-     */
-    public void setSnapshotSyncStartMarker(TxnContext txn, UUID currentSnapshotSyncId, CorfuStoreMetadata.Timestamp shadowStreamTs) {
-
-        long currentSnapshotSyncIdLong = currentSnapshotSyncId.getMostSignificantBits() & Long.MAX_VALUE;
-        long persistedSnapshotId = queryMetadata(txn, LogReplicationMetadataType.CURRENT_SNAPSHOT_CYCLE_ID).get(LogReplicationMetadataType.CURRENT_SNAPSHOT_CYCLE_ID);
-
-        if (persistedSnapshotId != currentSnapshotSyncIdLong) {
-            // Update if current Snapshot Sync differs from the persisted one, otherwise ignore.
-            // It could have already been updated in the case that leader changed in between a snapshot sync cycle
-            appendUpdate(txn, LogReplicationMetadataType.CURRENT_SNAPSHOT_CYCLE_ID, currentSnapshotSyncIdLong);
-            appendUpdate(txn, LogReplicationMetadataType.CURRENT_CYCLE_MIN_SHADOW_STREAM_TS, shadowStreamTs.getSequence());
-        }
-    }
-
-    /**
-     * Retrieve the snapshot sync start marker
-     **/
-    public long getMinSnapshotSyncShadowStreamTs() {
-        return queryMetadata(LogReplicationMetadataType.CURRENT_CYCLE_MIN_SHADOW_STREAM_TS);
-    }
-
-    /**
-     * Retrieve the current snapshot sync cycle Id
-     */
-    public long getCurrentSnapshotSyncCycleId() {
-        return queryMetadata(LogReplicationMetadataType.CURRENT_SNAPSHOT_CYCLE_ID);
-    }
-
-    /**
-     * Interface to write an event to the logReplicationEventTable.
-     * @param key
-     * @param event
-     */
-    public void updateLogReplicationEventTable(ReplicationEventKey key, ReplicationEvent event) {
-        log.info("UpdateReplicationEvent {} with event {}", REPLICATION_EVENT_TABLE_NAME, event);
-        try (TxnContext txn = corfuStore.txn(NAMESPACE)) {
-            txn.putRecord(replicationEventTable, key, event, null);
-            txn.commit();
-        }
-    }
-
-    /**
-     * Subscribe to the logReplicationEventTable
-     * @param listener
-     */
-    public void subscribeReplicationEventTable(StreamListener listener) {
-        log.info("LogReplication start listener for table {}", REPLICATION_EVENT_TABLE_NAME);
-        corfuStore.subscribeListener(listener, NAMESPACE, LR_STREAM_TAG, Collections.singletonList(REPLICATION_EVENT_TABLE_NAME));
-    }
+    // ================================ End Runtime Helper Functions ==================================
 
-    /**
-     * Unsubscribe the logReplicationEventTable
-     * @param listener
-     */
-    public void unsubscribeReplicationEventTable(StreamListener listener) {
-        corfuStore.unsubscribeListener(listener);
-    }
 
     public void shutdown() {
         // No-Op
     }
-
-    public enum LogReplicationMetadataType {
-        TOPOLOGY_CONFIG_ID("topologyConfigId"),
-        VERSION("version"),
-        LAST_SNAPSHOT_STARTED("lastSnapshotStarted"),
-        LAST_SNAPSHOT_TRANSFERRED("lastSnapshotTransferred"),
-        LAST_SNAPSHOT_APPLIED("lastSnapshotApplied"),
-        LAST_SNAPSHOT_TRANSFERRED_SEQUENCE_NUMBER("lastSnapshotTransferredSeqNumber"),
-        CURRENT_SNAPSHOT_CYCLE_ID("currentSnapshotCycleId"),
-        CURRENT_CYCLE_MIN_SHADOW_STREAM_TS("minShadowStreamTimestamp"),
-        LAST_LOG_ENTRY_PROCESSED("lastLogEntryProcessed"),
-        REMAINING_REPLICATION_PERCENT("replicationStatus"),
-        DATA_CONSISTENT_ON_STANDBY("dataConsistentOnStandby"),
-        SNAPSHOT_SYNC_TYPE("snapshotSyncType"),
-        SNAPSHOT_SYNC_COMPLETE_TIME("snapshotSyncCompleteTime");
-
-        @Getter
-        String val;
-        LogReplicationMetadataType(String newVal) {
-            val  = newVal;
-        }
-    }
 }
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java
index a301756608e..544c85dfd5b 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/LogReplicationSinkManager.java
@@ -11,8 +11,11 @@ import org.corfudb.infrastructure.ServerContext;
 import org.corfudb.infrastructure.logreplication.LogReplicationConfig;
 import org.corfudb.infrastructure.logreplication.infrastructure.plugins.ISnapshotSyncPlugin;
 import org.corfudb.infrastructure.logreplication.infrastructure.plugins.LogReplicationPluginConfig;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationMetadata;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationSession;
 import org.corfudb.runtime.CorfuRuntime;
 import org.corfudb.runtime.LogReplication;
+import org.corfudb.runtime.LogReplication.LogReplicationEntryMsg;
 import org.corfudb.runtime.LogReplication.LogReplicationEntryMetadataMsg;
 import org.corfudb.runtime.LogReplication.LogReplicationEntryType;
 import org.corfudb.runtime.exceptions.TransactionAbortedException;
@@ -46,6 +49,7 @@ import static org.corfudb.protocols.service.CorfuProtocolLogReplication.getLrEnt
  * */
 @Slf4j
 public class LogReplicationSinkManager implements DataReceiver {
+
     /*
      * Read SinkManager configuration information from a file.
      * If the file is not available, use the default values.
@@ -54,6 +58,8 @@ public class LogReplicationSinkManager implements DataReceiver {
 
     private static final int DEFAULT_ACK_CNT = 1;
 
+    private final LogReplicationSession session;
+
     // Duration in milliseconds after which an ACK is sent back to the sender
     // if the message count is not reached before
     private int ackCycleTime = DEFAULT_ACK_CNT;
@@ -101,16 +107,18 @@ public class LogReplicationSinkManager implements DataReceiver {
     private final AtomicBoolean ongoingApply = new AtomicBoolean(false);
 
     /**
-     * Constructor Sink Manager
+     * Constructor
      *
      * @param localCorfuEndpoint endpoint for local corfu server
      * @param config log replication configuration
-     * @param metadataManager
-     * @param context
+     * @param metadataManager manages log replication session's metadata
+     * @param context server level context
+     * @param topologyConfigId log replication topology epoch
+     * @param session log replication session unique identifier
      */
     public LogReplicationSinkManager(String localCorfuEndpoint, LogReplicationConfig config,
                                      LogReplicationMetadataManager metadataManager,
-                                     ServerContext context, long topologyConfigId) {
+                                     ServerContext context, long topologyConfigId, LogReplicationSession session) {
 
         this.runtime = CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder()
                 .trustStore((String) context.getServerConfig().get(ConfigParamNames.TRUST_STORE))
@@ -124,7 +132,10 @@ public class LogReplicationSinkManager implements DataReceiver {
                 .parseConfigurationString(localCorfuEndpoint).connect();
         this.pluginConfigFilePath = context.getPluginConfigFilePath();
         this.topologyConfigId = topologyConfigId;
-        init(metadataManager, config);
+        this.session = session;
+        this.logReplicationMetadataManager = metadataManager;
+        this.config = config;
+        init();
     }
 
     /**
@@ -135,25 +146,23 @@ public class LogReplicationSinkManager implements DataReceiver {
      */
     @VisibleForTesting
     public LogReplicationSinkManager(String localCorfuEndpoint, LogReplicationConfig config,
-                                     LogReplicationMetadataManager metadataManager, String pluginConfigFilePath) {
+                                     LogReplicationMetadataManager metadataManager, String pluginConfigFilePath,
+                                     LogReplicationSession session) {
         this.runtime =  CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder()
                 .maxCacheEntries(config.getMaxCacheSize())
                 .build())
                 .parseConfigurationString(localCorfuEndpoint).connect();
         this.pluginConfigFilePath = pluginConfigFilePath;
-        init(metadataManager, config);
+        this.session = session;
+        this.logReplicationMetadataManager = metadataManager;
+        this.config = config;
+        init();
     }
 
     /**
      * Initialize common parameters
-     *
-     * @param metadataManager metadata manager instance
-     * @param config log replication configuration
      */
-    private void init(LogReplicationMetadataManager metadataManager, LogReplicationConfig config) {
-        this.logReplicationMetadataManager = metadataManager;
-        this.config = config;
-
+    private void init() {
         // When the server is up, it will be at LOG_ENTRY_SYNC state by default.
         // The sender will query receiver's status and decide what type of replication to start with.
         // It will transit to SNAPSHOT_SYNC state if it received a SNAPSHOT_START message from the sender.
@@ -172,7 +181,7 @@ public class LogReplicationSinkManager implements DataReceiver {
         try {
             IRetry.build(IntervalRetry.class, () -> {
                 try {
-                    logReplicationMetadataManager.setDataConsistentOnStandby(isDataConsistent);
+                    logReplicationMetadataManager.setDataConsistentOnStandby(isDataConsistent, session);
                 } catch (TransactionAbortedException tae) {
                     log.error("Error while attempting to setDataConsistent in SinkManager's init", tae);
                     throw new RetryNeededException();
@@ -198,14 +207,14 @@ public class LogReplicationSinkManager implements DataReceiver {
         // Instantiate Snapshot Sync Plugin, this is an external service which will be triggered on start and end
         // of a snapshot sync.
         snapshotSyncPlugin = getOnSnapshotSyncPlugin();
-
-        snapshotWriter = new StreamsSnapshotWriter(runtime, config, logReplicationMetadataManager);
-        logEntryWriter = new LogEntryWriter(config, logReplicationMetadataManager);
-        logEntryWriter.reset(logReplicationMetadataManager.getLastAppliedSnapshotTimestamp(),
-                logReplicationMetadataManager.getLastProcessedLogEntryTimestamp());
-
+        snapshotWriter = new StreamsSnapshotWriter(runtime, config, logReplicationMetadataManager, session);
+        logEntryWriter = new LogEntryWriter(config, logReplicationMetadataManager, session);
         logEntrySinkBufferManager = new LogEntrySinkBufferManager(ackCycleTime, ackCycleCnt, bufferSize,
-                logReplicationMetadataManager.getLastProcessedLogEntryTimestamp(), this);
+                logReplicationMetadataManager.queryReplicationMetadata(session).getLastLogEntryProcessed(),
+                this);
+
+        // TODO(AGMM): I believe the SnapshotSinkManager should be initialized here with NON_ADDRESS.. and reset
+        // to metadata last processedTs, whenever it resumes
     }
 
     private ISnapshotSyncPlugin getOnSnapshotSyncPlugin() {
@@ -226,6 +235,7 @@ public class LogReplicationSinkManager implements DataReceiver {
      * If the configFile doesn't exist, use the default values.
      */
     private void readConfig() {
+        //TODO(AGMM): I believe this should come from the LogReplicationServerContext
         File configFile = new File(CONFIG_FILE);
         try {
             FileReader reader = new FileReader(configFile);
@@ -236,7 +246,7 @@ public class LogReplicationSinkManager implements DataReceiver {
             ackCycleTime = Integer.parseInt(props.getProperty("log_writer_ack_cycle_time", Integer.toString(ackCycleTime)));
             reader.close();
         } catch (FileNotFoundException e) {
-            log.warn("Config file {} does not exist.  Using default configs", CONFIG_FILE);
+            log.warn("Config file {} does not exist. Using default configs", CONFIG_FILE);
         } catch (IOException e) {
             log.error("IO Exception when reading config file", e);
         }
@@ -283,7 +293,7 @@ public class LogReplicationSinkManager implements DataReceiver {
 
         if (!receivedValidMessage(message)) {
             // It is possible that the sender doesn't receive the SNAPSHOT_TRANSFER_COMPLETE ack message and
-            // sends the SNAPSHOT_END marker again, but the receiver has already transited to
+            // sends the SNAPSHOT_END marker again, but the receiver has already transitioned to
             // the LOG_ENTRY_SYNC state.
             // In this case send the SNAPSHOT_TRANSFER_COMPLETE ack again so the sender can do the proper transition.
             if (message.getMetadata().getEntryType() == LogReplicationEntryType.SNAPSHOT_END) {
@@ -320,9 +330,11 @@ public class LogReplicationSinkManager implements DataReceiver {
     }
 
     private void processSnapshotSyncApplied(LogReplication.LogReplicationEntryMsg entry) {
-        long lastAppliedBaseSnapshotTimestamp = logReplicationMetadataManager.getLastAppliedSnapshotTimestamp();
-        long latestSnapshotSyncCycleId = logReplicationMetadataManager.getCurrentSnapshotSyncCycleId();
+        ReplicationMetadata metadata = logReplicationMetadataManager.queryReplicationMetadata(session);
+        long lastAppliedBaseSnapshotTimestamp = metadata.getLastSnapshotApplied();
+        long latestSnapshotSyncCycleId = metadata.getCurrentSnapshotCycleId();
         long ackSnapshotSyncCycleId = entry.getMetadata().getSyncRequestId().getMsb() & Long.MAX_VALUE;
+
         // Verify this snapshot ACK corresponds to the last initialized/valid snapshot sync
         // as a previous one could have been canceled but still processed due to messages being out of order
         if ((ackSnapshotSyncCycleId == latestSnapshotSyncCycleId) &&
@@ -367,12 +379,12 @@ public class LogReplicationSinkManager implements DataReceiver {
             return false;
         }
 
-        // Fails to set the baseSnapshot at the metadata store, it could be a out of date message,
+        // Fails to set the baseSnapshot at the metadata store, it could be an out of date message,
         // or the current node is out of sync, ignore it.
-        if (!logReplicationMetadataManager.setBaseSnapshotStart(topologyConfigId, messageBaseSnapshot)) {
+        if (!logReplicationMetadataManager.setBaseSnapshotStart(session, topologyConfigId, messageBaseSnapshot)) {
             log.warn("Sink Manager in state {} and received message {}. " +
-                            "Dropping Message due to failure to update the metadata store {}",
-                    rxState, entry.getMetadata(), logReplicationMetadataManager);
+                            "Dropping message due to failure to update the metadata store.",
+                    rxState, entry.getMetadata());
             return false;
         }
 
@@ -388,24 +400,21 @@ public class LogReplicationSinkManager implements DataReceiver {
      *
      * @param entry a SNAPSHOT_START message
      */
-    private void processSnapshotStart(LogReplication.LogReplicationEntryMsg entry) {
-        long topologyId = entry.getMetadata().getTopologyConfigID();
-        long timestamp = entry.getMetadata().getSnapshotTimestamp();
-
-        // Signal start of snapshot sync to the writer, so data can be cleared (on old snapshot syncs)
-        snapshotWriter.reset(topologyId, timestamp);
-
-        // Update lastTransferDone with the new snapshot transfer timestamp.
+    private void processSnapshotStart(LogReplicationEntryMsg entry) {
         baseSnapshotTimestamp = entry.getMetadata().getSnapshotTimestamp();
 
-        // Setup buffer manager.
+        // Signal start of snapshot sync to the writer, so data can be cleared (on old snapshot syncs)
+        snapshotWriter.reset(entry.getMetadata().getTopologyConfigID(), baseSnapshotTimestamp);
+        // TODO(AGMM): I believe this is always a fresh start so we don't need to pass the metadata last transferred, test
+        // it and if not pass instead logReplicationMetadataManager.getLastSnapshotTransferredSequenceNumber()
+        //TODO(AGMM): I belive there is a bug, if the sink crashes and it was in the middle of a snapshot cycle,
+        // a SNAPSHOT_START message won't come ad sso the Buffer won't be ever created and we'll get a NPE
         snapshotSinkBufferManager = new SnapshotSinkBufferManager(ackCycleTime, ackCycleCnt, bufferSize,
-                logReplicationMetadataManager.getLastSnapshotTransferredSequenceNumber(), this);
-
-        // Set state in SNAPSHOT_SYNC state.
+                Address.NON_ADDRESS, this);
         rxState = RxState.SNAPSHOT_SYNC;
-        log.info("Sink manager entry {} state, snapshot start with {}",
-                rxState, TextFormat.shortDebugString(entry.getMetadata()));
+
+        log.info("Sink manager entry {} state, snapshot start with {}", rxState,
+                TextFormat.shortDebugString(entry.getMetadata()));
     }
 
     /**
@@ -417,7 +426,7 @@ public class LogReplicationSinkManager implements DataReceiver {
         try {
             IRetry.build(IntervalRetry.class, () -> {
                 try {
-                    logReplicationMetadataManager.setSnapshotAppliedComplete(entry);
+                    logReplicationMetadataManager.setSnapshotAppliedComplete(entry, session.getClusterId());
                 } catch (TransactionAbortedException tae) {
                     log.error("Error while attempting to set SNAPSHOT_SYNC as completed.", tae);
                     throw new RetryNeededException();
@@ -432,8 +441,9 @@ public class LogReplicationSinkManager implements DataReceiver {
         processSnapshotSyncApplied(entry);
 
         rxState = RxState.LOG_ENTRY_SYNC;
+        //TODO(AGMM): It seems this is creatig the LogEntrySink on completion of full sync, so last processed log entry should be nothing
         logEntrySinkBufferManager = new LogEntrySinkBufferManager(ackCycleTime, ackCycleCnt, bufferSize,
-                logReplicationMetadataManager.getLastProcessedLogEntryTimestamp(), this);
+                entry.getMetadata().getSnapshotTimestamp(), this);
         logEntryWriter.reset(entry.getMetadata().getSnapshotTimestamp(), entry.getMetadata().getSnapshotTimestamp());
 
         log.info("Snapshot apply complete, sync_id={}, snapshot={}, state={}", entry.getMetadata().getSyncRequestId(),
@@ -462,18 +472,17 @@ public class LogReplicationSinkManager implements DataReceiver {
         }
     }
 
-    private synchronized void startSnapshotApplyAsync(LogReplication.LogReplicationEntryMsg entry) {
+    private synchronized void startSnapshotApplyAsync(LogReplicationEntryMsg entry) {
         if (!ongoingApply.get()) {
             ongoingApply.set(true);
             applyExecutor.submit(() -> startSnapshotApply(entry));
         }
     }
 
-    private synchronized void startSnapshotApply(LogReplication.LogReplicationEntryMsg entry) {
+    private synchronized void startSnapshotApply(LogReplicationEntryMsg entry) {
         log.debug("Entry Start Snapshot Sync Apply, id={}", entry.getMetadata().getSyncRequestId());
-        // set data_consistent as false
-        setDataConsistentWithRetry(false);
 
+        setDataConsistentWithRetry(false);
         snapshotWriter.clearLocalStreams();
         snapshotWriter.startSnapshotSyncApply();
         completeSnapshotApply(entry);
@@ -539,14 +548,13 @@ public class LogReplicationSinkManager implements DataReceiver {
      *
      * */
     public void reset() {
-        long lastAppliedSnapshotTimestamp = logReplicationMetadataManager.getLastAppliedSnapshotTimestamp();
-        long lastProcessedLogEntryTimestamp = logReplicationMetadataManager.getLastProcessedLogEntryTimestamp();
-        log.debug("Reset Sink Manager, lastAppliedSnapshotTs={}, lastProcessedLogEntryTs={}", lastAppliedSnapshotTimestamp,
-                lastProcessedLogEntryTimestamp);
-        snapshotWriter.reset(topologyConfigId, lastAppliedSnapshotTimestamp);
-        logEntryWriter.reset(lastAppliedSnapshotTimestamp, lastProcessedLogEntryTimestamp);
+        ReplicationMetadata metadata = logReplicationMetadataManager.queryReplicationMetadata(session);
+        log.debug("Reset Sink Manager, lastAppliedSnapshotTs={}, lastProcessedLogEntryTs={}", metadata.getLastSnapshotApplied(),
+                metadata.getLastLogEntryProcessed());
+        snapshotWriter.reset(topologyConfigId, metadata.getLastSnapshotApplied());
+        logEntryWriter.reset(metadata.getLastSnapshotApplied(), metadata.getLastLogEntryProcessed());
         logEntrySinkBufferManager = new LogEntrySinkBufferManager(ackCycleTime, ackCycleCnt, bufferSize,
-                lastProcessedLogEntryTimestamp, this);
+                metadata.getLastLogEntryProcessed(), this);
     }
 
     public void shutdown() {
@@ -559,20 +567,23 @@ public class LogReplicationSinkManager implements DataReceiver {
      *
      * In the event of restarts, a Snapshot Sync which had finished transfer can resume the apply stage.
      */
-    public void resumeSnapshotApply() {
+    private void resumeSnapshotApply(ReplicationMetadata metadata) {
         // Signal start of snapshot sync to the writer, so data can be cleared (on old snapshot syncs)
-        snapshotWriter.reset(topologyConfigId, logReplicationMetadataManager.getLastStartedSnapshotTimestamp());
-        long snapshotTransferTs = logReplicationMetadataManager.getLastTransferredSnapshotTimestamp();
-        UUID snapshotSyncId = new UUID(logReplicationMetadataManager.getCurrentSnapshotSyncCycleId(), Long.MAX_VALUE);
+        snapshotWriter.reset(topologyConfigId, logReplicationMetadataManager.queryReplicationMetadata(session).getLastSnapshotStarted());
+
+        long snapshotTransferTs = metadata.getLastSnapshotTransferred();
+        // TODO(AGMM) check if UUID needs to be computed this way with it being now UuidMsg
+        UUID snapshotSyncId = new UUID(metadata.getCurrentSnapshotCycleId(), Long.MAX_VALUE);
         log.info("Resume Snapshot Sync Apply, snapshot_transfer_ts={}, id={}", snapshotTransferTs, snapshotSyncId);
+
         // Construct Log Replication Entry message used to complete the Snapshot Sync with info in the metadata manager
-        LogReplicationEntryMetadataMsg metadata = LogReplicationEntryMetadataMsg.newBuilder()
+        LogReplicationEntryMetadataMsg logEntryMsg = LogReplicationEntryMetadataMsg.newBuilder()
                 .setEntryType(LogReplicationEntryType.SNAPSHOT_END)
-                .setTopologyConfigID(logReplicationMetadataManager.getTopologyConfigId())
-                .setTimestamp(-1L)
+                .setTopologyConfigID(metadata.getTopologyConfigId())
+                .setTimestamp(Address.NON_ADDRESS)
                 .setSnapshotTimestamp(snapshotTransferTs)
                 .setSyncRequestId(getUuidMsg(snapshotSyncId)).build();
-        startSnapshotApplyAsync(getLrEntryAckMsg(metadata));
+        startSnapshotApplyAsync(getLrEntryAckMsg(logEntryMsg));
     }
 
     /**
@@ -603,6 +614,21 @@ public class LogReplicationSinkManager implements DataReceiver {
         }
     }
 
+    public ReplicationMetadata getMetadata() {
+        return logReplicationMetadataManager.queryReplicationMetadata(session);
+    }
+
+    public void startPendingSnapshotApply() {
+        ReplicationMetadata metadata = logReplicationMetadataManager.queryReplicationMetadata(session);
+
+        boolean isSnapshotApplyPending = (metadata.getLastSnapshotStarted() == metadata.getLastSnapshotTransferred()) &&
+                metadata.getLastSnapshotTransferred() > metadata.getLastSnapshotApplied();
+
+        if (isSnapshotApplyPending && !ongoingApply.get()) {
+            resumeSnapshotApply(metadata);
+        }
+    }
+
     enum RxState {
         SNAPSHOT_SYNC,
         LOG_ENTRY_SYNC
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/StreamsSnapshotWriter.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/StreamsSnapshotWriter.java
index 6fa40fdc409..5d441af43ad 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/StreamsSnapshotWriter.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/StreamsSnapshotWriter.java
@@ -5,7 +5,8 @@ import io.netty.buffer.Unpooled;
 import lombok.Getter;
 import lombok.extern.slf4j.Slf4j;
 import org.corfudb.infrastructure.logreplication.LogReplicationConfig;
-import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager.LogReplicationMetadataType;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationSession;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationMetadata;
 import org.corfudb.protocols.logprotocol.OpaqueEntry;
 import org.corfudb.protocols.logprotocol.SMREntry;
 import org.corfudb.protocols.wireprotocol.StreamAddressRange;
@@ -60,6 +61,8 @@ public class StreamsSnapshotWriter implements SnapshotWriter {
 
     private static final SMREntry CLEAR_ENTRY = new SMREntry(CLEAR_SMR_METHOD, new Array[0], Serializers.PRIMITIVE);
 
+    private final LogReplicationSession session;
+
     // Mapping from regular stream Id to stream Name
     private final HashMap<UUID, String> streamViewMap;
 
@@ -85,9 +88,11 @@ public class StreamsSnapshotWriter implements SnapshotWriter {
     @Getter
     private Phase phase;
 
-    public StreamsSnapshotWriter(CorfuRuntime rt, LogReplicationConfig config, LogReplicationMetadataManager logReplicationMetadataManager) {
+    public StreamsSnapshotWriter(CorfuRuntime rt, LogReplicationConfig config,
+                                 LogReplicationMetadataManager logReplicationMetadataManager, LogReplicationSession session) {
         this.rt = rt;
         this.logReplicationMetadataManager = logReplicationMetadataManager;
+        this.session = session;
         this.streamViewMap = new HashMap<>();
         this.regularToShadowStreamId = new HashMap<>();
         this.phase = Phase.TRANSFER_PHASE;
@@ -181,8 +186,7 @@ public class StreamsSnapshotWriter implements SnapshotWriter {
 
         try (TxnContext txn = logReplicationMetadataManager.getTxnContext()) {
             updateLog(txn, smrEntries, shadowStreamUuid);
-            logReplicationMetadataManager.appendUpdate(txn,
-                    LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED_SEQUENCE_NUMBER, currentSeqNum);
+            logReplicationMetadataManager.updateReplicationMetadataField(txn, session, ReplicationMetadata.LASTSNAPSHOTTRANSFERREDSEQNUMBER_FIELD_NUMBER, currentSeqNum);
             timestamp = txn.commit();
         }
 
@@ -204,7 +208,7 @@ public class StreamsSnapshotWriter implements SnapshotWriter {
      * @param streamId
      */
     private void updateLog(TxnContext txnContext, List<SMREntry> smrEntries, UUID streamId) {
-        Map<LogReplicationMetadataType, Long> metadataMap = logReplicationMetadataManager.queryMetadata(txnContext, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID,
+        Map<LogReplicationMetadataType, Long> metadataMap = logReplicationMetadataManager.queryReplicationMetadata(txnContext, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID,
                 LogReplicationMetadataType.LAST_SNAPSHOT_STARTED, LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED_SEQUENCE_NUMBER);
         long persistedTopologyConfigId = metadataMap.get(LogReplicationMetadataType.TOPOLOGY_CONFIG_ID);
         long persistedSnapshotStart = metadataMap.get(LogReplicationMetadataType.LAST_SNAPSHOT_STARTED);
@@ -217,8 +221,8 @@ public class StreamsSnapshotWriter implements SnapshotWriter {
             return;
         }
 
-        logReplicationMetadataManager.appendUpdate(txnContext, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID, topologyConfigId);
-        logReplicationMetadataManager.appendUpdate(txnContext, LogReplicationMetadataType.LAST_SNAPSHOT_STARTED, srcGlobalSnapshot);
+        logReplicationMetadataManager.updateReplicationMetadataField(txnContext, session, ReplicationMetadata.TOPOLOGYCONFIGID_FIELD_NUMBER, topologyConfigId);
+        logReplicationMetadataManager.updateReplicationMetadataField(txnContext, session, ReplicationMetadata.LASTSNAPSHOTSTARTED_FIELD_NUMBER, srcGlobalSnapshot);
 
         for (SMREntry smrEntry : smrEntries) {
             txnContext.logUpdate(streamId, smrEntry, dataStreamToTagsMap.get(streamId));
@@ -323,7 +327,7 @@ public class StreamsSnapshotWriter implements SnapshotWriter {
 
         // This variable reflects the minimum timestamp for all shadow streams in the current snapshot cycle.
         // We seek up to this address, assuming that no trim should occur beyond this snapshot start
-        long currentMinShadowStreamTimestamp = logReplicationMetadataManager.getMinSnapshotSyncShadowStreamTs();
+        long currentMinShadowStreamTimestamp = logReplicationMetadataManager.queryReplicationMetadata(session).getCurrentCycleMinShadowStreamTs();
         OpaqueStream shadowOpaqueStream = new OpaqueStream(rt.getStreamsView().get(shadowStreamId, options));
         shadowOpaqueStream.seek(currentMinShadowStreamTimestamp);
         Stream<OpaqueEntry> shadowStream = shadowOpaqueStream.streamUpTo(snapshot);
@@ -409,11 +413,10 @@ public class StreamsSnapshotWriter implements SnapshotWriter {
         phase = Phase.APPLY_PHASE;
 
         // Get the number of entries to apply
-        long seqNum = logReplicationMetadataManager.queryMetadata(LogReplicationMetadataType.LAST_SNAPSHOT_TRANSFERRED_SEQUENCE_NUMBER);
+        long sequenceNumber = logReplicationMetadataManager.queryReplicationMetadata(session).getLastSnapshotTransferredSeqNumber();
 
-        // Only if there is data to be applied
-        if (seqNum != Address.NON_ADDRESS) {
-            log.debug("Start applying shadow streams, seqNum={}", seqNum);
+        if (sequenceNumber != Address.NON_ADDRESS) {
+            log.debug("Start applying shadow streams, seqNum={}", sequenceNumber);
             applyShadowStreams();
         }
     }
@@ -466,7 +469,8 @@ public class StreamsSnapshotWriter implements SnapshotWriter {
         try {
             IRetry.build(IntervalRetry.class, () -> {
                 try (TxnContext txnContext = logReplicationMetadataManager.getTxnContext()) {
-                    logReplicationMetadataManager.appendUpdate(txnContext, LogReplicationMetadataType.TOPOLOGY_CONFIG_ID, topologyConfigId);
+                    logReplicationMetadataManager.updateReplicationMetadataField(txnContext, session,
+                            ReplicationMetadata.TOPOLOGYCONFIGID_FIELD_NUMBER, topologyConfigId);
                     streamsToClear.forEach(streamId -> {
                         clearStream(streamId, txnContext);
                     });
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/LogEntrySenderBufferManager.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/LogEntrySenderBufferManager.java
index 16381eb64df..5e6810b161e 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/LogEntrySenderBufferManager.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/LogEntrySenderBufferManager.java
@@ -5,7 +5,7 @@ import io.micrometer.core.instrument.Tag;
 import lombok.extern.slf4j.Slf4j;
 import org.corfudb.common.metrics.micrometer.MeterRegistryProvider;
 import org.corfudb.infrastructure.logreplication.DataSender;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatusVal;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus;
 import org.corfudb.infrastructure.logreplication.replication.LogReplicationAckReader;
 import org.corfudb.runtime.LogReplication.LogReplicationEntryMsg;
 
@@ -74,7 +74,7 @@ public class LogEntrySenderBufferManager extends SenderBufferManager {
     public void updateAck(LogReplicationEntryMsg entry) {
         updateAck(entry.getMetadata().getTimestamp());
         ackReader.setAckedTsAndSyncType(entry.getMetadata().getTimestamp(),
-                ReplicationStatusVal.SyncType.LOG_ENTRY);
+                ReplicationStatus.SyncType.LOG_ENTRY);
     }
 
     private static Optional<AtomicLong> configureAcksCounter() {
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/SnapshotSenderBufferManager.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/SnapshotSenderBufferManager.java
index f7503444aea..a546e7932a0 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/SnapshotSenderBufferManager.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/SnapshotSenderBufferManager.java
@@ -5,7 +5,7 @@ import io.micrometer.core.instrument.Tag;
 import lombok.extern.slf4j.Slf4j;
 import org.corfudb.common.metrics.micrometer.MeterRegistryProvider;
 import org.corfudb.infrastructure.logreplication.DataSender;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatusVal;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus;
 import org.corfudb.infrastructure.logreplication.replication.LogReplicationAckReader;
 import org.corfudb.runtime.LogReplication.LogReplicationEntryMsg;
 import org.corfudb.runtime.LogReplication.LogReplicationEntryType;
@@ -55,12 +55,12 @@ public class SnapshotSenderBufferManager extends SenderBufferManager {
         // If only a given stream has been replicated, update with the sequence number
         if (entry.getMetadata().getEntryType() == LogReplicationEntryType.SNAPSHOT_REPLICATED) {
             ackReader.setAckedTsAndSyncType(entry.getMetadata().getSnapshotSyncSeqNum(),
-                    ReplicationStatusVal.SyncType.SNAPSHOT);
+                    ReplicationStatus.SyncType.SNAPSHOT);
         } else {
             // If all streams have been replicated, ack with the base snapshot so that the remaining entries(0) get
             // calculated correctly
             ackReader.setAckedTsAndSyncType(entry.getMetadata().getSnapshotTimestamp(),
-                    ReplicationStatusVal.SyncType.SNAPSHOT);
+                    ReplicationStatus.SyncType.SNAPSHOT);
         }
     }
 
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/logreader/StreamsLogEntryReader.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/logreader/StreamsLogEntryReader.java
index 82a5bae1e8b..d629aa242ad 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/logreader/StreamsLogEntryReader.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/logreader/StreamsLogEntryReader.java
@@ -18,6 +18,7 @@ import org.corfudb.runtime.LogReplication.LogReplicationEntryType;
 import org.corfudb.runtime.exceptions.TrimmedException;
 import org.corfudb.runtime.view.Address;
 import org.corfudb.runtime.view.ObjectsView;
+import org.corfudb.runtime.view.TableRegistry;
 import org.corfudb.runtime.view.stream.OpaqueStream;
 
 import javax.annotation.concurrent.NotThreadSafe;
@@ -37,6 +38,8 @@ import static org.corfudb.infrastructure.logreplication.LogReplicationConfig.MAX
 import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;
 import static org.corfudb.protocols.service.CorfuProtocolLogReplication.generatePayload;
 import static org.corfudb.protocols.service.CorfuProtocolLogReplication.getLrEntryMsg;
+import static org.corfudb.runtime.view.TableRegistry.CORFU_SYSTEM_NAMESPACE;
+import static org.corfudb.runtime.view.TableRegistry.getFullyQualifiedTableName;
 
 @Slf4j
 @NotThreadSafe
@@ -223,7 +226,7 @@ public class StreamsLogEntryReader implements LogEntryReader {
                 if (lastOpaqueEntryValid) {
                     validDeltaCounter.ifPresent(Counter::increment);
                 }
-                currentProcessedEntryMetadata = new StreamIteratorMetadata(txOpaqueStream.txStream.pos(), lastOpaqueEntryValid);
+                currentProcessedEntryMetadata = new StreamIteratorMetadata(txOpaqueStream.logReplicatorOpaqueStream.pos(), lastOpaqueEntryValid);
             }
 
             log.trace("Generate LogEntryDataMessage size {} with {} entries for maxDataSizePerMsg {}. lastEntry size {}",
@@ -302,13 +305,12 @@ public class StreamsLogEntryReader implements LogEntryReader {
      */
     public static class TxOpaqueStream {
         private CorfuRuntime rt;
-        private OpaqueStream txStream;
+        private OpaqueStream logReplicatorOpaqueStream;
         private Iterator iterator;
 
         public TxOpaqueStream(CorfuRuntime rt) {
-            //create an opaque stream for transaction stream
             this.rt = rt;
-            txStream = new OpaqueStream(rt.getStreamsView().get(ObjectsView.getLogReplicatorStreamId()));
+            logReplicatorOpaqueStream = new OpaqueStream(rt.getStreamsView().get(ObjectsView.getLogReplicatorStreamId()));
             streamUpTo();
         }
 
@@ -319,7 +321,7 @@ public class StreamsLogEntryReader implements LogEntryReader {
          */
         private void streamUpTo(long snapshot) {
             log.trace("StreamUpTo {}", snapshot);
-            iterator = txStream.streamUpTo(snapshot).iterator();
+            iterator = logReplicatorOpaqueStream.streamUpTo(snapshot).iterator();
         }
 
         /**
@@ -359,7 +361,7 @@ public class StreamsLogEntryReader implements LogEntryReader {
          */
         public void seek(long firstAddress) {
             log.trace("seek head {}", firstAddress);
-            txStream.seek(firstAddress);
+            logReplicatorOpaqueStream.seek(firstAddress);
             streamUpTo();
         }
     }
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/logreader/StreamsSnapshotReader.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/logreader/StreamsSnapshotReader.java
index b478e49f354..6371f5b7da2 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/logreader/StreamsSnapshotReader.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/logreader/StreamsSnapshotReader.java
@@ -19,6 +19,7 @@ import org.corfudb.runtime.LogReplication.LogReplicationEntryType;
 import org.corfudb.runtime.exceptions.TrimmedException;
 import org.corfudb.runtime.view.Address;
 import org.corfudb.runtime.view.StreamOptions;
+import org.corfudb.runtime.view.TableRegistry;
 import org.corfudb.runtime.view.stream.OpaqueStream;
 
 import javax.annotation.concurrent.NotThreadSafe;
@@ -38,6 +39,8 @@ import static org.corfudb.infrastructure.logreplication.LogReplicationConfig.MAX
 import static org.corfudb.protocols.CorfuProtocolCommon.getUuidMsg;
 import static org.corfudb.protocols.service.CorfuProtocolLogReplication.generatePayload;
 import static org.corfudb.protocols.service.CorfuProtocolLogReplication.getLrEntryMsg;
+import static org.corfudb.runtime.view.TableRegistry.CORFU_SYSTEM_NAMESPACE;
+import static org.corfudb.runtime.view.TableRegistry.getFullyQualifiedTableName;
 
 @Slf4j
 @NotThreadSafe
@@ -87,7 +90,7 @@ public class StreamsSnapshotReader implements SnapshotReader {
      * @param entryList
      * @return
      */
-    private OpaqueEntry generateOpaqueEntry(long version, UUID streamID,  SMREntryList entryList) {
+    private OpaqueEntry generateOpaqueEntry(long version, UUID streamID, SMREntryList entryList) {
         Map<UUID, List<SMREntry>> map = new HashMap<>();
         map.put(streamID, entryList.getSmrEntries());
         return new OpaqueEntry(version, map);
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/CorfuLogReplicationRuntime.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/CorfuLogReplicationRuntime.java
index db515ccbf9a..b431035d4cf 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/CorfuLogReplicationRuntime.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/CorfuLogReplicationRuntime.java
@@ -6,6 +6,7 @@ import lombok.extern.slf4j.Slf4j;
 import org.corfudb.infrastructure.LogReplicationRuntimeParameters;
 import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;
 import org.corfudb.infrastructure.logreplication.infrastructure.TopologyDescriptor;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationSession;
 import org.corfudb.infrastructure.logreplication.replication.LogReplicationSourceManager;
 import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;
 import org.corfudb.infrastructure.logreplication.runtime.fsm.IllegalTransitionException;
@@ -156,18 +157,18 @@ public class CorfuLogReplicationRuntime {
     private volatile Optional<String> leaderNodeId = Optional.empty();
 
     @Getter
-    public final String remoteClusterId;
+    public final LogReplicationSession session;
 
     /**
      * Default Constructor
      */
     public CorfuLogReplicationRuntime(LogReplicationRuntimeParameters parameters, LogReplicationMetadataManager metadataManager,
                                       LogReplicationConfigManager replicationConfigManager) {
-        this.remoteClusterId = parameters.getRemoteClusterDescriptor().getClusterId();
+        this.session = parameters.getSession();
         this.metadataManager = metadataManager;
         this.router = new LogReplicationClientRouter(parameters, this);
         this.router.addClient(new LogReplicationHandler());
-        this.sourceManager = new LogReplicationSourceManager(parameters, new LogReplicationClient(router, remoteClusterId),
+        this.sourceManager = new LogReplicationSourceManager(parameters, new LogReplicationClient(router, session.getClusterId()),
                 metadataManager, replicationConfigManager);
         this.connectedNodes = new HashSet<>();
         ThreadFactory threadFactory = new ThreadFactoryBuilder().setNameFormat("runtime-fsm-worker").build();
@@ -187,7 +188,7 @@ public class CorfuLogReplicationRuntime {
      * Start Log Replication Communication FSM
      */
     public void start() {
-        log.info("Start Log Replication Runtime to remote {}", remoteClusterId);
+        log.info("Start Log Replication Runtime to remote {}", session.getClusterId());
         // Start Consumer Thread for this state machine (dedicated thread for event consumption)
         communicationFSMConsumer.submit(this::consume);
         router.connect();
diff --git a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/fsm/NegotiatingState.java b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/fsm/NegotiatingState.java
index a09be27f212..80a86d27fbe 100644
--- a/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/fsm/NegotiatingState.java
+++ b/infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/fsm/NegotiatingState.java
@@ -1,7 +1,10 @@
 package org.corfudb.infrastructure.logreplication.runtime.fsm;
 
 import lombok.extern.slf4j.Slf4j;
+import org.apache.tools.ant.taskdefs.Get;
 import org.corfudb.infrastructure.logreplication.infrastructure.LogReplicationNegotiationException;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationMetadata;
 import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;
 import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;
 import org.corfudb.infrastructure.logreplication.replication.send.LogReplicationEventMetadata;
@@ -11,6 +14,7 @@ import org.corfudb.infrastructure.logreplication.utils.LogReplicationConfigManag
 import org.corfudb.runtime.LogReplication;
 import org.corfudb.runtime.LogReplication.LogReplicationMetadataResponseMsg;
 import org.corfudb.runtime.proto.service.CorfuMessage;
+import org.corfudb.runtime.view.Address;
 
 import java.util.Optional;
 import java.util.concurrent.CompletableFuture;
@@ -176,31 +180,26 @@ public class NegotiatingState implements LogReplicationRuntimeState {
     private void processNegotiationResponse(LogReplicationMetadataResponseMsg negotiationResponse)
             throws LogReplicationNegotiationException {
 
-        log.debug("Process negotiation response {} from {}", negotiationResponse, fsm.getRemoteClusterId());
+        log.debug("Process negotiation response {} from {}", negotiationResponse, fsm.getSession().getClusterId());
 
-        /*
-         * The standby site has a smaller config ID, redo the discovery for this standby site when
-         * getting a new notification of the site config change if this standby is in the new config.
-         */
-        if (negotiationResponse.getTopologyConfigID() < metadataManager.getTopologyConfigId()) {
-            log.error("The active site configID {} is bigger than the standby configID {} ",
-                    metadataManager.getTopologyConfigId(), negotiationResponse.getTopologyConfigID());
+        ReplicationMetadata metadata = metadataManager.queryReplicationMetadata(fsm.getSession());
+
+        // The sink has a smaller config ID, redo the discovery for this remote, when
+        // getting a new notification of the site config, change if this sink is in the new config.
+        if (negotiationResponse.getTopologyConfigID() < metadata.getTopologyConfigId()) {
+            log.error("The source site configID {} is bigger than the sink configID {} ",
+                    metadata.getTopologyConfigId(), negotiationResponse.getTopologyConfigID());
             throw new LogReplicationNegotiationException("Mismatch of configID");
         }
 
-        /*
-         * The standby site has larger config ID, redo the whole discovery for the active site
-         * it will be triggered by a notification of the site config change.
-         */
-        if (negotiationResponse.getTopologyConfigID() > metadataManager.getTopologyConfigId()) {
-            log.error("The active site configID {} is smaller than the standby configID {} ",
-                    metadataManager.getTopologyConfigId(), negotiationResponse.getTopologyConfigID());
+        // The sink has a larger config ID, redo the whole discovery for the source site
+        // it will be triggered by a notification of the site config change.
+        if (negotiationResponse.getTopologyConfigID() > metadata.getTopologyConfigId()) {
+            log.error("The source site configID {} is smaller than the sink configID {} ",
+                    metadata.getTopologyConfigId(), negotiationResponse.getTopologyConfigID());
             throw new LogReplicationNegotiationException("Mismatch of configID");
         }
 
-        /*
-         * Get the current log head.
-         */
         long logHead = metadataManager.getLogHead();
 
         /*
@@ -214,8 +213,8 @@ public class NegotiatingState implements LogReplicationRuntimeState {
          * "snapshotApplied": "-1"
          * "lastLogEntryProcessed": "-1"
          */
-        if (negotiationResponse.getSnapshotStart() == -1) {
-            log.info("No snapshot available in remote. Initiate SNAPSHOT sync to {}", fsm.getRemoteClusterId());
+        if (negotiationResponse.getSnapshotStart() == Address.NON_ADDRESS) {
+            log.info("No snapshot available in remote. Initiate SNAPSHOT sync to {}", fsm.getSession().getClusterId());
             fsm.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.NEGOTIATION_COMPLETE,
                     new LogReplicationEvent(LogReplicationEvent.LogReplicationEventType.SNAPSHOT_SYNC_REQUEST)));
             return;
diff --git a/runtime/src/main/java/org/corfudb/protocols/logprotocol/OpaqueEntry.java b/runtime/src/main/java/org/corfudb/protocols/logprotocol/OpaqueEntry.java
index 9b0d81f076c..42731d8c283 100644
--- a/runtime/src/main/java/org/corfudb/protocols/logprotocol/OpaqueEntry.java
+++ b/runtime/src/main/java/org/corfudb/protocols/logprotocol/OpaqueEntry.java
@@ -41,16 +41,23 @@ public class OpaqueEntry implements Serializable {
     @Getter
     Map<UUID, List<SMREntry>> entries;
 
+    boolean opaque = true;
+
     @Getter
     // TODO(Maithem): Inconsistent behavior when full-sync vs delta (for full sync the versions will change)
     long version;
 
-
     public OpaqueEntry(long version, Map<UUID, List<SMREntry>> updates) {
         this.entries = updates;
         this.version = version;
     }
 
+    public OpaqueEntry(long version, Map<UUID, List<SMREntry>> updates, boolean opaque) {
+        this.entries = updates;
+        this.version = version;
+        this.opaque = opaque;
+    }
+
     public static void serialize(ByteBuf buf, OpaqueEntry entry) {
         buf.writeLong(entry.getVersion());
         buf.writeInt(entry.getEntries().size());
diff --git a/test/src/test/java/org/corfudb/infrastructure/logreplication/LogReplicationFSMTest.java b/test/src/test/java/org/corfudb/infrastructure/logreplication/LogReplicationFSMTest.java
index 88ec1707b22..7d607757a00 100644
--- a/test/src/test/java/org/corfudb/infrastructure/logreplication/LogReplicationFSMTest.java
+++ b/test/src/test/java/org/corfudb/infrastructure/logreplication/LogReplicationFSMTest.java
@@ -499,8 +499,7 @@ public class LogReplicationFSMTest extends AbstractViewTest implements Observer
                 break;
         }
 
-        LogReplicationMetadataManager metadataManager = new LogReplicationMetadataManager(runtime, TEST_TOPOLOGY_CONFIG_ID,
-                TEST_LOCAL_CLUSTER_ID);
+        LogReplicationMetadataManager metadataManager = new LogReplicationMetadataManager(runtime, TEST_TOPOLOGY_CONFIG_ID);
         LogReplicationConfig config = new LogReplicationConfig(new HashSet<>(Arrays.asList(TEST_STREAM_NAME)));
         LogReplicationConfigManager tableManagerPlugin = new LogReplicationConfigManager(runtime);
         ackReader = new LogReplicationAckReader(metadataManager, config, runtime, TEST_LOCAL_CLUSTER_ID);
diff --git a/test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java b/test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java
index 71e366c0469..d9f9cb538b3 100644
--- a/test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java
+++ b/test/src/test/java/org/corfudb/integration/CorfuReplicationClusterConfigIT.java
@@ -5,11 +5,13 @@ import com.google.protobuf.Message;
 import lombok.extern.slf4j.Slf4j;
 import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterConfig;
 import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatusKey;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatusVal;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.SnapshotSyncInfo;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.SyncStatus;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus.SyncType;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationSession;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationMetadataKey;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationMetadataVal;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationMetadata;
 import org.corfudb.infrastructure.logreplication.proto.Sample;
 import org.corfudb.infrastructure.logreplication.replication.LogReplicationAckReader;
 import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;
@@ -159,17 +161,17 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
 
         activeCorfuStore.openTable(LogReplicationMetadataManager.NAMESPACE,
                 REPLICATION_STATUS_TABLE,
-                LogReplicationMetadata.ReplicationStatusKey.class,
-                LogReplicationMetadata.ReplicationStatusVal.class,
+                LogReplicationSession.class,
+                ReplicationStatus.class,
                 null,
-                TableOptions.fromProtoSchema(LogReplicationMetadata.ReplicationStatusVal.class));
+                TableOptions.fromProtoSchema(ReplicationStatus.class));
 
         standbyCorfuStore.openTable(LogReplicationMetadataManager.NAMESPACE,
                 REPLICATION_STATUS_TABLE,
-                LogReplicationMetadata.ReplicationStatusKey.class,
-                LogReplicationMetadata.ReplicationStatusVal.class,
+                LogReplicationSession.class,
+                ReplicationStatus.class,
                 null,
-                TableOptions.fromProtoSchema(LogReplicationMetadata.ReplicationStatusVal.class));
+                TableOptions.fromProtoSchema(ReplicationStatus.class));
     }
 
     @After
@@ -249,36 +251,34 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
         log.info("Log replication succeeds without config change!");
 
         // Verify Sync Status before switchover
-        LogReplicationMetadata.ReplicationStatusKey key =
-                LogReplicationMetadata.ReplicationStatusKey
-                        .newBuilder()
-                        .setClusterId(DefaultClusterConfig.getStandbyClusterId())
-                        .build();
+        LogReplicationSession key = LogReplicationSession.newBuilder()
+                .setClusterId(DefaultClusterConfig.getStandbyClusterId())
+                .build();
 
-        ReplicationStatusVal replicationStatusVal;
+        ReplicationStatus ReplicationStatus;
         try (TxnContext txn = activeCorfuStore.txn(LogReplicationMetadataManager.NAMESPACE)) {
-            replicationStatusVal = (ReplicationStatusVal)txn.getRecord(REPLICATION_STATUS_TABLE, key).getPayload();
+            ReplicationStatus = (ReplicationStatus)txn.getRecord(REPLICATION_STATUS_TABLE, key).getPayload();
             txn.commit();
         }
 
-        log.info("ReplicationStatusVal: RemainingEntriesToSend: {}, SyncType: {}, Status: {}",
-                replicationStatusVal.getRemainingEntriesToSend(), replicationStatusVal.getSyncType(),
-                replicationStatusVal.getStatus());
+        log.info("ReplicationStatus: RemainingEntriesToSend: {}, SyncType: {}, Status: {}",
+                ReplicationStatus.getRemainingEntriesToSend(), ReplicationStatus.getSyncType(),
+                ReplicationStatus.getStatus());
 
         log.info("SnapshotSyncInfo: Base: {}, Type: {}, Status: {}, CompletedTime: {}",
-                replicationStatusVal.getSnapshotSyncInfo().getBaseSnapshot(), replicationStatusVal.getSnapshotSyncInfo().getType(),
-                replicationStatusVal.getSnapshotSyncInfo().getStatus(), replicationStatusVal.getSnapshotSyncInfo().getCompletedTime());
+                ReplicationStatus.getSnapshotSyncInfo().getBaseSnapshot(), ReplicationStatus.getSnapshotSyncInfo().getType(),
+                ReplicationStatus.getSnapshotSyncInfo().getStatus(), ReplicationStatus.getSnapshotSyncInfo().getCompletedTime());
 
 
-        assertThat(replicationStatusVal.getSyncType())
-                .isEqualTo(LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY);
-        assertThat(replicationStatusVal.getStatus())
-                .isEqualTo(LogReplicationMetadata.SyncStatus.ONGOING);
+        assertThat(ReplicationStatus.getSyncType())
+                .isEqualTo(SyncType.LOG_ENTRY);
+        assertThat(ReplicationStatus.getStatus())
+                .isEqualTo(SyncStatus.ONGOING);
 
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getType())
-                .isEqualTo(LogReplicationMetadata.SnapshotSyncInfo.SnapshotSyncType.DEFAULT);
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getStatus())
-                .isEqualTo(LogReplicationMetadata.SyncStatus.COMPLETED);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getType())
+                .isEqualTo(SnapshotSyncInfo.SnapshotSyncType.DEFAULT);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getStatus())
+                .isEqualTo(SyncStatus.COMPLETED);
 
         // Perform a role switch
         try (TxnContext txn = activeCorfuStore.txn(DefaultClusterManager.CONFIG_NAMESPACE)) {
@@ -299,20 +299,19 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
         sleepUninterruptibly(5);
 
         // Verify Sync Status during the first switchover
-        LogReplicationMetadata.ReplicationStatusKey StandbyKey =
-                LogReplicationMetadata.ReplicationStatusKey
-                        .newBuilder()
-                        .setClusterId(DefaultClusterConfig.getActiveClusterId())
-                        .build();
+        LogReplicationSession standbyKey = LogReplicationSession
+                .newBuilder()
+                .setClusterId(DefaultClusterConfig.getActiveClusterId())
+                .build();
 
-        ReplicationStatusVal standbyStatusVal;
+        ReplicationStatus standbyStatusVal;
         try (TxnContext txn = standbyCorfuStore.txn(LogReplicationMetadataManager.NAMESPACE)) {
-            standbyStatusVal = (ReplicationStatusVal)txn.getRecord(REPLICATION_STATUS_TABLE, StandbyKey).getPayload();
+            standbyStatusVal = (ReplicationStatus)txn.getRecord(REPLICATION_STATUS_TABLE, standbyKey).getPayload();
             assertThat(txn.getRecord(REPLICATION_STATUS_TABLE, key).getPayload()).isNull();
             txn.commit();
         }
 
-        log.info("ReplicationStatusVal: RemainingEntriesToSend: {}, SyncType: {}, Status: {}",
+        log.info("ReplicationStatus: RemainingEntriesToSend: {}, SyncType: {}, Status: {}",
                 standbyStatusVal.getRemainingEntriesToSend(), standbyStatusVal.getSyncType(),
                 standbyStatusVal.getStatus());
 
@@ -321,14 +320,14 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
                 standbyStatusVal.getSnapshotSyncInfo().getStatus(), standbyStatusVal.getSnapshotSyncInfo().getCompletedTime());
 
         assertThat(standbyStatusVal.getSyncType())
-                .isEqualTo(LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY);
+                .isEqualTo(SyncType.LOG_ENTRY);
         assertThat(standbyStatusVal.getStatus())
-                .isEqualTo(LogReplicationMetadata.SyncStatus.ONGOING);
+                .isEqualTo(SyncStatus.ONGOING);
 
         assertThat(standbyStatusVal.getSnapshotSyncInfo().getType())
-                .isEqualTo(LogReplicationMetadata.SnapshotSyncInfo.SnapshotSyncType.DEFAULT);
+                .isEqualTo(SnapshotSyncInfo.SnapshotSyncType.DEFAULT);
         assertThat(standbyStatusVal.getSnapshotSyncInfo().getStatus())
-                .isEqualTo(LogReplicationMetadata.SyncStatus.COMPLETED);
+                .isEqualTo(SyncStatus.COMPLETED);
 
         // Wait until data is fully replicated again
         waitForReplication(size -> size == thirdBatch, mapActive, thirdBatch);
@@ -371,27 +370,27 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
 
         // Verify Sync Status
         try (TxnContext txn = activeCorfuStore.txn(LogReplicationMetadataManager.NAMESPACE)) {
-            replicationStatusVal = (ReplicationStatusVal)txn.getRecord(REPLICATION_STATUS_TABLE, key).getPayload();
+            ReplicationStatus = (ReplicationStatus)txn.getRecord(REPLICATION_STATUS_TABLE, key).getPayload();
             txn.commit();
         }
 
-        log.info("ReplicationStatusVal: RemainingEntriesToSend: {}, SyncType: {}, Status: {}",
-                replicationStatusVal.getRemainingEntriesToSend(), replicationStatusVal.getSyncType(),
-                replicationStatusVal.getStatus());
+        log.info("ReplicationStatus: RemainingEntriesToSend: {}, SyncType: {}, Status: {}",
+                ReplicationStatus.getRemainingEntriesToSend(), ReplicationStatus.getSyncType(),
+                ReplicationStatus.getStatus());
 
         log.info("SnapshotSyncInfo: Base: {}, Type: {}, Status: {}, CompletedTime: {}",
-                replicationStatusVal.getSnapshotSyncInfo().getBaseSnapshot(), replicationStatusVal.getSnapshotSyncInfo().getType(),
-                replicationStatusVal.getSnapshotSyncInfo().getStatus(), replicationStatusVal.getSnapshotSyncInfo().getCompletedTime());
-
-        assertThat(replicationStatusVal.getSyncType())
-                .isEqualTo(LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY);
-        assertThat(replicationStatusVal.getStatus())
-                .isEqualTo(LogReplicationMetadata.SyncStatus.ONGOING);
-
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getType())
-                .isEqualTo(LogReplicationMetadata.SnapshotSyncInfo.SnapshotSyncType.DEFAULT);
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getStatus())
-                .isEqualTo(LogReplicationMetadata.SyncStatus.COMPLETED);
+                ReplicationStatus.getSnapshotSyncInfo().getBaseSnapshot(), ReplicationStatus.getSnapshotSyncInfo().getType(),
+                ReplicationStatus.getSnapshotSyncInfo().getStatus(), ReplicationStatus.getSnapshotSyncInfo().getCompletedTime());
+
+        assertThat(ReplicationStatus.getSyncType())
+                .isEqualTo(SyncType.LOG_ENTRY);
+        assertThat(ReplicationStatus.getStatus())
+                .isEqualTo(SyncStatus.ONGOING);
+
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getType())
+                .isEqualTo(SnapshotSyncInfo.SnapshotSyncType.DEFAULT);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getStatus())
+                .isEqualTo(SyncStatus.COMPLETED);
     }
 
     /**
@@ -430,25 +429,25 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
         // data after snapshot sync
         verifyNoDataOnStandbyOpenedTables();
 
-        LogReplicationMetadata.ReplicationStatusKey key =
-            LogReplicationMetadata.ReplicationStatusKey
+        LogReplicationSession key =
+            LogReplicationSession
                 .newBuilder()
                 .setClusterId(DefaultClusterConfig.getStandbyClusterId())
                 .build();
-        ReplicationStatusVal replicationStatusVal;
+        ReplicationStatus ReplicationStatus;
         try (TxnContext txn = activeCorfuStore.txn(LogReplicationMetadataManager.NAMESPACE)) {
-            replicationStatusVal = (ReplicationStatusVal)txn.getRecord(REPLICATION_STATUS_TABLE, key).getPayload();
+            ReplicationStatus = (ReplicationStatus)txn.getRecord(REPLICATION_STATUS_TABLE, key).getPayload();
             txn.commit();
         }
-        assertThat(replicationStatusVal.getSyncType())
-            .isEqualTo(LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY);
-        assertThat(replicationStatusVal.getStatus())
-            .isEqualTo(LogReplicationMetadata.SyncStatus.ONGOING);
+        assertThat(ReplicationStatus.getSyncType())
+            .isEqualTo(SyncType.LOG_ENTRY);
+        assertThat(ReplicationStatus.getStatus())
+            .isEqualTo(SyncStatus.ONGOING);
 
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getType())
-            .isEqualTo(LogReplicationMetadata.SnapshotSyncInfo.SnapshotSyncType.DEFAULT);
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getStatus())
-            .isEqualTo(LogReplicationMetadata.SyncStatus.COMPLETED);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getType())
+            .isEqualTo(SnapshotSyncInfo.SnapshotSyncType.DEFAULT);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getStatus())
+            .isEqualTo(SyncStatus.COMPLETED);
         log.info("Snapshot Sync was successful");
     }
 
@@ -493,25 +492,25 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
         sleepUninterruptibly(20);
 
         // Verify snapshot sync completes as expected
-        LogReplicationMetadata.ReplicationStatusKey key =
-            LogReplicationMetadata.ReplicationStatusKey
+        LogReplicationSession key =
+            LogReplicationSession
                 .newBuilder()
                 .setClusterId(DefaultClusterConfig.getStandbyClusterId())
                 .build();
-        ReplicationStatusVal replicationStatusVal;
+        ReplicationStatus ReplicationStatus;
         try (TxnContext txn = activeCorfuStore.txn(LogReplicationMetadataManager.NAMESPACE)) {
-            replicationStatusVal = (ReplicationStatusVal) txn.getRecord(REPLICATION_STATUS_TABLE, key).getPayload();
+            ReplicationStatus = (ReplicationStatus) txn.getRecord(REPLICATION_STATUS_TABLE, key).getPayload();
             txn.commit();
         }
-        assertThat(replicationStatusVal.getSyncType())
-            .isEqualTo(LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY);
-        assertThat(replicationStatusVal.getStatus())
-            .isEqualTo(LogReplicationMetadata.SyncStatus.ONGOING);
+        assertThat(ReplicationStatus.getSyncType())
+            .isEqualTo(SyncType.LOG_ENTRY);
+        assertThat(ReplicationStatus.getStatus())
+            .isEqualTo(SyncStatus.ONGOING);
 
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getType())
-            .isEqualTo(LogReplicationMetadata.SnapshotSyncInfo.SnapshotSyncType.DEFAULT);
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getStatus())
-            .isEqualTo(LogReplicationMetadata.SyncStatus.COMPLETED);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getType())
+            .isEqualTo(SnapshotSyncInfo.SnapshotSyncType.DEFAULT);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getStatus())
+            .isEqualTo(SyncStatus.COMPLETED);
         log.info("Snapshot Sync successful");
 
 
@@ -528,25 +527,25 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
         sleepUninterruptibly(10);
 
         // Verify snapshot sync completes as expected
-        key = LogReplicationMetadata.ReplicationStatusKey
+        key = LogReplicationSession
             .newBuilder()
             .setClusterId(DefaultClusterConfig.getActiveClusterId())
             .build();
         try (TxnContext txn =
                  standbyCorfuStore.txn(LogReplicationMetadataManager.NAMESPACE)) {
-            replicationStatusVal = (ReplicationStatusVal) txn.getRecord(REPLICATION_STATUS_TABLE, key).getPayload();
+            ReplicationStatus = (ReplicationStatus) txn.getRecord(REPLICATION_STATUS_TABLE, key).getPayload();
             txn.commit();
         }
 
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getType())
-            .isEqualTo(LogReplicationMetadata.SnapshotSyncInfo.SnapshotSyncType.DEFAULT);
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getStatus())
-            .isEqualTo(LogReplicationMetadata.SyncStatus.COMPLETED);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getType())
+            .isEqualTo(SnapshotSyncInfo.SnapshotSyncType.DEFAULT);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getStatus())
+            .isEqualTo(SyncStatus.COMPLETED);
 
-        assertThat(replicationStatusVal.getSyncType())
-            .isEqualTo(LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY);
-        assertThat(replicationStatusVal.getStatus())
-            .isEqualTo(LogReplicationMetadata.SyncStatus.ONGOING);
+        assertThat(ReplicationStatus.getSyncType())
+            .isEqualTo(SyncType.LOG_ENTRY);
+        assertThat(ReplicationStatus.getStatus())
+            .isEqualTo(SyncStatus.ONGOING);
         log.info("Snapshot Sync successful after CP/Trim and Switchover");
     }
 
@@ -695,17 +694,17 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
         assertThat(mapActive.size()).isEqualTo(firstBatch);
 
         // Verify Sync Status
-        ReplicationStatusKey standbyClusterId = ReplicationStatusKey.newBuilder()
+        LogReplicationSession standbyClusterId = LogReplicationSession.newBuilder()
                         .setClusterId(DefaultClusterConfig.getStandbyClusterId())
                         .build();
-        ReplicationStatusVal standbyStatus;
+        ReplicationStatus standbyStatus;
 
         try (TxnContext txn = activeCorfuStore.txn(LogReplicationMetadataManager.NAMESPACE)) {
             // Since LR has never been started, the table should not exist in the registry
             // Note that, in the case of a real client querying the status, this would simply time out
             // because LR is not available and status is only queried on the active site through LR. For the purpose of this
             // test, we query the database directly, so we should simply not find any record.
-            standbyStatus = (ReplicationStatusVal)txn.getRecord(REPLICATION_STATUS_TABLE, standbyClusterId).getPayload();
+            standbyStatus = (ReplicationStatus)txn.getRecord(REPLICATION_STATUS_TABLE, standbyClusterId).getPayload();
             assertThat(standbyStatus).isNull();
         }
 
@@ -720,9 +719,9 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
             Sleep.sleepUninterruptibly(Duration.ofMillis(waitInMillis));
 
             try (TxnContext txn = activeCorfuStore.txn(LogReplicationMetadataManager.NAMESPACE)) {
-                standbyStatus = (ReplicationStatusVal) txn.getRecord(REPLICATION_STATUS_TABLE, standbyClusterId).getPayload();
+                standbyStatus = (ReplicationStatus) txn.getRecord(REPLICATION_STATUS_TABLE, standbyClusterId).getPayload();
                 if (standbyStatus != null) {
-                    assertThat(standbyStatus.getStatus()).isEqualTo(LogReplicationMetadata.SyncStatus.NOT_STARTED);
+                    assertThat(standbyStatus.getStatus()).isEqualTo(SyncStatus.NOT_STARTED);
                 }
                 txn.commit();
             }
@@ -732,8 +731,8 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
         Sleep.sleepUninterruptibly(Duration.ofSeconds(LogReplicationAckReader.ACKED_TS_READ_INTERVAL_SECONDS + deltaSeconds));
 
         try (TxnContext txn = activeCorfuStore.txn(LogReplicationMetadataManager.NAMESPACE)) {
-            standbyStatus = (ReplicationStatusVal)txn.getRecord(REPLICATION_STATUS_TABLE, standbyClusterId).getPayload();
-            assertThat(standbyStatus.getStatus()).isEqualTo(LogReplicationMetadata.SyncStatus.NOT_STARTED);
+            standbyStatus = (ReplicationStatus)txn.getRecord(REPLICATION_STATUS_TABLE, standbyClusterId).getPayload();
+            assertThat(standbyStatus.getStatus()).isEqualTo(SyncStatus.NOT_STARTED);
             txn.commit();
         }
 
@@ -747,16 +746,16 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
             assertThat(mapStandby.containsKey(String.valueOf(i))).isTrue();
         }
 
-        while (!standbyStatus.getSnapshotSyncInfo().getStatus().equals(LogReplicationMetadata.SyncStatus.COMPLETED)) {
+        while (!standbyStatus.getSnapshotSyncInfo().getStatus().equals(SyncStatus.COMPLETED)) {
             try (TxnContext txn = activeCorfuStore.txn(LogReplicationMetadataManager.NAMESPACE)) {
-                standbyStatus = (ReplicationStatusVal)txn.getRecord(REPLICATION_STATUS_TABLE, standbyClusterId).getPayload();
+                standbyStatus = (ReplicationStatus)txn.getRecord(REPLICATION_STATUS_TABLE, standbyClusterId).getPayload();
                 txn.commit();
             }
         }
 
         log.info("Snapshot replication status : COMPLETED");
         // Confirm Log entry Sync status is ONGOING
-        assertThat(standbyStatus.getStatus()).isEqualTo(LogReplicationMetadata.SyncStatus.ONGOING);
+        assertThat(standbyStatus.getStatus()).isEqualTo(SyncStatus.ONGOING);
 
         // (4) Write noisy streams and check remaining entries
         // Write 'N' entries to active noisy map
@@ -781,7 +780,7 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
         Sleep.sleepUninterruptibly(Duration.ofSeconds(LogReplicationAckReader.ACKED_TS_READ_INTERVAL_SECONDS + deltaSeconds));
 
         try (TxnContext txn = activeCorfuStore.txn(LogReplicationMetadataManager.NAMESPACE)) {
-            standbyStatus = (ReplicationStatusVal)txn.getRecord(REPLICATION_STATUS_TABLE, standbyClusterId).getPayload();
+            standbyStatus = (ReplicationStatus)txn.getRecord(REPLICATION_STATUS_TABLE, standbyClusterId).getPayload();
             txn.commit();
         }
 
@@ -791,13 +790,13 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
         // (5) Confirm that if standby LR is stopped, in the middle of replication, the status changes to STOPPED
         shutdownCorfuServer(standbyReplicationServer);
 
-        while (!standbyStatus.getStatus().equals(LogReplicationMetadata.SyncStatus.STOPPED)) {
+        while (!standbyStatus.getStatus().equals(SyncStatus.STOPPED)) {
             try (TxnContext txn = activeCorfuStore.txn(LogReplicationMetadataManager.NAMESPACE)) {
-                standbyStatus = (ReplicationStatusVal) txn.getRecord(REPLICATION_STATUS_TABLE, standbyClusterId).getPayload();
+                standbyStatus = (ReplicationStatus) txn.getRecord(REPLICATION_STATUS_TABLE, standbyClusterId).getPayload();
                 txn.commit();
             }
         }
-        assertThat(standbyStatus.getStatus()).isEqualTo(LogReplicationMetadata.SyncStatus.STOPPED);
+        assertThat(standbyStatus.getStatus()).isEqualTo(SyncStatus.STOPPED);
     }
 
     /**
@@ -1193,13 +1192,13 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
         assertThat(mapStandby.size()).isEqualTo(thirdBatch);
     }
 
-    private Table<LogReplicationMetadataKey, LogReplicationMetadataVal, LogReplicationMetadataVal> getMetadataTable(CorfuRuntime runtime) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException {
+    private Table<LogReplicationMetadataKey, ReplicationMetadata, ReplicationMetadata> getMetadataTable(CorfuRuntime runtime) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException {
         CorfuStore corfuStore = new CorfuStore(runtime);
         CorfuStoreMetadata.TableName metadataTableName = null;
-        Table<LogReplicationMetadataKey, LogReplicationMetadataVal, LogReplicationMetadataVal> metadataTable = null;
+        Table<LogReplicationMetadataKey, ReplicationMetadata, ReplicationMetadata> metadataTable = null;
 
         for (CorfuStoreMetadata.TableName name : corfuStore.listTables(LogReplicationMetadataManager.NAMESPACE)){
-            if(name.getTableName().contains(LogReplicationMetadataManager.METADATA_TABLE_PREFIX_NAME)) {
+            if(name.getTableName().contains(LogReplicationMetadataManager.METADATA_TABLE_NAME)) {
                 metadataTableName = name;
             }
         }
@@ -1208,9 +1207,9 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
                     LogReplicationMetadataManager.NAMESPACE,
                     metadataTableName.getTableName(),
                     LogReplicationMetadataKey.class,
-                    LogReplicationMetadataVal.class,
+                    ReplicationMetadata.class,
                     null,
-                    TableOptions.fromProtoSchema(LogReplicationMetadataVal.class));
+                    TableOptions.fromProtoSchema(ReplicationMetadata.class));
 
         return metadataTable;
     }
@@ -1258,35 +1257,35 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
 
         // Verify Sync Status
         Sleep.sleepUninterruptibly(Duration.ofSeconds(3));
-        LogReplicationMetadata.ReplicationStatusKey key =
-                LogReplicationMetadata.ReplicationStatusKey
+        LogReplicationSession key =
+                LogReplicationSession
                         .newBuilder()
                         .setClusterId(DefaultClusterConfig.getStandbyClusterId())
                         .build();
 
-        LogReplicationMetadata.ReplicationStatusVal replicationStatusVal;
+        ReplicationStatus ReplicationStatus;
         try (TxnContext txn = activeCorfuStore.txn(LogReplicationMetadataManager.NAMESPACE)) {
-            replicationStatusVal = (ReplicationStatusVal)txn.getRecord(REPLICATION_STATUS_TABLE, key).getPayload();
+            ReplicationStatus = (ReplicationStatus)txn.getRecord(REPLICATION_STATUS_TABLE, key).getPayload();
             txn.commit();
         }
 
-        log.info("ReplicationStatusVal: RemainingEntriesToSend: {}, SyncType: {}, Status: {}",
-                replicationStatusVal.getRemainingEntriesToSend(), replicationStatusVal.getSyncType(),
-                replicationStatusVal.getStatus());
+        log.info("ReplicationStatus: RemainingEntriesToSend: {}, SyncType: {}, Status: {}",
+                ReplicationStatus.getRemainingEntriesToSend(), ReplicationStatus.getSyncType(),
+                ReplicationStatus.getStatus());
 
         log.info("SnapshotSyncInfo: Base: {}, Type: {}, Status: {}, CompletedTime: {}",
-                replicationStatusVal.getSnapshotSyncInfo().getBaseSnapshot(), replicationStatusVal.getSnapshotSyncInfo().getType(),
-                replicationStatusVal.getSnapshotSyncInfo().getStatus(), replicationStatusVal.getSnapshotSyncInfo().getCompletedTime());
+                ReplicationStatus.getSnapshotSyncInfo().getBaseSnapshot(), ReplicationStatus.getSnapshotSyncInfo().getType(),
+                ReplicationStatus.getSnapshotSyncInfo().getStatus(), ReplicationStatus.getSnapshotSyncInfo().getCompletedTime());
 
-        assertThat(replicationStatusVal.getSyncType())
-                .isEqualTo(LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY);
-        assertThat(replicationStatusVal.getStatus())
-                .isEqualTo(LogReplicationMetadata.SyncStatus.ONGOING);
+        assertThat(ReplicationStatus.getSyncType())
+                .isEqualTo(SyncType.LOG_ENTRY);
+        assertThat(ReplicationStatus.getStatus())
+                .isEqualTo(SyncStatus.ONGOING);
 
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getType())
-                .isEqualTo(LogReplicationMetadata.SnapshotSyncInfo.SnapshotSyncType.DEFAULT);
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getStatus())
-                .isEqualTo(LogReplicationMetadata.SyncStatus.COMPLETED);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getType())
+                .isEqualTo(SnapshotSyncInfo.SnapshotSyncType.DEFAULT);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getStatus())
+                .isEqualTo(SyncStatus.COMPLETED);
 
 
         // Write 5 entries to active map
@@ -1331,26 +1330,26 @@ public class CorfuReplicationClusterConfigIT extends AbstractIT {
 
         // Verify that a forced snapshot sync is finished.
         try (TxnContext txn = activeCorfuStore.txn(LogReplicationMetadataManager.NAMESPACE)) {
-            replicationStatusVal = (ReplicationStatusVal)txn.getRecord(REPLICATION_STATUS_TABLE, key).getPayload();
+            ReplicationStatus = (ReplicationStatus)txn.getRecord(REPLICATION_STATUS_TABLE, key).getPayload();
             txn.commit();
         }
 
-        log.info("ReplicationStatusVal: RemainingEntriesToSend: {}, SyncType: {}, Status: {}",
-                replicationStatusVal.getRemainingEntriesToSend(), replicationStatusVal.getSyncType(),
-                replicationStatusVal.getStatus());
+        log.info("ReplicationStatus: RemainingEntriesToSend: {}, SyncType: {}, Status: {}",
+                ReplicationStatus.getRemainingEntriesToSend(), ReplicationStatus.getSyncType(),
+                ReplicationStatus.getStatus());
 
         log.info("SnapshotSyncInfo: Base: {}, Type: {}, Status: {}, CompletedTime: {}",
-                replicationStatusVal.getSnapshotSyncInfo().getBaseSnapshot(), replicationStatusVal.getSnapshotSyncInfo().getType(),
-                replicationStatusVal.getSnapshotSyncInfo().getStatus(), replicationStatusVal.getSnapshotSyncInfo().getCompletedTime());
-
-        assertThat(replicationStatusVal.getSyncType())
-                .isEqualTo(LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY);
-        assertThat(replicationStatusVal.getStatus())
-                .isEqualTo(LogReplicationMetadata.SyncStatus.ONGOING);
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getType())
-                .isEqualTo(LogReplicationMetadata.SnapshotSyncInfo.SnapshotSyncType.FORCED);
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getStatus())
-                .isEqualTo(LogReplicationMetadata.SyncStatus.COMPLETED);
+                ReplicationStatus.getSnapshotSyncInfo().getBaseSnapshot(), ReplicationStatus.getSnapshotSyncInfo().getType(),
+                ReplicationStatus.getSnapshotSyncInfo().getStatus(), ReplicationStatus.getSnapshotSyncInfo().getCompletedTime());
+
+        assertThat(ReplicationStatus.getSyncType())
+                .isEqualTo(SyncType.LOG_ENTRY);
+        assertThat(ReplicationStatus.getStatus())
+                .isEqualTo(SyncStatus.ONGOING);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getType())
+                .isEqualTo(SnapshotSyncInfo.SnapshotSyncType.FORCED);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getStatus())
+                .isEqualTo(SyncStatus.COMPLETED);
     }
 
 
diff --git a/test/src/test/java/org/corfudb/integration/CorfuReplicationLargeTxIT.java b/test/src/test/java/org/corfudb/integration/CorfuReplicationLargeTxIT.java
index 51d492a839f..109c1867a06 100644
--- a/test/src/test/java/org/corfudb/integration/CorfuReplicationLargeTxIT.java
+++ b/test/src/test/java/org/corfudb/integration/CorfuReplicationLargeTxIT.java
@@ -3,7 +3,8 @@ package org.corfudb.integration;
 import lombok.Getter;
 import lombok.extern.slf4j.Slf4j;
 import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultLogReplicationConfigAdapter;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationSession;
 import org.corfudb.infrastructure.logreplication.proto.Sample;
 import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;
 import org.corfudb.runtime.collections.CorfuStreamEntries;
@@ -96,11 +97,11 @@ public class CorfuReplicationLargeTxIT extends LogReplicationAbstractIT {
         // change on status are captured)
         int totalStandbyStatusUpdates = 2;
         corfuStoreStandby.openTable(LogReplicationMetadataManager.NAMESPACE,
-            LogReplicationMetadataManager.REPLICATION_STATUS_TABLE,
-            LogReplicationMetadata.ReplicationStatusKey.class,
-            LogReplicationMetadata.ReplicationStatusVal.class,
+            LogReplicationMetadataManager.REPLICATION_STATUS_TABLE_NAME,
+            LogReplicationSession.class,
+            ReplicationStatus.class,
             null,
-            TableOptions.fromProtoSchema(LogReplicationMetadata.ReplicationStatusVal.class));
+            TableOptions.fromProtoSchema(ReplicationStatus.class));
 
         CountDownLatch statusUpdateLatch = new CountDownLatch(totalStandbyStatusUpdates);
         ReplicationStatusListener standbyListener =
diff --git a/test/src/test/java/org/corfudb/integration/CorfuReplicationReconfigurationIT.java b/test/src/test/java/org/corfudb/integration/CorfuReplicationReconfigurationIT.java
index a75430f8399..ea71f6ae74f 100644
--- a/test/src/test/java/org/corfudb/integration/CorfuReplicationReconfigurationIT.java
+++ b/test/src/test/java/org/corfudb/integration/CorfuReplicationReconfigurationIT.java
@@ -3,11 +3,13 @@ package org.corfudb.integration;
 import lombok.extern.slf4j.Slf4j;
 import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterConfig;
 import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultLogReplicationConfigAdapter;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.SnapshotSyncInfo;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.SyncStatus;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationSession;
 import org.corfudb.infrastructure.logreplication.proto.Sample;
 import org.corfudb.infrastructure.logreplication.replication.LogReplicationAckReader;
 import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatusVal;
 import org.corfudb.protocols.wireprotocol.ILogData;
 import org.corfudb.runtime.CorfuRuntime;
 import org.corfudb.runtime.CorfuStoreMetadata;
@@ -161,18 +163,18 @@ public class CorfuReplicationReconfigurationIT extends LogReplicationAbstractIT
 
         // (7) Verify replication status after all data has been replicated (no further data)
         corfuStoreActive.openTable(LogReplicationMetadataManager.NAMESPACE,
-                LogReplicationMetadataManager.REPLICATION_STATUS_TABLE,
-                LogReplicationMetadata.ReplicationStatusKey.class,
-                LogReplicationMetadata.ReplicationStatusVal.class,
+                LogReplicationMetadataManager.REPLICATION_STATUS_TABLE_NAME,
+                LogReplicationSession.class,
+                ReplicationStatus.class,
                 null,
-                TableOptions.fromProtoSchema(LogReplicationMetadata.ReplicationStatusVal.class));
+                TableOptions.fromProtoSchema(ReplicationStatus.class));
 
         // Wait the polling period time before verifying sync status (to make sure it was updated)
         Sleep.sleepUninterruptibly(Duration.ofSeconds(LogReplicationAckReader.ACKED_TS_READ_INTERVAL_SECONDS + 1));
 
-        long remainingEntriesToSend = verifyReplicationStatus(ReplicationStatusVal.SyncType.LOG_ENTRY,
-                LogReplicationMetadata.SyncStatus.ONGOING, LogReplicationMetadata.SnapshotSyncInfo.SnapshotSyncType.DEFAULT,
-                LogReplicationMetadata.SyncStatus.COMPLETED);
+        long remainingEntriesToSend = verifyReplicationStatus(ReplicationStatus.SyncType.LOG_ENTRY,
+                SyncStatus.ONGOING, SnapshotSyncInfo.SnapshotSyncType.DEFAULT,
+                SyncStatus.COMPLETED);
        assertThat(remainingEntriesToSend).isEqualTo(0L);
 
         // (8) Keep writing data into the TX stream (but with data not intended for replication) while
@@ -193,9 +195,9 @@ public class CorfuReplicationReconfigurationIT extends LogReplicationAbstractIT
 
         // While the TX log is growing, the remaining entries to send can be changing during this time, as it is computed
         // wrt. the tail of the log and this varies depending on how fast we are catching the tail of the log.
-        verifyReplicationStatus(ReplicationStatusVal.SyncType.LOG_ENTRY,
-                LogReplicationMetadata.SyncStatus.ONGOING, LogReplicationMetadata.SnapshotSyncInfo.SnapshotSyncType.DEFAULT,
-                LogReplicationMetadata.SyncStatus.COMPLETED);
+        verifyReplicationStatus(ReplicationStatus.SyncType.LOG_ENTRY,
+                SyncStatus.ONGOING, SnapshotSyncInfo.SnapshotSyncType.DEFAULT,
+                SyncStatus.COMPLETED);
 
         stopWrites.set(true);
 
@@ -207,44 +209,44 @@ public class CorfuReplicationReconfigurationIT extends LogReplicationAbstractIT
         // Wait the polling period time and verify sync status again (to make sure it was not erroneously updated)
         Sleep.sleepUninterruptibly(Duration.ofSeconds(LogReplicationAckReader.ACKED_TS_READ_INTERVAL_SECONDS + delta));
 
-        remainingEntriesToSend = verifyReplicationStatus(ReplicationStatusVal.SyncType.LOG_ENTRY,
-                LogReplicationMetadata.SyncStatus.ONGOING, LogReplicationMetadata.SnapshotSyncInfo.SnapshotSyncType.DEFAULT,
-                LogReplicationMetadata.SyncStatus.COMPLETED);
+        remainingEntriesToSend = verifyReplicationStatus(ReplicationStatus.SyncType.LOG_ENTRY,
+                SyncStatus.ONGOING, SnapshotSyncInfo.SnapshotSyncType.DEFAULT,
+                SyncStatus.COMPLETED);
         assertThat(remainingEntriesToSend).isEqualTo(0L);
     }
 
-    private long verifyReplicationStatus(ReplicationStatusVal.SyncType targetSyncType,
-                                         LogReplicationMetadata.SyncStatus targetSyncStatus,
-                                         LogReplicationMetadata.SnapshotSyncInfo.SnapshotSyncType targetSnapshotSyncType,
-                                         LogReplicationMetadata.SyncStatus targetSnapshotSyncStatus) {
+    private long verifyReplicationStatus(ReplicationStatus.SyncType targetSyncType,
+                                         SyncStatus targetSyncStatus,
+                                         SnapshotSyncInfo.SnapshotSyncType targetSnapshotSyncType,
+                                         SyncStatus targetSnapshotSyncStatus) {
 
-        LogReplicationMetadata.ReplicationStatusKey key =
-                LogReplicationMetadata.ReplicationStatusKey
+        LogReplicationSession key =
+                LogReplicationSession
                         .newBuilder()
                         .setClusterId(DefaultClusterConfig.getStandbyClusterId())
                         .build();
 
-        ReplicationStatusVal replicationStatusVal;
+        ReplicationStatus ReplicationStatus;
         try (TxnContext txn = corfuStoreActive.txn(LogReplicationMetadataManager.NAMESPACE)) {
-            replicationStatusVal = (ReplicationStatusVal)txn.getRecord(LogReplicationMetadataManager.REPLICATION_STATUS_TABLE, key).getPayload();
+            ReplicationStatus = (ReplicationStatus)txn.getRecord(LogReplicationMetadataManager.REPLICATION_STATUS_TABLE_NAME, key).getPayload();
             txn.commit();
         }
 
-        log.info("ReplicationStatusVal: RemainingEntriesToSend: {}, SyncType: {}, Status: {}",
-                replicationStatusVal.getRemainingEntriesToSend(), replicationStatusVal.getSyncType(),
-                replicationStatusVal.getStatus());
+        log.info("ReplicationStatus: RemainingEntriesToSend: {}, SyncType: {}, Status: {}",
+                ReplicationStatus.getRemainingEntriesToSend(), ReplicationStatus.getSyncType(),
+                ReplicationStatus.getStatus());
 
-        log.info("ReplicationStatusVal: Base: {}, Type: {}, Status: {}, CompletedTime: {}",
-                replicationStatusVal.getSnapshotSyncInfo().getBaseSnapshot(), replicationStatusVal.getSnapshotSyncInfo().getType(),
-                replicationStatusVal.getSnapshotSyncInfo().getStatus(), replicationStatusVal.getSnapshotSyncInfo().getCompletedTime());
+        log.info("ReplicationStatus: Base: {}, Type: {}, Status: {}, CompletedTime: {}",
+                ReplicationStatus.getSnapshotSyncInfo().getBaseSnapshot(), ReplicationStatus.getSnapshotSyncInfo().getType(),
+                ReplicationStatus.getSnapshotSyncInfo().getStatus(), ReplicationStatus.getSnapshotSyncInfo().getCompletedTime());
 
-        assertThat(replicationStatusVal.getSyncType()).isEqualTo(targetSyncType);
-        assertThat(replicationStatusVal.getStatus()).isEqualTo(targetSyncStatus);
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getType()).isEqualTo(targetSnapshotSyncType);
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getStatus()).isEqualTo(targetSnapshotSyncStatus);
-        assertThat(replicationStatusVal.getSnapshotSyncInfo().getBaseSnapshot()).isGreaterThan(Address.NON_ADDRESS);
+        assertThat(ReplicationStatus.getSyncType()).isEqualTo(targetSyncType);
+        assertThat(ReplicationStatus.getStatus()).isEqualTo(targetSyncStatus);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getType()).isEqualTo(targetSnapshotSyncType);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getStatus()).isEqualTo(targetSnapshotSyncStatus);
+        assertThat(ReplicationStatus.getSnapshotSyncInfo().getBaseSnapshot()).isGreaterThan(Address.NON_ADDRESS);
 
-        return replicationStatusVal.getRemainingEntriesToSend();
+        return ReplicationStatus.getRemainingEntriesToSend();
     }
 
     private void openNonReplicatedTable() throws Exception {
@@ -500,11 +502,11 @@ public class CorfuReplicationReconfigurationIT extends LogReplicationAbstractIT
             // Wait until snapshot sync has completed
             // Open replication status table and monitor completion field
             corfuStoreActive.openTable(LogReplicationMetadataManager.NAMESPACE,
-                    LogReplicationMetadataManager.REPLICATION_STATUS_TABLE,
-                    LogReplicationMetadata.ReplicationStatusKey.class,
-                    LogReplicationMetadata.ReplicationStatusVal.class,
+                    LogReplicationMetadataManager.REPLICATION_STATUS_TABLE_NAME,
+                    LogReplicationSession.class,
+                    ReplicationStatus.class,
                     null,
-                    TableOptions.fromProtoSchema(LogReplicationMetadata.ReplicationStatusVal.class));
+                    TableOptions.fromProtoSchema(ReplicationStatus.class));
             blockUntilSnapshotSyncCompleted();
 
             // Verify Snapshot has successfully replicated
@@ -567,30 +569,30 @@ public class CorfuReplicationReconfigurationIT extends LogReplicationAbstractIT
     }
 
     private void blockUntilSnapshotSyncCompleted() {
-        LogReplicationMetadata.ReplicationStatusKey key =
-                LogReplicationMetadata.ReplicationStatusKey
+        LogReplicationSession key =
+                LogReplicationSession
                         .newBuilder()
                         .setClusterId(DefaultClusterConfig.getStandbyClusterId())
                         .build();
 
-        ReplicationStatusVal replicationStatusVal;
+        ReplicationStatus ReplicationStatus;
         boolean snapshotSyncCompleted = false;
 
         while (snapshotSyncCompleted) {
             try (TxnContext txn = corfuStoreActive.txn(LogReplicationMetadataManager.NAMESPACE)) {
-                replicationStatusVal = (ReplicationStatusVal) txn.getRecord(LogReplicationMetadataManager.REPLICATION_STATUS_TABLE, key).getPayload();
+                ReplicationStatus = (ReplicationStatus) txn.getRecord(LogReplicationMetadataManager.REPLICATION_STATUS_TABLE_NAME, key).getPayload();
                 txn.commit();
             }
 
-            log.info("ReplicationStatusVal: RemainingEntriesToSend: {}, SyncType: {}, Status: {}",
-                    replicationStatusVal.getRemainingEntriesToSend(), replicationStatusVal.getSyncType(),
-                    replicationStatusVal.getStatus());
+            log.info("ReplicationStatus: RemainingEntriesToSend: {}, SyncType: {}, Status: {}",
+                    ReplicationStatus.getRemainingEntriesToSend(), ReplicationStatus.getSyncType(),
+                    ReplicationStatus.getStatus());
 
-            log.info("ReplicationStatusVal: Base: {}, Type: {}, Status: {}, CompletedTime: {}",
-                    replicationStatusVal.getSnapshotSyncInfo().getBaseSnapshot(), replicationStatusVal.getSnapshotSyncInfo().getType(),
-                    replicationStatusVal.getSnapshotSyncInfo().getStatus(), replicationStatusVal.getSnapshotSyncInfo().getCompletedTime());
+            log.info("ReplicationStatus: Base: {}, Type: {}, Status: {}, CompletedTime: {}",
+                    ReplicationStatus.getSnapshotSyncInfo().getBaseSnapshot(), ReplicationStatus.getSnapshotSyncInfo().getType(),
+                    ReplicationStatus.getSnapshotSyncInfo().getStatus(), ReplicationStatus.getSnapshotSyncInfo().getCompletedTime());
 
-            snapshotSyncCompleted = replicationStatusVal.getSnapshotSyncInfo().getStatus() == LogReplicationMetadata.SyncStatus.COMPLETED;
+            snapshotSyncCompleted = ReplicationStatus.getSnapshotSyncInfo().getStatus() == SyncStatus.COMPLETED;
         }
     }
 
diff --git a/test/src/test/java/org/corfudb/integration/CorfuReplicationUpgradeIT.java b/test/src/test/java/org/corfudb/integration/CorfuReplicationUpgradeIT.java
index ae37c25c272..6afe7ba801c 100644
--- a/test/src/test/java/org/corfudb/integration/CorfuReplicationUpgradeIT.java
+++ b/test/src/test/java/org/corfudb/integration/CorfuReplicationUpgradeIT.java
@@ -2,7 +2,8 @@ package org.corfudb.integration;
 
 import lombok.Getter;
 import lombok.extern.slf4j.Slf4j;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationSession;
 import org.corfudb.infrastructure.logreplication.proto.Sample;
 import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;
 import org.corfudb.runtime.collections.CorfuStore;
@@ -106,11 +107,11 @@ public class CorfuReplicationUpgradeIT extends LogReplicationAbstractIT {
 
         // Subscribe to replication status table on Standby (to be sure data change on status are captured)
         corfuStoreStandby.openTable(LogReplicationMetadataManager.NAMESPACE,
-            LogReplicationMetadataManager.REPLICATION_STATUS_TABLE,
-            LogReplicationMetadata.ReplicationStatusKey.class,
-            LogReplicationMetadata.ReplicationStatusVal.class,
+            LogReplicationMetadataManager.REPLICATION_STATUS_TABLE_NAME,
+            LogReplicationSession.class,
+            ReplicationStatus.class,
             null,
-            TableOptions.fromProtoSchema(LogReplicationMetadata.ReplicationStatusVal.class));
+            TableOptions.fromProtoSchema(ReplicationStatus.class));
 
         CountDownLatch statusUpdateLatch = new CountDownLatch(2);
         ReplicationStatusListener standbyListener = new ReplicationStatusListener(statusUpdateLatch, false);
@@ -208,11 +209,11 @@ public class CorfuReplicationUpgradeIT extends LogReplicationAbstractIT {
 
         // Subscribe to replication status table on Standby (to be sure data change on status are captured)
         corfuStoreStandby.openTable(LogReplicationMetadataManager.NAMESPACE,
-            LogReplicationMetadataManager.REPLICATION_STATUS_TABLE,
-            LogReplicationMetadata.ReplicationStatusKey.class,
-            LogReplicationMetadata.ReplicationStatusVal.class,
+            LogReplicationMetadataManager.REPLICATION_STATUS_TABLE_NAME,
+            LogReplicationSession.class,
+            ReplicationStatus.class,
             null,
-            TableOptions.fromProtoSchema(LogReplicationMetadata.ReplicationStatusVal.class));
+            TableOptions.fromProtoSchema(ReplicationStatus.class));
 
         CountDownLatch statusUpdateLatch = new CountDownLatch(2);
         ReplicationStatusListener standbyListener = new ReplicationStatusListener(statusUpdateLatch, false);
@@ -312,11 +313,11 @@ public class CorfuReplicationUpgradeIT extends LogReplicationAbstractIT {
 
         // Subscribe to replication status table on Standby (to be sure data change on status are captured)
         corfuStoreStandby.openTable(LogReplicationMetadataManager.NAMESPACE,
-            LogReplicationMetadataManager.REPLICATION_STATUS_TABLE,
-            LogReplicationMetadata.ReplicationStatusKey.class,
-            LogReplicationMetadata.ReplicationStatusVal.class,
+            LogReplicationMetadataManager.REPLICATION_STATUS_TABLE_NAME,
+            LogReplicationSession.class,
+            ReplicationStatus.class,
             null,
-            TableOptions.fromProtoSchema(LogReplicationMetadata.ReplicationStatusVal.class));
+            TableOptions.fromProtoSchema(ReplicationStatus.class));
 
         CountDownLatch statusUpdateLatch = new CountDownLatch(2);
         ReplicationStatusListener standbyListener = new ReplicationStatusListener(statusUpdateLatch, false);
@@ -452,11 +453,11 @@ public class CorfuReplicationUpgradeIT extends LogReplicationAbstractIT {
 
         // Subscribe to replication status table on Standby (to be sure data change on status are captured)
         corfuStoreStandby.openTable(LogReplicationMetadataManager.NAMESPACE,
-            LogReplicationMetadataManager.REPLICATION_STATUS_TABLE,
-            LogReplicationMetadata.ReplicationStatusKey.class,
-            LogReplicationMetadata.ReplicationStatusVal.class,
+            LogReplicationMetadataManager.REPLICATION_STATUS_TABLE_NAME,
+            LogReplicationSession.class,
+            ReplicationStatus.class,
             null,
-            TableOptions.fromProtoSchema(LogReplicationMetadata.ReplicationStatusVal.class));
+            TableOptions.fromProtoSchema(ReplicationStatus.class));
 
         CountDownLatch statusUpdateLatch = new CountDownLatch(2);
         ReplicationStatusListener standbyListener = new ReplicationStatusListener(statusUpdateLatch, false);
@@ -563,11 +564,11 @@ public class CorfuReplicationUpgradeIT extends LogReplicationAbstractIT {
 
         // Subscribe to replication status table on Standby (to be sure data change on status are captured)
         corfuStoreStandby.openTable(LogReplicationMetadataManager.NAMESPACE,
-            LogReplicationMetadataManager.REPLICATION_STATUS_TABLE,
-            LogReplicationMetadata.ReplicationStatusKey.class,
-            LogReplicationMetadata.ReplicationStatusVal.class,
+            LogReplicationMetadataManager.REPLICATION_STATUS_TABLE_NAME,
+            LogReplicationSession.class,
+            ReplicationStatus.class,
             null,
-            TableOptions.fromProtoSchema(LogReplicationMetadata.ReplicationStatusVal.class));
+            TableOptions.fromProtoSchema(ReplicationStatus.class));
 
         CountDownLatch statusUpdateLatch = new CountDownLatch(2);
         ReplicationStatusListener standbyListener = new ReplicationStatusListener(statusUpdateLatch, false);
@@ -709,11 +710,11 @@ public class CorfuReplicationUpgradeIT extends LogReplicationAbstractIT {
 
         // Subscribe to replication status table on Standby (to be sure data change on status are captured)
         corfuStoreStandby.openTable(LogReplicationMetadataManager.NAMESPACE,
-                LogReplicationMetadataManager.REPLICATION_STATUS_TABLE,
-                LogReplicationMetadata.ReplicationStatusKey.class,
-                LogReplicationMetadata.ReplicationStatusVal.class,
+                LogReplicationMetadataManager.REPLICATION_STATUS_TABLE_NAME,
+                LogReplicationSession.class,
+                ReplicationStatus.class,
                 null,
-                TableOptions.fromProtoSchema(LogReplicationMetadata.ReplicationStatusVal.class));
+                TableOptions.fromProtoSchema(ReplicationStatus.class));
 
         CountDownLatch statusUpdateLatch = new CountDownLatch(2);
         ReplicationStatusListener standbyListener = new ReplicationStatusListener(statusUpdateLatch, false);
diff --git a/test/src/test/java/org/corfudb/integration/CorfuStoreBrowserEditorIT.java b/test/src/test/java/org/corfudb/integration/CorfuStoreBrowserEditorIT.java
index 400d4829c27..1b0575fefd0 100644
--- a/test/src/test/java/org/corfudb/integration/CorfuStoreBrowserEditorIT.java
+++ b/test/src/test/java/org/corfudb/integration/CorfuStoreBrowserEditorIT.java
@@ -19,7 +19,6 @@ import java.util.Map;
 import java.util.Set;
 
 import org.corfudb.browser.CorfuStoreBrowserEditor;
-import org.corfudb.browser.CorfuStoreBrowserEditorMain;
 import org.corfudb.protocols.wireprotocol.IMetadata;
 import org.corfudb.runtime.CorfuRuntime;
 import org.corfudb.runtime.CorfuStoreMetadata;
@@ -703,17 +702,12 @@ public class CorfuStoreBrowserEditorIT extends AbstractIT {
         writer.close();
 
         runtime.shutdown();
-        final String []args = {
-                "--host=" + corfuSingleNodeHost,
-                "--port=" + corfuStringNodePort,
-                "--operation=deleteRecord",
-                "--tablename=" + tableName,
-                "--namespace=" + namespace,
-                "--keysToDeleteFilePath=" + pathToRecordsToDelete,
-                "--batchSize=" + (numRecords / 10)
-        };
-
-        int deletedRecordCount = CorfuStoreBrowserEditorMain.mainMethod(args);
+
+        runtime = createRuntime(singleNodeEndpoint);
+        CorfuStoreBrowserEditor browser = new CorfuStoreBrowserEditor(runtime);
+
+        int deletedRecordCount = browser.deleteRecordsFromFile(namespace, tableName,
+                pathToRecordsToDelete, numRecords / 10);
         assertThat(deletedRecordCount).isEqualTo(numRecords);
         runtime.shutdown();
     }
diff --git a/test/src/test/java/org/corfudb/integration/LogReplicationAbstractIT.java b/test/src/test/java/org/corfudb/integration/LogReplicationAbstractIT.java
index acf1f9c6d54..b7caa36a413 100644
--- a/test/src/test/java/org/corfudb/integration/LogReplicationAbstractIT.java
+++ b/test/src/test/java/org/corfudb/integration/LogReplicationAbstractIT.java
@@ -28,6 +28,8 @@ import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultC
 import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultClusterManager;
 import org.corfudb.infrastructure.logreplication.infrastructure.plugins.DefaultSnapshotSyncPlugin;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationSession;
 import org.corfudb.infrastructure.logreplication.proto.Sample;
 import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;
 import org.corfudb.protocols.wireprotocol.Token;
@@ -187,11 +189,11 @@ public class LogReplicationAbstractIT extends AbstractIT {
 
             // Subscribe to replication status table on Standby (to be sure data change on status are captured)
             corfuStoreStandby.openTable(LogReplicationMetadataManager.NAMESPACE,
-                    LogReplicationMetadataManager.REPLICATION_STATUS_TABLE,
-                    LogReplicationMetadata.ReplicationStatusKey.class,
-                    LogReplicationMetadata.ReplicationStatusVal.class,
+                    LogReplicationMetadataManager.REPLICATION_STATUS_TABLE_NAME,
+                    LogReplicationSession.class,
+                    ReplicationStatus.class,
                     null,
-                    TableOptions.fromProtoSchema(LogReplicationMetadata.ReplicationStatusVal.class));
+                    TableOptions.fromProtoSchema(ReplicationStatus.class));
 
             CountDownLatch statusUpdateLatch = new CountDownLatch(totalStandbyStatusUpdates);
             ReplicationStatusListener standbyListener = new ReplicationStatusListener(statusUpdateLatch, false);
@@ -295,40 +297,40 @@ public class LogReplicationAbstractIT extends AbstractIT {
                 LogReplicationMetadataManager.LR_STATUS_STREAM_TAG);
 
         corfuStoreActive.openTable(LogReplicationMetadataManager.NAMESPACE,
-                LogReplicationMetadataManager.REPLICATION_STATUS_TABLE,
-                LogReplicationMetadata.ReplicationStatusKey.class,
-                LogReplicationMetadata.ReplicationStatusVal.class,
+                LogReplicationMetadataManager.REPLICATION_STATUS_TABLE_NAME,
+                LogReplicationSession.class,
+                ReplicationStatus.class,
                 null,
-                TableOptions.fromProtoSchema(LogReplicationMetadata.ReplicationStatusVal.class));
+                TableOptions.fromProtoSchema(ReplicationStatus.class));
 
-        LogReplicationMetadata.ReplicationStatusKey key =
-                LogReplicationMetadata.ReplicationStatusKey
+        LogReplicationSession key =
+                LogReplicationSession
                         .newBuilder()
                         .setClusterId(DefaultClusterConfig.getStandbyClusterId())
                         .build();
-        LogReplicationMetadata.ReplicationStatusVal replicationStatusVal;
+        ReplicationStatus ReplicationStatus;
 
         statusUpdateLatch.await();
         try (TxnContext txn = corfuStoreActive.txn(LogReplicationMetadataManager.NAMESPACE)) {
-            replicationStatusVal = (LogReplicationMetadata.ReplicationStatusVal) txn.getRecord("LogReplicationStatus", key).getPayload();
+            ReplicationStatus = (ReplicationStatus) txn.getRecord("LogReplicationStatus", key).getPayload();
             txn.commit();
         }
 
-        assertThat(replicationStatusVal.getRemainingEntriesToSend()).isEqualTo(0);
+        assertThat(ReplicationStatus.getRemainingEntriesToSend()).isEqualTo(0);
     }
 
     private void verifyReplicationStatusFromActive() throws Exception {
-        Table<LogReplicationMetadata.ReplicationStatusKey, LogReplicationMetadata.ReplicationStatusVal, LogReplicationMetadata.ReplicationStatusVal>
+        Table<LogReplicationSession, ReplicationStatus, ReplicationStatus>
                 replicationStatusTable = corfuStoreActive.openTable(LogReplicationMetadataManager.NAMESPACE,
-                LogReplicationMetadataManager.REPLICATION_STATUS_TABLE,
-                LogReplicationMetadata.ReplicationStatusKey.class,
-                LogReplicationMetadata.ReplicationStatusVal.class,
+                LogReplicationMetadataManager.REPLICATION_STATUS_TABLE_NAME,
+                LogReplicationSession.class,
+                ReplicationStatus.class,
                 null,
-                TableOptions.fromProtoSchema(LogReplicationMetadata.ReplicationStatusVal.class));
+                TableOptions.fromProtoSchema(ReplicationStatus.class));
 
         IRetry.build(IntervalRetry.class, () -> {
             try(TxnContext txn = corfuStoreActive.txn(LogReplicationMetadataManager.NAMESPACE)) {
-                List<CorfuStoreEntry<LogReplicationMetadata.ReplicationStatusKey, LogReplicationMetadata.ReplicationStatusVal, LogReplicationMetadata.ReplicationStatusVal>>
+                List<CorfuStoreEntry<LogReplicationSession, ReplicationStatus, ReplicationStatus>>
                         entries = txn.executeQuery(replicationStatusTable, all -> true);
                 assertThat(entries.size()).isNotZero();
                 if (entries.get(0).getPayload().getSnapshotSyncInfo().getStatus() != LogReplicationMetadata.SyncStatus.COMPLETED) {
@@ -405,7 +407,7 @@ public class LogReplicationAbstractIT extends AbstractIT {
         @Override
         public void onNext(CorfuStreamEntries results) {
             results.getEntries().forEach((schema, entries) -> entries.forEach(e -> {
-                    LogReplicationMetadata.ReplicationStatusVal statusVal = (LogReplicationMetadata.ReplicationStatusVal)e.getPayload();
+                    ReplicationStatus statusVal = (ReplicationStatus)e.getPayload();
                     accumulatedStatus.add(statusVal.getDataConsistent());
                     if (this.waitSnapshotStatusComplete && statusVal.getSnapshotSyncInfo().getStatus().equals(LogReplicationMetadata.SyncStatus.COMPLETED)) {
                         countDownLatch.countDown();
diff --git a/test/src/test/java/org/corfudb/integration/LogReplicationIT.java b/test/src/test/java/org/corfudb/integration/LogReplicationIT.java
index 981f992c58a..42b6807dbef 100644
--- a/test/src/test/java/org/corfudb/integration/LogReplicationIT.java
+++ b/test/src/test/java/org/corfudb/integration/LogReplicationIT.java
@@ -8,6 +8,7 @@ import org.corfudb.infrastructure.LogReplicationRuntimeParameters;
 import org.corfudb.infrastructure.logreplication.LogReplicationConfig;
 import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;
 import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata;
 import org.corfudb.infrastructure.logreplication.replication.LogReplicationSourceManager;
 import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;
 import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationFSM;
@@ -71,8 +72,8 @@ public class LogReplicationIT extends AbstractIT implements Observer {
     private static final int WRITER_PORT = DEFAULT_PORT + 1;
     private static final String DESTINATION_ENDPOINT = DEFAULT_HOST + ":" + WRITER_PORT;
 
-    private static final String ACTIVE_CLUSTER_ID = UUID.randomUUID().toString();
     private static final String REMOTE_CLUSTER_ID = UUID.randomUUID().toString();
+
     private static final int CORFU_PORT = 9000;
     private static final String TABLE_PREFIX = "test";
 
@@ -112,6 +113,10 @@ public class LogReplicationIT extends AbstractIT implements Observer {
 
     private SourceForwardingDataSender sourceDataSender;
 
+    private final LogReplicationMetadata.LogReplicationSession session = LogReplicationMetadata.LogReplicationSession.newBuilder()
+            .setClusterId(REMOTE_CLUSTER_ID)
+            .build();
+
     // List of all opened maps backed by Corfu on Source and Destination
     private HashMap<String, CorfuTable<Long, Long>> srcCorfuTables = new HashMap<>();
     private HashMap<String, CorfuTable<Long, Long>> dstCorfuTables = new HashMap<>();
@@ -228,7 +233,7 @@ public class LogReplicationIT extends AbstractIT implements Observer {
         dstTestRuntime.parseConfigurationString(DESTINATION_ENDPOINT);
         dstTestRuntime.connect();
 
-        logReplicationMetadataManager = new LogReplicationMetadataManager(dstTestRuntime, 0, REMOTE_CLUSTER_ID);
+        logReplicationMetadataManager = new LogReplicationMetadataManager(dstTestRuntime, 0);
         expectedAckTimestamp = new AtomicLong(Long.MAX_VALUE);
         testConfig.clear().setRemoteClusterId(REMOTE_CLUSTER_ID);
     }
@@ -765,7 +770,7 @@ public class LogReplicationIT extends AbstractIT implements Observer {
         // Verify Destination
         verifyData(dstCorfuTables, srcDataForVerification);
         expectedAckTimestamp.set(srcDataRuntime.getAddressSpaceView().getLogTail());
-        assertThat(expectedAckTimestamp.get()).isEqualTo(logReplicationMetadataManager.getLastProcessedLogEntryTimestamp());
+        assertThat(expectedAckTimestamp.get()).isEqualTo(logReplicationMetadataManager.queryReplicationMetadata(session).getLastLogEntryProcessed());
         verifyPersistedSnapshotMetadata();
         verifyPersistedLogEntryMetadata();
 
@@ -1366,7 +1371,7 @@ public class LogReplicationIT extends AbstractIT implements Observer {
 
         // Data Sender
         sourceDataSender = new SourceForwardingDataSender(DESTINATION_ENDPOINT, config, testConfig,
-                logReplicationMetadataManager, nettyConfig, function);
+                logReplicationMetadataManager, nettyConfig, function, REMOTE_CLUSTER_ID.toString());
 
         LogReplicationConfigManager tableManagerPlugin = new LogReplicationConfigManager(srcTestRuntime);
 
@@ -1485,13 +1490,15 @@ public class LogReplicationIT extends AbstractIT implements Observer {
     }
 
     private void verifyPersistedSnapshotMetadata() {
-        long lastSnapshotStart = logReplicationMetadataManager.getLastStartedSnapshotTimestamp();
-        long lastSnapshotDone = logReplicationMetadataManager.getLastAppliedSnapshotTimestamp();
+        LogReplicationMetadata.ReplicationMetadata metadata = logReplicationMetadataManager.queryReplicationMetadata(session);
+
+        long lastSnapshotStart = metadata.getLastSnapshotStarted();
+        long lastSnapshotDone = metadata.getLastSnapshotApplied();
         assertThat(lastSnapshotStart).isEqualTo(lastSnapshotDone);
     }
 
     private void verifyPersistedLogEntryMetadata() {
-        long lastLogProcessed = logReplicationMetadataManager.getLastProcessedLogEntryTimestamp();
+        long lastLogProcessed = logReplicationMetadataManager.queryReplicationMetadata(session).getLastLogEntryProcessed();
 
         log.debug("\nlastLogProcessed " + lastLogProcessed + " expectedTimestamp " + expectedAckTimestamp.get());
         assertThat(expectedAckTimestamp.get() == lastLogProcessed).isTrue();
diff --git a/test/src/test/java/org/corfudb/integration/LogReplicationReaderWriterIT.java b/test/src/test/java/org/corfudb/integration/LogReplicationReaderWriterIT.java
index b9674564ff2..e3ce65a799a 100644
--- a/test/src/test/java/org/corfudb/integration/LogReplicationReaderWriterIT.java
+++ b/test/src/test/java/org/corfudb/integration/LogReplicationReaderWriterIT.java
@@ -52,7 +52,6 @@ public class LogReplicationReaderWriterIT extends AbstractIT {
     private static final int NUM_KEYS = 10;
     private static final int NUM_STREAMS = 2;
     public static final int NUM_TRANSACTIONS = 20;
-    public static final String PRIMARY_SITE_ID = "Cluster-Paris";
     public static final int BATCH_SIZE = 2;
 
     // Enforce to read each entry for each message
@@ -292,7 +291,7 @@ public class LogReplicationReaderWriterIT extends AbstractIT {
 
     public static void writeSnapLogMsgs(List<LogReplicationEntryMsg> msgQ, Set<String> streams, CorfuRuntime rt) {
         LogReplicationConfig config = new LogReplicationConfig(streams, BATCH_SIZE, MAX_MSG_SIZE);
-        LogReplicationMetadataManager logReplicationMetadataManager = new LogReplicationMetadataManager(rt, 0, PRIMARY_SITE_ID);
+        LogReplicationMetadataManager logReplicationMetadataManager = new LogReplicationMetadataManager(rt, 0);
         StreamsSnapshotWriter writer = new StreamsSnapshotWriter(rt, config, logReplicationMetadataManager);
 
         if (msgQ.isEmpty()) {
@@ -348,7 +347,7 @@ public class LogReplicationReaderWriterIT extends AbstractIT {
 
     public static void writeLogEntryMsgs(List<LogReplicationEntryMsg> msgQ, Set<String> streams, CorfuRuntime rt) {
         LogReplicationConfig config = new LogReplicationConfig(streams);
-        LogReplicationMetadataManager logReplicationMetadataManager = new LogReplicationMetadataManager(rt, 0, PRIMARY_SITE_ID);
+        LogReplicationMetadataManager logReplicationMetadataManager = new LogReplicationMetadataManager(rt, 0);
         LogEntryWriter writer = new LogEntryWriter(config, logReplicationMetadataManager);
 
         if (msgQ.isEmpty()) {
diff --git a/test/src/test/java/org/corfudb/integration/SourceForwardingDataSender.java b/test/src/test/java/org/corfudb/integration/SourceForwardingDataSender.java
index 8b17e99b0f4..69700151608 100644
--- a/test/src/test/java/org/corfudb/integration/SourceForwardingDataSender.java
+++ b/test/src/test/java/org/corfudb/integration/SourceForwardingDataSender.java
@@ -7,7 +7,9 @@ import lombok.extern.slf4j.Slf4j;
 import org.corfudb.common.util.ObservableValue;
 import org.corfudb.infrastructure.logreplication.DataSender;
 import org.corfudb.infrastructure.logreplication.LogReplicationConfig;
-import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationMetadata;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.ReplicationStatus;
+import org.corfudb.infrastructure.logreplication.proto.LogReplicationMetadata.LogReplicationSession;
 import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;
 import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationSinkManager;
 import org.corfudb.infrastructure.logreplication.replication.LogReplicationSourceManager;
@@ -95,16 +97,20 @@ public class SourceForwardingDataSender extends AbstractIT implements DataSender
 
     private static final String REPLICATION_STATUS_TABLE = "LogReplicationStatus";
 
+    private final LogReplicationSession sinkSession;
+
     @SneakyThrows
     public SourceForwardingDataSender(String destinationEndpoint, LogReplicationConfig config, LogReplicationIT.TestConfig testConfig,
                                       LogReplicationMetadataManager metadataManager,
-                                      String pluginConfigFilePath, LogReplicationIT.TransitionSource function) {
+                                      String pluginConfigFilePath, LogReplicationIT.TransitionSource function, String sinkClusterId) {
         this.runtime = CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder().build())
                 .parseConfigurationString(destinationEndpoint)
                 .connect();
         this.destinationDataSender = new AckDataSender();
+        this.sinkSession = LogReplicationSession.newBuilder().setClusterId(sinkClusterId).build();
         this.destinationDataControl = new DefaultDataControl(new DefaultDataControlConfig(false, 0));
-        this.destinationLogReplicationManager = new LogReplicationSinkManager(runtime.getLayoutServers().get(0), config, metadataManager, pluginConfigFilePath);
+        this.destinationLogReplicationManager = new LogReplicationSinkManager(runtime.getLayoutServers().get(0),
+                config, metadataManager, pluginConfigFilePath, sinkSession);
         this.ifDropMsg = testConfig.getDropMessageLevel();
         this.delayedApplyCycles = testConfig.getDelayedApplyCycles();
         this.metadataResponseObservable = new ObservableValue<>(null);
@@ -115,10 +121,10 @@ public class SourceForwardingDataSender extends AbstractIT implements DataSender
         this.standbyCorfuStore = new CorfuStore(runtime);
         standbyCorfuStore.openTable(LogReplicationMetadataManager.NAMESPACE,
                 REPLICATION_STATUS_TABLE,
-                LogReplicationMetadata.ReplicationStatusKey.class,
-                LogReplicationMetadata.ReplicationStatusVal.class,
+                LogReplicationSession.class,
+                ReplicationStatus.class,
                 null,
-                TableOptions.fromProtoSchema(LogReplicationMetadata.ReplicationStatusVal.class));
+                TableOptions.fromProtoSchema(ReplicationStatus.class));
         this.destinationClusterID = testConfig.getRemoteClusterId();
     }
 
@@ -219,14 +225,17 @@ public class SourceForwardingDataSender extends AbstractIT implements DataSender
                 timeoutMetadataResponse = false;
                 return new CompletableFuture<>();
             }
+
+            ReplicationMetadata metadata = destinationLogReplicationManager.getLogReplicationMetadataManager().queryReplicationMetadata(sinkSession);
+
             // In test implementation emulate the apply has succeeded and return a LogReplicationMetadataResponse
             response = LogReplicationMetadataResponseMsg.newBuilder()
                     .setTopologyConfigID(0)
                     .setVersion("version")
                     .setSnapshotStart(baseSnapshotTimestamp)
-                    .setSnapshotTransferred(destinationLogReplicationManager.getLogReplicationMetadataManager().getLastTransferredSnapshotTimestamp())
-                    .setSnapshotApplied(destinationLogReplicationManager.getLogReplicationMetadataManager().getLastAppliedSnapshotTimestamp())
-                    .setLastLogEntryTimestamp(destinationLogReplicationManager.getLogReplicationMetadataManager().getLastProcessedLogEntryTimestamp())
+                    .setSnapshotTransferred(metadata.getLastSnapshotTransferred())
+                    .setSnapshotApplied(metadata.getLastSnapshotApplied())
+                    .setLastLogEntryTimestamp(metadata.getLastLogEntryProcessed())
                     .build();
         }
 
@@ -300,11 +309,11 @@ public class SourceForwardingDataSender extends AbstractIT implements DataSender
                         .build())
                 .build();
 
-        assertThat(destinationLogReplicationManager.getLogReplicationMetadataManager()
-                .getLastProcessedLogEntryTimestamp())
+        ReplicationMetadata metadata = destinationLogReplicationManager.getLogReplicationMetadataManager()
+                .queryReplicationMetadata(sinkSession);
+        assertThat(metadata.getLastLogEntryProcessed())
                 .isGreaterThanOrEqualTo(newMessage.getMetadata().getPreviousTimestamp());
-        assertThat(destinationLogReplicationManager.getLogReplicationMetadataManager()
-                .getLastProcessedLogEntryTimestamp())
+        assertThat(metadata.getLastLogEntryProcessed())
                 .isLessThan(newMessage.getMetadata().getTimestamp());
 
         lastAckDropped = Long.MAX_VALUE;
@@ -316,11 +325,11 @@ public class SourceForwardingDataSender extends AbstractIT implements DataSender
         if (destinationClusterID == null) {
             return;
         }
-        LogReplicationMetadata.ReplicationStatusKey standbyClusterId = LogReplicationMetadata.ReplicationStatusKey.newBuilder()
+        LogReplicationSession standbyClusterId = LogReplicationSession.newBuilder()
                 .setClusterId(destinationClusterID)
                 .build();
         try (TxnContext txn = standbyCorfuStore.txn(LogReplicationMetadataManager.NAMESPACE)) {
-            LogReplicationMetadata.ReplicationStatusVal standbyStatus = (LogReplicationMetadata.ReplicationStatusVal)txn.getRecord(REPLICATION_STATUS_TABLE, standbyClusterId).getPayload();
+            ReplicationStatus standbyStatus = (ReplicationStatus)txn.getRecord(REPLICATION_STATUS_TABLE, standbyClusterId).getPayload();
             assertThat(standbyStatus.getDataConsistent()).isEqualTo(expectedDataConsistent);
         }
     }
