package org.corfudb.runtime;

import lombok.Getter;
import lombok.extern.slf4j.Slf4j;
import org.apache.commons.compress.archivers.tar.TarArchiveEntry;
import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;
import org.apache.commons.io.FileUtils;
import org.corfudb.protocols.logprotocol.MultiSMREntry;
import org.corfudb.protocols.logprotocol.OpaqueEntry;
import org.corfudb.protocols.logprotocol.SMREntry;
import org.corfudb.runtime.collections.CorfuStore;
import org.corfudb.runtime.collections.TxnContext;
import org.corfudb.runtime.exceptions.BackupRestoreException;
import org.corfudb.runtime.view.CacheOption;
import org.corfudb.runtime.view.TableRegistry;
import org.corfudb.util.serializer.Serializers;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.lang.reflect.Array;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.UUID;

import static org.corfudb.runtime.view.TableRegistry.CORFU_SYSTEM_NAMESPACE;

/**
 * Provides Corfu native restore support. Works together with Backup.
 *
 * Restore all tables in the given backup .tar file which is generated by Corfu Backup.
 *
 * Steps:
 * 1. Open the given .tar file, obtain a set of backup files for tables
 * 2. Restore tables by committing transactions using the OpaqueEntries from table backup files
 */
@Slf4j
public class Restore {

    // The path of backup tar file
    private final String filePath;

    // The path of a temporary directory under which the unpacked table's backup files are stored
    private String restoreTempDirPath;

    // The filename of each table's backup file, format: uuid.namespace$tableName.
    private final List<String> tableBackups;

    private CorfuRuntime rt;

    // The Corfu Store associated with the runtime
    private CorfuStore corfuStore;

    // If FULL, will clean up all tables before restore;
    // If PARTIAL, will only clean up tables that are to be restored
    private RestoreMode restoreMode;

    /**
     * Unpacked files from backup tar file are stored under RESTORE_TEMP_DIR. They are deleted after restore finishes.
     */
    private static final String RESTORE_TEMP_DIR_PREFIX = "corfu_restore_";

    /***
     * @param filePath      - the path of backup tar file
     * @param runtime       - the runtime which is performing the restore
     * @throws IOException when failed to create the temp directory
     */
    public Restore(String filePath, CorfuRuntime runtime, RestoreMode restoreMode) throws IOException {
        this.filePath = filePath;
        this.tableBackups = new ArrayList<>();
        this.rt = runtime;
        this.corfuStore = new CorfuStore(runtime);
        this.restoreMode = restoreMode;
    }

    /**
     * Start the restore process
     *
     * @throws IOException
     */
    public void start() throws IOException {
        log.info("started corfu restore");
        try {
            // The cleanup() in finally block is not guaranteed to have
            // been run in previous restore if there was OOM
            cleanup();
            openTarFile();
            verify();
            restore();
        } catch (Exception e) {
            throw new BackupRestoreException("failed to restore from backup file " + filePath, e);
        } finally {
            cleanup();
        }
        log.info("restore completed");
    }

    private void restore() throws IOException {
        if (restoreMode == RestoreMode.FULL) {
            clearAllTables();
        }

        long startTime = System.currentTimeMillis();
        for (String tableBackup : tableBackups) {
            UUID streamId = UUID.fromString(tableBackup.substring(0, tableBackup.indexOf(".")));
            try {
                Path tableBackupPath = Paths.get(restoreTempDirPath).resolve(tableBackup);
                restoreTable(tableBackupPath, streamId);
            } catch (IOException e) {
                log.error("failed to restore table {} from temp file {}", streamId, tableBackup);
                throw e;
            }
        }
        long elapsedTime = System.currentTimeMillis() - startTime;
        log.info("successfully restored {} tables to, elapsed time {}ms",
                tableBackups.size(), elapsedTime);
    }

    /**
     * Restore a single table
     *
     * @param filePath   - the path of the temp backup file
     * @param streamId   - the stream ID of the table which is to be restored
     * @throws IOException
     */
    private void restoreTable(Path filePath, UUID streamId) throws IOException {
        long startTime = System.currentTimeMillis();

        try (FileInputStream fileInput = new FileInputStream(filePath.toString())) {

            // Clear table before restore
            if (restoreMode == RestoreMode.PARTIAL) {
                SMREntry entry = new SMREntry("clear", new Array[0], Serializers.PRIMITIVE);
                nonCachedAppendSMREntries(streamId, entry);
            }

            StreamBatchWriter sbw = new StreamBatchWriter(rt.getParameters().getRestoreBatchSize(),
                    rt.getParameters().getMaxWriteSize(), streamId);
            while (fileInput.available() > 0) {
                OpaqueEntry opaqueEntry = OpaqueEntry.read(fileInput);
                List<SMREntry> smrEntries = opaqueEntry.getEntries().get(streamId);
                if (smrEntries == null || smrEntries.isEmpty()) {
                    continue;
                }

                sbw.batchWrite(smrEntries);
            }
            sbw.shutdown();

            long elapsedTime = System.currentTimeMillis() - startTime;

            log.info("completed restore of table {} with {} numEntries, total size {} byte(s), elapsed time {}ms",
                    streamId, sbw.getTotalNumSMREntries(), sbw.getTotalWriteSize(), elapsedTime);
        } catch (FileNotFoundException e) {
            log.error("restoreTable can not find file {}", filePath);
            throw e;
        }
    }

    /**
     * Open the backup tar file and save the table backups to tableDir directory
     */
    private void openTarFile() throws IOException {
        this.restoreTempDirPath = Files.createTempDirectory(RESTORE_TEMP_DIR_PREFIX).toString();
        try (FileInputStream fileInput = new FileInputStream(filePath);
             TarArchiveInputStream tarInput = new TarArchiveInputStream(fileInput)) {
            getTablesFromTarFile(tarInput);
        } catch (IOException e) {
            log.error("failed to get tables from tar file {}", filePath);
            throw e;
        }
    }

    private void getTablesFromTarFile(TarArchiveInputStream tarInput) throws IOException {
        int count;
        byte[] buf = new byte[1024];
        TarArchiveEntry entry;
        while ((entry = tarInput.getNextTarEntry()) != null) {
            tableBackups.add(entry.getName());

            String tablePath = restoreTempDirPath + File.separator + entry.getName();
            try (FileOutputStream fos = new FileOutputStream(tablePath)) {
                while ((count = tarInput.read(buf, 0, 1024)) != -1) {
                    fos.write(buf, 0, count);
                }
            }
        }
    }

    /**
     * Some verification logic (TBD) such as
     * - Compare the user provided streamIds and names of table backups under tmp directory, or some metadata file
     * - Checksum
     */
    private void verify() {
        // TODO: verification logic to be implemented
    }

    /**
     * Delete all temp restore directories under the system temp directory.
     */
    private void cleanup() {
        File tmpdir = new File(System.getProperty("java.io.tmpdir"));
        File[] restoreDirs = tmpdir.listFiles(file -> file.getName().contains(RESTORE_TEMP_DIR_PREFIX));
        if (restoreDirs != null) {
            for (File file : restoreDirs) {
                try {
                    FileUtils.deleteDirectory(file);
                    log.info("removed temporary backup directory {}", file.getAbsolutePath());
                } catch (IOException e) {
                    log.error("failed to delete the temporary backup directory {}", file.getAbsolutePath());
                }
            }
        }
    }

    private void clearAllTables() {
        TxnContext txn = corfuStore.txn(CORFU_SYSTEM_NAMESPACE);

        corfuStore.getRuntime().getTableRegistry().listTables().forEach(tableName -> {
            String name = TableRegistry.getFullyQualifiedTableName(tableName);
            UUID streamId = CorfuRuntime.getStreamID(name);
            SMREntry entry = new SMREntry("clear", new Array[0], Serializers.PRIMITIVE);
            txn.logUpdate(streamId, entry);
        });

        txn.commit();
    }

    private void nonCachedAppendSMREntries(UUID streamId, SMREntry... smrEntries) {
        MultiSMREntry multiSMREntry = new MultiSMREntry();
        multiSMREntry.addTo(Arrays.asList(smrEntries));
        rt.getStreamsView().append(multiSMREntry, null, CacheOption.WRITE_AROUND, streamId);
    }

    public enum RestoreMode {
        FULL,   // Clean up ALL tables before restore
        PARTIAL // Clean up ONLY tables that are to be restored
    }

    class StreamBatchWriter {

        private final int maxBatchSize;
        private final int maxWriteSize;
        private final UUID streamId;

        @Getter
        private int totalNumSMREntries = 0;
        @Getter
        private int totalWriteSize = 0;

        private final List<SMREntry> buffer = new ArrayList<>();
        private int bufferWriteSize = 0;

        StreamBatchWriter(int maxBatchSize, int maxWriteSize, UUID streamId) {
            this.maxBatchSize = maxBatchSize;
            this.maxWriteSize = maxWriteSize;
            this.streamId = streamId;
        }

        public void batchWrite(List<SMREntry> smrEntries) {
            if (smrEntries.isEmpty()) {
                return;
            }

            for (SMREntry smrEntry : smrEntries) {
                if (buffer.size() == maxBatchSize || bufferWriteSize + smrEntry.getSerializedSize() > maxWriteSize) {
                    flushBuffer();
                }
                buffer.add(smrEntry);
                bufferWriteSize += smrEntry.getSerializedSize();
            }
        }

        public void shutdown() {
            flushBuffer();
        }

        private void flushBuffer() {
            totalNumSMREntries += buffer.size();
            totalWriteSize += bufferWriteSize;

            nonCachedAppendSMREntries(streamId, buffer.toArray(new SMREntry[0]));

            bufferWriteSize = 0;
            buffer.clear();
        }

    }
}
